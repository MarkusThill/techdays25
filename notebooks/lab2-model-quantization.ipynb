{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusThill/techdays25/blob/feature-lab2-initial-draft/notebooks/lab2-model-quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWrVTJSVVy4"
      },
      "source": [
        "# ðŸš€ Lab 2: Effiziente Quantisierung tiefer neuronaler Netze\n",
        "- Dieses Jupyter Notebook **benÃ¶tigt eine GPU Laufzeit**. Falls nicht bereits voreingestellt, kann daher der Laufzeittyp im MenÃ¼ unter \"Laufzeit\" > \"Laufzeittyp Ã¤ndern\" > \"Hardwarebeschleuniger\" > **\"T4 GPU\"** geÃ¤ndert werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHjiyBN9VVy4"
      },
      "source": [
        "# Vorbereitungen: Installation der nÃ¶tigen AbhÃ¤ngigkeiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zRp0QsBVVy5"
      },
      "outputs": [],
      "source": [
        "# Remove the `%%capture`, if you have the impression that something is going wrong during the setup\n",
        "#%%capture\n",
        "!pip install \"techdays25[lab2] @ git+https://github.com/MarkusThill/techdays25.git@feature-lab2-initial-draft\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PetUdSKZVVy5"
      },
      "source": [
        "**IN ROT 'WICHTIG: Nach der Installation der AbhÃ¤ngigkeiten (siehe oben) muss die Google Colab Laufzeit neugestartet werden! Im Anschluss kann mit der AusfÃ¼hrung der nÃ¤chsten Zellen fortgefahren werden werden.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/MarkusThill/techdays25.git\"\n",
        "!cd techdays25 && git checkout feature-lab2-initial-draft"
      ],
      "metadata": {
        "id": "TvMZAZUyiYx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf2wjy7rVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Colab-spezifische Konfigurationen {display-mode: \"form\"}\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "\n",
        "    output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPuTmcJKVVy5"
      },
      "source": [
        "# ðŸ“˜ Einleitung und Gliederung\n",
        "\n",
        "Dieses Jupyter Notebook ist in 4 Teile gegliedert. Es empfiehlt sich, die einzelnen Teile von vorne beginnend, nacheinander durchzuarbeiten.\n",
        "\n",
        "- ðŸ“– Teil 1: Darstellung numerischer Datentypen\n",
        "  - In diesem Teil wiederholen wir verschiedene Darstellungen von numerischen Datentypen und lernen in einem interaktivem Modul die Unterschiede zwischen diesen kennen.\n",
        "- ðŸ”¢ Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
        "- ðŸ•¸ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
        "- ðŸ“ž Teil 4: Quantisierung eines DTMF Klassifikationsmodells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-emxsEEVVy5"
      },
      "source": [
        "# ðŸ“– Teil 1: Darstellung numerischer Datentypen\n",
        "- Zweierkomplementdarstellung\n",
        "- IEEE-754 Standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0MW1AnSVVy5"
      },
      "source": [
        "### Ganzahldarstellungen/Zweierkomplementdarstellung"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Darstellung von 8-Bit Integer Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Initialize 8 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"40px\")\n",
        "    )\n",
        "    for _ in range(8)\n",
        "]\n",
        "\n",
        "# Color bars for sign and integer part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 40px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 40px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    for i in range(8)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Hex representation (2 hex digits for 8 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            BinÃ¤rdarstellung: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:]}</span>\n",
        "            </code><br>\n",
        "            Vorzeichenlose Dezimalzahl: <b>{unsigned_decimal}</b><br>\n",
        "            Vorzeichenbehaftete Dezimalzahl (Zweierkomplement): <b>{signed_decimal}</b><br>\n",
        "            Hexadezimaldarstellung: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()\n"
      ],
      "metadata": {
        "id": "Vooo4D08nI9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDlSxZqOVVy6"
      },
      "source": [
        "#### Ãœbungsfragen (Optional):\n",
        "\n",
        "- Was ist die grÃ¶ÃŸtmÃ¶gliche bzw. kleinstmÃ¶gliche Zahl die mit 8 Bit dargestellt werden kÃ¶nnen?\n",
        "- Signed vs. Unsigned Darstellung: Setze das 8. Bit (hÃ¶chstwertiges Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "- Was charakterisiert eine negative Zahl in der Zweierkomplementdarstellung (unsigned integer) im Allgmeinen?\n",
        "- Wie negiere ich eine Zahl (z.B. 32 -> -32 bzw. -71 -> 71)?\n",
        "- Angenommen ich habe -33 als 8-bit Zahl vorliegen. Wie wÃ¼rde ich daraus eine 32-bit unsigned Integer Zahl machen?\n",
        "- Maximale und minimale Werte: Was ist der maximale/minimale Wert, den man mit einer 8-Bit signed/unsigned Zahl darstellen kann?\n",
        "- Alle Bits gesetzt: Setze alle Bits einer 8-Bit-Zahl auf 1. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q1kp8MaVVy6"
      },
      "source": [
        "### Fixkommadarstellungen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Darstellung von 16-Bit Integer/Festkomma-Zahlen {display-mode: \"form\"}\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, integer part, and fractional part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 7\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "def fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to a fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = twos_complement(integer_part)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "def unsigned_fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to an unsigned fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The unsigned fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = int(\"\".join(str(b) for b in integer_part), 2)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Fixed-point value\n",
        "    fixed_point_decimal = fixed_point_value(bit_values)\n",
        "\n",
        "    # Unsigned fixed-point value\n",
        "    unsigned_fixed_point_decimal = unsigned_fixed_point_value(bit_values)\n",
        "\n",
        "    # Hex representation (4 hex digits for 16 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            BinÃ¤rdarstellung: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:8]}</span>.\n",
        "                <span style=\"color: blue;\">{bit_string[8:]}</span>\n",
        "            </code><br>\n",
        "            Vorzeichenlose Dezimalzahl: <b>{unsigned_decimal}</b><br>\n",
        "            Vorzeichenbehaftete Dezimalzahl (Zweierkomplement): <b>{signed_decimal}</b><br>\n",
        "            Vorzeichenlose Festkommazahl: <b>{unsigned_fixed_point_decimal}</b><br>\n",
        "            Vorzeichenbehaftete Festkommazahl (Zweierkomplement): <b>{fixed_point_decimal}</b><br>\n",
        "            Hexadezimaldarstellung: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "def reset_bits(*args) -> None:\n",
        "    \"\"\"Reset all toggle buttons to their initial state (False).\"\"\"\n",
        "    for btn in bit_toggles:\n",
        "        btn.value = False\n",
        "\n",
        "# Create reset button\n",
        "reset_button = widgets.Button(description=\"Reset\", layout=widgets.Layout(width=\"100px\"))\n",
        "reset_button.on_click(reset_bits)\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars), reset_button]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()\n"
      ],
      "metadata": {
        "id": "X37wJrQDpVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN_oFcfjVVy6"
      },
      "source": [
        "#### Ãœbungsfragen (Optional):\n",
        "- Was ist die kleinstmÃ¶gliche vorzeichenbehaftete Festkommazahl?\n",
        "- Wie stelle ich -1.25 als Festkommazahl dar?\n",
        "- Was ist die kleinstmÃ¶gliche (grÃ¶ÃŸtmÃ¶gliche) Festkommazahl grÃ¶ÃŸer (kleiner) als Null?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8LgC7KNVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit (FP16) FlieÃŸkommazahlen nach IEEE 754 {display-mode: \"form\"}\n",
        "\n",
        "import struct\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, exponent, and mantissa\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 5\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show FP16 value and components\n",
        "output = widgets.Output()\n",
        "\n",
        "def bits_to_float16(bits: list[int]) -> np.float16:\n",
        "    \"\"\"Convert list of bits to FP16 float value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        np.float16: The FP16 float value of the binary number.\n",
        "    \"\"\"\n",
        "    bit_string = \"\".join(str(b) for b in bits)\n",
        "    # Convert binary string to integer\n",
        "    int_value = int(bit_string, 2)\n",
        "    # Pack as unsigned 16-bit int, then unpack as float16 using numpy\n",
        "    packed = struct.pack(\"<H\", int_value)  # Big endian 16-bit unsigned int\n",
        "    return np.frombuffer(packed, dtype=np.float16)[0]\n",
        "\n",
        "def update_display(*args):\n",
        "    \"\"\"Update the display with the current binary, FP16 float value, and its components.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Extract components\n",
        "    sign = bit_values[0]\n",
        "    exponent_bits = bit_values[1:6]\n",
        "    mantissa_bits = bit_values[6:]\n",
        "\n",
        "    exponent = int(\"\".join(str(b) for b in exponent_bits), 2)\n",
        "    exponent_unbiased = exponent - 15  # Bias = 15\n",
        "\n",
        "    mantissa_raw = \"\".join(str(b) for b in mantissa_bits)\n",
        "    mantissa_value = (\n",
        "        1 + sum(int(b) * 2 ** (-i) for i, b in enumerate(mantissa_bits, start=1))\n",
        "        if exponent != 0\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "    # Convert to float16 value\n",
        "    fp16_value = bits_to_float16(bit_values)\n",
        "\n",
        "    # Clear previous output and display new info\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            BinÃ¤rdarstellung: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:6]}</span>\n",
        "                <span style=\"color: blue;\">{bit_string[6:]}</span>\n",
        "            </code><br>\n",
        "            Vorzeichen (1 bit): <b>{sign}</b> ({\"-\" if sign else \"+\"})<br>\n",
        "            Exponent (5 bits): <b>{\"\".join(str(b) for b in exponent_bits)} (biased: {exponent}, unbiased: {exponent_unbiased})</b><br>\n",
        "            Mantisse (10 bits): <b>{mantissa_raw}</b><br>\n",
        "            <hr>\n",
        "            <b>FP16 Dezimaldarstellung: {fp16_value} </b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "def reset_bits(*args) -> None:\n",
        "    \"\"\"Reset all toggle buttons to their initial state (False).\"\"\"\n",
        "    for btn in bit_toggles:\n",
        "        btn.value = False\n",
        "\n",
        "# Create reset button\n",
        "reset_button = widgets.Button(description=\"Reset\", layout=widgets.Layout(width=\"100px\"))\n",
        "reset_button.on_click(reset_bits)\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars), reset_button]))\n",
        "display(output)\n",
        "\n",
        "# Initialize output\n",
        "update_display()  # 0 01111 0000000001 ^=^ 1.00097656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBCmHSNeVVy6"
      },
      "source": [
        "#### Ãœbungsfragen (Optional):\n",
        "- Wie wÃ¼rde ich 1.0, 0.5 und 7.0 darstellen?\n",
        "- Was ist die grÃ¶ÃŸte/kleinste darstellbare Zahl?\n",
        "- Gibt es einen Unterschied zwischen +0.0 und -0.0?\n",
        "- Wie stelle ich `+Inf` bzw. `-Inf` dar?\n",
        "- Wie stelle ich `NaN` dar?\n",
        "- Was ergibt der Vergleich `float(\"nan\") != float(\"nan\")`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7youIav3VVy7"
      },
      "source": [
        "# ðŸ”¢ Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
        "\n",
        "TODO:\n",
        "- In diesem Abschnitt werden wir das lineare ONNX-Regressions-Modell, das wir in Lab 1 erzeugt haben, quantisieren und uns die Ergebnisse fÃ¼r verschiedene Quantisierungsstufen (FP32, FP16, INT8) anschauen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KX9mB2kgqHH"
      },
      "outputs": [],
      "source": [
        "# Load necessary libs\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import onnx\n",
        "import pandas as pd\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "from techdays25.onnx_utils import (\n",
        "    OnnxModel,\n",
        "    benchmark_models_on_batch_size,\n",
        "    plot_benchmark_results,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify, which model to use\n",
        "onnx_model_path = Path(\"techdays25/assets/lab1/pytorch_regression.onnx\")"
      ],
      "metadata": {
        "id": "vMj1QPe8umFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the model again\n",
        "from techdays25 import onnx_utils\n",
        "onnx_utils.netron_visualize(str(onnx_model_path))"
      ],
      "metadata": {
        "id": "zHbGI4Lwuh8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ls-fTM1gqHH"
      },
      "source": [
        "## Quantisiere ONNX Modell nach FP16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbYQ_9fjMCUD"
      },
      "outputs": [],
      "source": [
        "# Load the previously saved FP32 ONNX model\n",
        "regression_model_fp32 = onnx.load(onnx_model_path)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    regression_model_fp32,  # path to the onnx model\n",
        "    min_positive_val=1e-7,  # Constant values will be clipped to these bounds\n",
        "    max_finite_val=1e4,  # same as above\n",
        "    keep_io_types=True,  # If set to false, the IO types will change to FP16\n",
        "    disable_shape_infer=False,  # Skips running onnx shape/type inference\n",
        "    op_block_list=None,  # A list of OPs which shall not be quantized\n",
        "    node_block_list=None,  # A list of nodes which shall not be converted\n",
        ")\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_fp16_path = onnx_model_path.stem + \"_fp16\" + onnx_model_path.suffix\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_fp16_path)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_fp16_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbOmu6lDgqHI"
      },
      "source": [
        "## Quantisiere Modell nach INT8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process"
      ],
      "metadata": {
        "id": "VG3h5hRa25kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cemKbQh6gqHI"
      },
      "outputs": [],
      "source": [
        "# First try static quantization and then switch to dynamic quantization\n",
        "# and see how the results change\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "#\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = np.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process"
      ],
      "metadata": {
        "id": "wB9FrJXeab4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = Path(\"dtmf_classifier.onnx\")\n",
        "# First try static quantization and then switch to dynamic quantization\n",
        "# and see how the results change\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "# Shape inference and model optimization, in preparation for quantization.\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = dtmf_gen.generate_dataset(\n",
        "            n_samples=32, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        extra_options={\"CalibTensorRangeSymmetric\":True}\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ],
      "metadata": {
        "id": "kgQGXuHvab4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_77SjqWgqHI"
      },
      "source": [
        "## Netron Visualisierung der ONNX Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPJlTiVRgqHI"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "# Change model path accordingly:\n",
        "onnx_utils.netron_visualize(\"pytorch_regression_int8.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ZYUTq7gqHI"
      },
      "source": [
        "## Vergleich der quantisierten Modellvarianten mit ursprÃ¼nglichem Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX1nKqsDgqHI"
      },
      "outputs": [],
      "source": [
        "reg_model_fp32_cpu = OnnxModel(onnx_model_path, provider=\"CPUExecutionProvider\")\n",
        "reg_model_fp16_cpu = OnnxModel(onnx_model_fp16_path, provider=\"CPUExecutionProvider\")\n",
        "reg_model_int8_cpu = OnnxModel(onnx_model_path_int8, provider=\"CPUExecutionProvider\")\n",
        "\n",
        "reg_model_fp32_gpu = OnnxModel(onnx_model_path, provider=\"CUDAExecutionProvider\")\n",
        "reg_model_fp16_gpu = OnnxModel(onnx_model_fp16_path, provider=\"CUDAExecutionProvider\")\n",
        "reg_model_int8_gpu = OnnxModel(onnx_model_path_int8, provider=\"CUDAExecutionProvider\")\n",
        "\n",
        "print(\"\\nSpezifikation des FP16 Modells:\")\n",
        "print(reg_model_fp16_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGYkUWNzMJGz"
      },
      "outputs": [],
      "source": [
        "# Create some random data and compare the results of the FP16 and FP32 models\n",
        "u_range = (-10, 10)  # set range for which input values shall be generated\n",
        "\n",
        "models = {\n",
        "    \"FP32/CPU\": reg_model_fp32_cpu,  # first model is the reference\n",
        "    \"FP16/CPU\": reg_model_fp16_cpu,\n",
        "    #\"INT8/CPU\": reg_model_int8_cpu,\n",
        "    # \"FP32/GPU\": reg_model_fp32_gpu,\n",
        "    \"FP16/GPU\": reg_model_fp16_gpu,\n",
        "    \"INT8/GPU\": reg_model_int8_gpu,\n",
        "}\n",
        "\n",
        "uu = np.linspace(*u_range, 15).reshape(-1, 1).astype(np.float32)\n",
        "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
        "\n",
        "# Extract the first key-value pair (this is the reference)\n",
        "first_key = next(iter(ii_predictions))\n",
        "first_value = ii_predictions[first_key]\n",
        "ii_diffs = {\n",
        "    \"Î”\" + k: first_value - v for k, v in ii_predictions.items() if k != first_key\n",
        "}\n",
        "\n",
        "df_data = {\"Input [U/V]\": uu.flatten()}\n",
        "\n",
        "df_data.update(ii_predictions)\n",
        "df_data.update(ii_diffs)\n",
        "\n",
        "pd.DataFrame(df_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzNNq4CUgqHI"
      },
      "source": [
        "### Fragen (Optional)\n",
        "- Wie verhalten sich die Modellausgaben/Differenzen der beiden obigen Modelle fÃ¼r unterschiedliche Bereiche, die in `u_range` spezifiziert werden, z.B. fÃ¼r `u_range=(0,100)` oder `u_range=(-1000, 1000)`?\n",
        "- Wie lassen sich mÃ¶gliche Abweichungen erklÃ¤ren?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRlxbLaqgqHI"
      },
      "outputs": [],
      "source": [
        "# Comment/Uncomment the lines in `models` to unselect/select certain models\n",
        "models = {\n",
        "    \"FP32/CPU\": reg_model_fp32_cpu,  # first model is the reference\n",
        "    #\"FP16/CPU\": reg_model_fp16_cpu,\n",
        "    #\"INT8/CPU\": reg_model_int8_cpu,\n",
        "    # \"FP32/GPU\": reg_model_fp32_gpu,\n",
        "    \"FP16/GPU\": reg_model_fp16_gpu,\n",
        "    \"INT8/GPU\": reg_model_int8_gpu,\n",
        "}\n",
        "\n",
        "# systematically evaluate the model differences for a given range\n",
        "uu = np.linspace(-200, 200, 100000).reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
        "# Extract the first key-value pair (this is the reference)\n",
        "ref_key = next(iter(ii_predictions))\n",
        "ref_value = ii_predictions[ref_key]\n",
        "ii_diffs = {k: ref_value - v for k, v in ii_predictions.items() if k != ref_key}\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for k, v in ii_diffs.items():\n",
        "    plt.plot(uu, v, label=k)\n",
        "\n",
        "# plt.yscale(\"symlog\", linthresh=.0001)\n",
        "plt.grid(which=\"both\")\n",
        "plt.xlabel(\"U [V]\")\n",
        "plt.ylabel(r\"$\\Delta \\hat{I}_{ref}$ [mA]\")\n",
        "plt.legend()\n",
        "plt.title(f\"Abweichungen diverser ONNX Modelle zur Referenz {first_key}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fragen (Optional)\n",
        "- Unterscheiden sich die Kurven fÃ¼r INT8/CPU (FP16/CPU) und INT8/GPU (FP16/GPU)? Wieso?\n",
        "- Wie ist das Verhalten der Kurven fÃ¼r die INT8-Modelle (statisch quantisiert) bei $\\pm 10.0$ zu erklÃ¤ren?\n",
        "- Gibt es Unterschiede zwischen den statisch und dynamische quantisierten INT8 Modellen?\n"
      ],
      "metadata": {
        "id": "PBHXjy_NzPci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Messung der Inferenzzeiten fÃ¼r die quantisierten Modelle\n",
        "- Wir variieren die Batch-Size und messen die Laufzeit fÃ¼r jeweils $n$ DurchlÃ¤ufe"
      ],
      "metadata": {
        "id": "5F97gmC9waHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJnVIlNxgqHJ"
      },
      "outputs": [],
      "source": [
        "# measure inference times/latency for different batch sizes\n",
        "\n",
        "batch_sizes = [2**i for i in range(10, 23)]\n",
        "model_dict = {\n",
        "    \"ONNX Regression Model (FP32/CPU)\": reg_model_fp32_cpu.predict,\n",
        "    #\"ONNX Regression Model (FP16/CPU)\": reg_model_fp16_cpu.predict,\n",
        "    #\"ONNX Regression Model (INT8/CPU)\": reg_model_int8_cpu.predict,\n",
        "    \"ONNX Regression Model (FP32/GPU)\": reg_model_fp32_gpu.predict,\n",
        "    \"ONNX Regression Model (FP16/GPU)\": reg_model_fp16_gpu.predict,\n",
        "    \"ONNX Regression Model (INT8/GPU)\": reg_model_int8_gpu.predict,\n",
        "}\n",
        "\n",
        "benchmark_results = benchmark_models_on_batch_size(\n",
        "    model_dict=model_dict,\n",
        "    input_shape=(1,),\n",
        "    batch_sizes=batch_sizes,\n",
        "    n_runs=100,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg8OpUBIgqHJ"
      },
      "outputs": [],
      "source": [
        "plot_benchmark_results(results=benchmark_results, title=\"Laufzeiten der unterschiedlichen quantisierten Modelle\", xscale=\"log\", yscale=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fragen (Optional)\n",
        "- Wie stark ist der Einfluss der Quantisierungen bei diesem Modell auf die Laufzeit?\n",
        "- Wie ist das Laufzeitverhalten des statisch vs. dynamisch quantisierten Modells?"
      ],
      "metadata": {
        "id": "E-_5yC16xqIe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fd481-eMB-R"
      },
      "source": [
        "# ðŸ•¸ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
        "\n",
        "In diesem Teil werden wir uns damit befassen, welche Probleme bei der Modellquantisierung auftreten kÃ¶nnen und dies anhand eines Beispiels illustrieren. Folgende Schritte werden durchgefÃ¼hrt:\n",
        "- Erstellen eines benutzerdefinierten Modells in Keras zur Mittelwertbildung entlang der Zeitachse.\n",
        "- Konvertieren des Keras-Modells in das ONNX-Format.\n",
        "- Quantisieren des ONNX-Modells von FP32 auf FP16.\n",
        "- Generierung von 3-dimensionalen Zeitreihendaten fÃ¼r die Modellinferenz.\n",
        "- Modellinferenz mit dem Keras-Modell.\n",
        "- Modellinferenz mit den FP32/FP16 ONNX-Modellen:\n",
        "  - Laden und AusfÃ¼hren von ONNX-Modellen mit der ONNX Runtime.\n",
        "  - Vergleich der Ausgaben von FP32- und FP16-ONNX-Modellen.\n",
        "- Diskussion der Beobachtungen und mÃ¶glicher LÃ¶sungen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pncih_L8dWVa"
      },
      "source": [
        "## Modelldefinition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya6rTWHfamy3"
      },
      "source": [
        "Unser Modell unten nimmt einen 3-dimensionalen Eingabetensor mit den Dimensionen (Batch-GrÃ¶ÃŸe, SequenzlÃ¤nge, Merkmalsanzahl) entgegen. In unserem Beispiel hat der Eingabetensor die Form (2, 10000, 3), was bedeutet, dass wir zwei Batch-Elemente haben, jedes mit einer SequenzlÃ¤nge von 10000 und 3 Merkmalen pro Zeitschritt.\n",
        "\n",
        "Nach der Verarbeitung durch das Modell wird die Zeitdimension reduziert, und die Ausgabe hat die Form (Batch-GrÃ¶ÃŸe, Merkmalsanzahl). FÃ¼r unser Beispiel ergibt sich eine Ausgabe mit der Form (2, 3). Die Ausgabe reprÃ¤sentiert den Durchschnitt der Merkmale Ã¼ber die gesamte SequenzlÃ¤nge fÃ¼r jedes Batch-Element.\n",
        "\n",
        "**Beispiel (Visuelles Beispiel weiter unten)**\n",
        "\n",
        "Eingabetensor (2 x 4 x 3):\n",
        "```\n",
        "[\n",
        "  [\n",
        "    [3, 4, 5],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "  ],\n",
        "  [\n",
        "    [2, 4, 6],\n",
        "    [8, 10, 12],\n",
        "    [14, 16, 18],\n",
        "    [20, 22, 24]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "Ausgabetensor (2 x 3):\n",
        "```\n",
        "[\n",
        "  [ 6,  7,  8],\n",
        "  [11, 13, 15]\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBhX8Vul3feC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Layer\n",
        "\n",
        "\n",
        "class SumLayer(Layer):\n",
        "    \"\"\"Custom Layer to sum over time dimension of a tensor.\"\"\"\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"Reduce (sum) the input tensor along the time axis (axis=1).\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): The input tensor of shape (batch_size, sequence_length, feature_dim).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The reduced tensor of shape (batch_size, feature_dim).\n",
        "        \"\"\"\n",
        "        return tf.reduce_sum(inputs, axis=1)\n",
        "\n",
        "\n",
        "# Custom Layer: Division by sequence length\n",
        "class DivisionLayer(Layer):\n",
        "    \"\"\"Divide a tensor by the length of the given sequence.\"\"\"\n",
        "\n",
        "    def call(self, inputs: tuple[tf.Tensor, tf.Tensor]) -> tf.Tensor:\n",
        "        \"\"\"Divide the summed tensor by the sequence length to get the average.\n",
        "\n",
        "        Args:\n",
        "            inputs (Tuple[tf.Tensor, tf.Tensor]): A tuple containing the summed tensor and the original input tensor.\n",
        "                - tensor_x (tf.Tensor): The summed tensor of shape (batch_size, feature_dim).\n",
        "                - original_input (tf.Tensor): The original input tensor of shape (batch_size, sequence_length, feature_dim).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The averaged tensor of shape (batch_size, feature_dim).\n",
        "        \"\"\"\n",
        "        tensor_x, original_input = inputs\n",
        "        seq_length = tf.shape(original_input)[\n",
        "            1\n",
        "        ]  # Get the dynamic sequence length (length of the time dimension)\n",
        "        return tensor_x / tf.cast(seq_length, dtype=tensor_x.dtype)\n",
        "\n",
        "\n",
        "# Define model with separate Sum and Division layers\n",
        "def global_average_pooling_1d() -> Model:\n",
        "    \"\"\"Define a Keras model with separate Sum and Division layers for global average pooling.\n",
        "\n",
        "    Returns:\n",
        "        Model: A Keras model that performs global average pooling over the time dimension.\n",
        "    \"\"\"\n",
        "    inputs = Input(\n",
        "        shape=(None, 3), name=\"input\"\n",
        "    )  # Define the input layer with shape (sequence_length=None, feature_dim=3)\n",
        "    sum_x = SumLayer(name=\"sum\")(inputs)  # Apply the SumLayer to the inputs\n",
        "    output = DivisionLayer(name=\"divide\")([\n",
        "        sum_x,\n",
        "        inputs,\n",
        "    ])  # Apply the DivisionLayer to the summed tensor and the original inputs\n",
        "    return Model(\n",
        "        inputs, output, name=\"GlobalAveragePooling1D\"\n",
        "    )  # Create the Keras model with the specified input and output\n",
        "\n",
        "\n",
        "# Create the model\n",
        "model = global_average_pooling_1d()\n",
        "\n",
        "# Print model summary to see the architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beispiel"
      ],
      "metadata": {
        "id": "eix_OlBl-Nmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample data\n",
        "batch_size = 2\n",
        "sequence_length = 5\n",
        "feature_dim = 3\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.rand(batch_size, sequence_length, feature_dim).astype(np.float32).round(1)\n",
        "print(f\"Input {str(sample_data.shape).replace(',', ' x')}:\\n\", sample_data)\n",
        "\n",
        "# Pass data through the model\n",
        "output_data = model.predict(sample_data, verbose=0)\n",
        "\n",
        "# Print the output\n",
        "print(f\"\\nOutput {str(output_data.shape).replace(',', ' x')}:\\n\", output_data)"
      ],
      "metadata": {
        "id": "IoVsJOuP5j7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualisierung der obigen Beispieldaten {display-mode: \"form\"}\n",
        "\n",
        "# Visualize the input and output\n",
        "def plot_data(input_data, output_data):\n",
        "    batch_size, sequence_length, feature_dim = input_data.shape\n",
        "    gap_size = 1  # Size of the gap between rows and columns\n",
        "    total_cols = sequence_length + 1 + gap_size  # Include gap for output column\n",
        "    total_rows = feature_dim + gap_size  # Include gap between rows\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=batch_size, ncols=1, figsize=(9, 3 * batch_size))\n",
        "\n",
        "    if batch_size == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        ax = axes[i]\n",
        "        data_with_output = np.full((feature_dim, total_cols), np.nan)  # Initialize with NaNs for gaps\n",
        "        data_with_output[:, :sequence_length] = input_data[i].T  # Fill input data (transpose to match dimensions)\n",
        "        data_with_output[:, sequence_length + gap_size] = output_data[i]  # Fill output data\n",
        "\n",
        "        cax = ax.matshow(data_with_output, cmap='Blues', vmin=0, vmax=1)\n",
        "\n",
        "        for (j, k), val in np.ndenumerate(data_with_output):\n",
        "            if not np.isnan(val):\n",
        "                ax.text(k, j, f'{val:.2f}', ha='center', va='center', color='black')\n",
        "\n",
        "        ax.set_xticks(np.arange(total_cols))\n",
        "        ax.set_xticklabels([f'$t_{t}$' for t in range(sequence_length)] + [''] * gap_size + ['Modell-Output'])\n",
        "        ax.set_yticks(np.arange(feature_dim))\n",
        "        ax.set_yticklabels([f'Kanal {f}' for f in range(feature_dim)])\n",
        "        ax.set_title(f'Signal {i+1}')\n",
        "\n",
        "        # Remove tick lines and surrounding border\n",
        "        ax.tick_params(axis='both', which='both', length=0)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_data(sample_data, output_data)"
      ],
      "metadata": {
        "id": "D2PXtb-z98pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_5U6zHgR-_"
      },
      "source": [
        "## Modellkonvertierung nach ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-9pMzIv6oUY"
      },
      "outputs": [],
      "source": [
        "# Convert our GlobalAveragePooling1D Model to ONNX format\n",
        "import onnx  # ONNX library for handling ONNX models\n",
        "import tf2onnx  # TensorFlow to ONNX conversion library\n",
        "from onnxconverter_common import float16  # Utility for FP16 conversion\n",
        "\n",
        "# Define the path where the FP32 ONNX model will be saved\n",
        "onnx_model_path_fp32 = \"gap1d_model_fp32.onnx\"\n",
        "\n",
        "# Convert the Keras model to ONNX format with FP32 precision\n",
        "# Define the input specification for the model conversion\n",
        "spec = (tf.TensorSpec((None, None, 3), tf.float32, name=\"input\"),)\n",
        "# Convert the Keras model to ONNX using tf2onnx\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=18)\n",
        "\n",
        "# Save the converted FP32 ONNX model to the specified path\n",
        "onnx.save(onnx_model, onnx_model_path_fp32)\n",
        "print(f\"ONNX model (FP32) saved to {onnx_model_path_fp32}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdLdCuQBgaLi"
      },
      "source": [
        "## Quantisierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8A1tP9V679a"
      },
      "outputs": [],
      "source": [
        "# Now quantize the ONNX model to FP16 and save it\n",
        "\n",
        "# Load the previously saved FP32 ONNX model\n",
        "onnx_model_fp32 = onnx.load(onnx_model_path_fp32)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(onnx_model_fp32, keep_io_types=True)\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_path_fp16 = \"gap1d_model_fp16.onnx\"\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_path_fp16)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_path_fp16}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7m2fr58kMm"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"gap1d_model_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R_B8RE7ggas"
      },
      "source": [
        "## Datengenerierung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PORbJXNx4yav"
      },
      "outputs": [],
      "source": [
        "# First create some data and put it through the Keras model\n",
        "import matplotlib.pyplot as plt  # Library for plotting\n",
        "import numpy as np  # Library for numerical operations\n",
        "\n",
        "# Create a random input tensor with a batch size of 2\n",
        "# Generate a sequence of numbers from 0 to 9999 and reshape it to (1, 10000, 1)\n",
        "tt = np.arange(10_000).reshape(1, -1, 1)\n",
        "\n",
        "# Create an offset array and reverse it\n",
        "off = (np.array(np.arange(6)).astype(np.float32) + 4)[::-1]\n",
        "\n",
        "# Generate a 3-dimensional time series data using a sine function with the offset\n",
        "xx = 0.4 * np.sin(4 * np.pi * 1e-5 * off**2 * tt) + off\n",
        "\n",
        "# Reshape the data to have dimensions (sequence_length, batch_size, feature_dim)\n",
        "xx = xx.reshape(-1, 2, 3)\n",
        "\n",
        "# Swap the axes to get the shape (batch_size, sequence_length, feature_dim)\n",
        "xx = np.swapaxes(xx, 0, 1)\n",
        "\n",
        "# Convert the data to float32 type\n",
        "x_input = xx.astype(np.float32)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensions of the input tensor:\", x_input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGQTVao-GYZM"
      },
      "outputs": [],
      "source": [
        "# Plot the generated time series data\n",
        "import matplotlib.pyplot as plt  # Library for plotting (re-imported for completeness)\n",
        "\n",
        "# Create a new figure with a specified size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the first batch (b$_1$) of the time series data\n",
        "plt.plot(xx[0, :, :], label=\"b$_1$\")\n",
        "\n",
        "# Plot the second batch (b$_2$) of the time series data\n",
        "plt.plot(xx[1, :, :], label=\"b$_2$\")\n",
        "\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"t\")\n",
        "\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"Amplitude\")\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Ein Batch bestehend aus jeweils zwei 3-dimensionalen Zeitreihen\")\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(1.1, 0.6), ncol=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRHQY_j_gzEj"
      },
      "source": [
        "## Inferenz mit dem Keras Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9EP5mXQ-Ln2"
      },
      "outputs": [],
      "source": [
        "# Put the data through the Keras model\n",
        "\n",
        "# Use the Keras model to make predictions on the input data\n",
        "y_output_keras = model.predict(x_input, verbose=0)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensionen des Eingabetensors:\", str(x_input.shape).replace(',', \" x\"))  # Erwartete Form: (2, 10000, 3)\n",
        "\n",
        "# Print the dimensions of the Keras model output\n",
        "print(\n",
        "    \"Dimensionen der Keras-Modellausgabe:\", str(y_output_keras.shape).replace(',', \" x\")\n",
        ")  # expected shape: (2, 3) -> reduced time axis!\n",
        "\n",
        "# Print the output of the Keras model\n",
        "print(\"\\nKeras-Modellausgabe:\\n\", y_output_keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq_N1o4Sg7p9"
      },
      "source": [
        "## Inferenz mit den FP32/FP16 ONNX Modellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8LdB2clSPgQ"
      },
      "outputs": [],
      "source": [
        "# Run the FP32 ONNX model\n",
        "y_output_onnx_fp32 = OnnxModel(onnx_model_path=\"gap1d_model_fp32.onnx\").predict(x_input)\n",
        "\n",
        "# Print the output of the FP32 ONNX model\n",
        "print(\"\\nONNX (FP32) Modellausgabe:\\n\", y_output_onnx_fp32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8wCn4znSZ_s"
      },
      "outputs": [],
      "source": [
        "# Run the FP16 ONNX model\n",
        "y_output_onnx_fp16 = OnnxModel(onnx_model_path=\"gap1d_model_fp16.onnx\").predict(x_input)\n",
        "\n",
        "# Print the output of the FP32 ONNX model\n",
        "print(\"\\nONNX (FP16) Modellausgabe:\\n\", y_output_onnx_fp16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsQD-7RzO2Ao"
      },
      "source": [
        "## Fragen / Diskussion\n",
        "- Welche Ergebnisse erwarten wir? Stimmen die Ergebnisse mit den Erwartungen Ã¼berein?\n",
        "- Was fÃ¤llt bei der Ausgabe des quantisierten FP16 Modells auf?\n",
        "  - Wie kÃ¶nnte man sich dieses Ergebnis erklÃ¤ren?\n",
        "  - LÃ¤sst sich das Problem ggfs. vermeiden?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5i-XeVZVVy7"
      },
      "source": [
        "# ðŸ“ž Teil 4: Quantisierung eines DTMF Klassifikationsmodells"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Unbenannt.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "xwGUBX9CHGGe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG6JRjlfVVy7"
      },
      "source": [
        "## EinfÃ¼hrung: Generierung und Dekodierung/Klassifizierung von DTMF (dual-tone multi-frequency) Signalen <a class=\"anchor\" id=\"part0\"></a>\n",
        "\n",
        "\n",
        "Das Dualton-Mehrfrequenzwahlverfahren (DTMF) ist ein Signalisierungssystem fÃ¼r das WÃ¤hlen eines Telefons, das in den frÃ¼hen 1960er Jahren von Western Electric entwickelt und spÃ¤ter von Bell System kommerziell an Telefonkunden geliefert wurde.\n",
        "Wenn eine Taste auf dem Telefon gedrÃ¼ckt wird, werden zwei harmonische Tonsignale erzeugt, und die Superposition/Ãœberlagerung beider Signale wird verwendet, um die entsprechende Telefontaste zu charakterisieren. Wenn zum Beispiel die Taste â€ž5â€œ gedrÃ¼ckt wird, entsteht ein Dualtontonsignal, das sich aus den Frequenzen 770 Hz und 1336 Hz zusammensetzt. Die beiden Frequenzen, die jede Taste beschreiben, sind in der folgenden Tabelle aufgefÃ¼hrt:\n",
        "\n",
        "|   | 1209Hz  | 1336 Hz  | 1477 Hz   | 1633 Hz  |\n",
        "|---|:---:|:---:|:---:|:---:|\n",
        "| **697 Hz**  |  1 | 2  | 3  | A  |\n",
        "| **770 Hz**  |  4 | 5  | 6  | B  |\n",
        "| **852 Hz**  |  7 | 8  | 9  | C  |\n",
        "| **941 Hz**  |  * | 0  | #  | D  |\n",
        "\n",
        "In diesem Beispiel werden wir uns ansehen, wie man solche DTMF-WÃ¤hlsequenzen generiert, sie in einer Audiodatei speichert und das Audiosignal mit einem einfachen KI-Modell wieder dekodiert.\n",
        "\n",
        "Wir werden die folgenden Schritte durchfÃ¼hren, um ein DTMF-Signal zu erzeugen und mit einem Klassifikationsmodell zu dekodieren:\n",
        "1. Erzeugung des Signals und der Audiodatei mit `scipy` und `numpy`. Wir speichern die erzeugte Audiodatei in einer `.wav` Datei, die in diesem Notebook oder in deinem lokalen Audioplayer abgespielt werden kann\n",
        "2. Wir laden eine einfaches KI-Modell, das die Klassifizierung der Tonsignale vornehmen kann\n",
        "3. Extraktion der gewÃ¤hlten Tastenfolge aus der `.wav`-Datei unter Verwendung des KI-Modells\n",
        "4. Quantisierung & Export des Modells nach ONNX im FP32 und FP16 Format. Quantisierung nach INT8 und Export nach TensorRT.\n",
        "5. Laufzeituntersuchungen fÃ¼r FP32/FP16/INT8, unterschiedliche Batch-GrÃ¶ÃŸen und SignallÃ¤ngen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXOs32MVVy7"
      },
      "outputs": [],
      "source": [
        "# TODOs:\n",
        "# Profiling in ONNX/TRT\n",
        "# We need to add the DTMF model artifacts to the assets\n",
        "# We need a TRT model which supports longer sequences for the accuracy!!!\n",
        "# Analysis in Frequency Domain\n",
        "# [x] Try to use ONNX INT8-model for TF\n",
        "# [x] Run an already quantized ONNX model in TRT without setting any Flag like INT8/FP16\n",
        "# [x] Look at results of quantized INT8 ONNX model for DTMF\n",
        "# [x] QAT of Tensorflow -> tf2onnx -> ORT/TRT\n",
        "# Hinweis Laufzeit neu starten in rot\n",
        "# Numerierung der Abschnitte\n",
        "# Merge to master branch and change installation instructions in notebooks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51a6fcd-760a-4926-8d68-7f75eddb906a"
      },
      "source": [
        "## Signal- und Audiodatei-Generierung <a class=\"anchor\" id=\"part1\"></a>\n",
        "- Im folgendem Widget ist es mÃ¶glich, eine Nummer zu wÃ¤hlen, fÃ¼r die ein DTMF-Signal generiert werden soll\n",
        "- Falls im Widget keine Nummer \"gewÃ¤hlt\" wird, wird eine Default-Sequenz angenommen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9360855-39ba-450f-975b-ebd7f48a5521"
      },
      "outputs": [],
      "source": [
        "# First import the necessary libs\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kR8O3oWRKR"
      },
      "outputs": [],
      "source": [
        "# @title Tastenfeld-Widget fÃ¼r Generierung der WÃ¤hlsequenz' {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize a text widget to display the dial sequence\n",
        "dial_sequence = widgets.Text(\n",
        "    value=\"\",\n",
        "    placeholder=\"Dial sequence will appear here...\",\n",
        "    description=\"\",\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width=\"300px\"),\n",
        ")\n",
        "\n",
        "\n",
        "# Function to handle button clicks\n",
        "def on_button_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    dial_sequence.value += b.description\n",
        "\n",
        "\n",
        "# Create buttons for the phone dialer\n",
        "buttons = []\n",
        "for row in [\n",
        "    [\"1\", \"2\", \"3\", \"A\"],\n",
        "    [\"4\", \"5\", \"6\", \"B\"],\n",
        "    [\"7\", \"8\", \"9\", \"C\"],\n",
        "    [\"*\", \"0\", \"#\", \"D\"],\n",
        "]:\n",
        "    button_row = []\n",
        "    for label in row:\n",
        "        button = widgets.Button(\n",
        "            description=label, layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        "        )\n",
        "        button.on_click(on_button_click)\n",
        "        button_row.append(button)\n",
        "    buttons.append(widgets.HBox(button_row))\n",
        "\n",
        "# Create a clear button\n",
        "clear_button = widgets.Button(\n",
        "    description=\"Clear\", layout=widgets.Layout(width=\"158px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "back_button = widgets.Button(\n",
        "    description=\"â¬…\", layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "\n",
        "def on_clear_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = \"\"\n",
        "\n",
        "\n",
        "def on_back_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = dial_sequence.value[:-1]\n",
        "\n",
        "\n",
        "clear_button.on_click(on_clear_click)\n",
        "\n",
        "\n",
        "back_button.on_click(on_back_click)\n",
        "\n",
        "# Display the dialer\n",
        "display(dial_sequence)\n",
        "for button_row in buttons:\n",
        "    display(button_row)\n",
        "display(widgets.HBox([clear_button, back_button]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V728NfPmsAQr"
      },
      "outputs": [],
      "source": [
        "print(\"GewÃ¤hlte Sequenz:\", dial_sequence.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8i2MsZF3o0g"
      },
      "source": [
        "### Generierung des WÃ¤hl-Audiosignals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAyM34wYqx_A"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    # length (randomly sampled in given range, or scalar) of the key signals (in seconds):\n",
        "    dur_key=(0.2, 0.3),\n",
        "\n",
        "    # length (randomly sampled in given range, or scalar) of the pauses (in seconds):\n",
        "    dur_pause=(0.01, 0.1),\n",
        "\n",
        "    # You can vary the noise level here (sampled from given range, or scalar value):\n",
        "    noise_factor=(20.0, 60.0),\n",
        "\n",
        "    # Frequency range (in Hz) to produce noise:\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62132ef1-c61f-4653-9f6c-a4d9f892781e"
      },
      "outputs": [],
      "source": [
        "# Either use the dialed sequence from above:\n",
        "my_dialed_sequence_keys = dial_sequence.value\n",
        "\n",
        "# ... or generate a random sequence:\n",
        "# my_dialed_sequence_keys = \"\".join([random.choice(\"1234567890ABCD*#\") for i in range(10)])\n",
        "\n",
        "# ... or use a simple sequence for debugging purposes\n",
        "# my_dialed_sequence_keys = \"1234567890ABCD*#\" # for debug purposes...\n",
        "\n",
        "# ... or use a slightly longer sequence (which also contains all symbols)\n",
        "# my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "if not my_dialed_sequence_keys:\n",
        "    my_dialed_sequence_keys = \"9128A08C16*C#547D3B\"\n",
        "\n",
        "# Try changing the following arguments: dur_key=0.05, dur_pause=0.02\n",
        "my_dialed_sequence_signal = dtmf_gen.get_tone_sequence(my_dialed_sequence_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-9x6ncx3wiD"
      },
      "source": [
        "### Visualisierung des Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aarMEIq3vS0m"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Das vollstÃ¤ndige gewÃ¤hlte Signal\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWiuyJ_7BUS6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal[: 10**4])\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Die ersten 10000 Datenpunkte des gewÃ¤hlten Signals\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJe9QX8Ee9aA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "quant = np.quantile(my_dialed_sequence_signal, 0.99)\n",
        "start_index = np.where(my_dialed_sequence_signal > quant)[0][10]\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Weiterer Zoom-In\")\n",
        "plt.xlim(start_index, start_index + 1.5 * 10**3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42af11c2-3c15-4a57-afa8-f62b8e82925d"
      },
      "outputs": [],
      "source": [
        "# Now let us listen to the generated WAV file\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "wav_file_name = \"my_dtmf_file.wav\"\n",
        "\n",
        "wavfile.write(\n",
        "    wav_file_name,\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (my_dialed_sequence_signal * np.iinfo(np.int32).max).astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(wav_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51a52767-7e0e-444f-8028-f5a52fce4820"
      },
      "outputs": [],
      "source": [
        "print(\"GewÃ¤hlte Sequenz: \", my_dialed_sequence_keys)\n",
        "print(\"Anzahl verwendeter Zeichen: \", len(set(my_dialed_sequence_keys)))\n",
        "print(\"GesamtlÃ¤nge des Signals:\", my_dialed_sequence_signal.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b763fef4-360e-4a01-910b-add573007fd3"
      },
      "source": [
        "### Signal-Spektrogramm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7827a985-0dd0-40c0-993c-e002523ef0e9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "Pxx, freqs, bins, im = plt.specgram(\n",
        "    my_dialed_sequence_signal, NFFT=1024, Fs=dtmf_gen.get_sample_rate()\n",
        ")\n",
        "plt.ylim(0, 2000)\n",
        "plt.xlabel(\"t [s]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "plt.title(\"Spektrogramm des generierten TelefonwÃ¤hlsignals\")\n",
        "plt.show(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aio7fvyo4ZUy"
      },
      "source": [
        "## Laden & Konvertierung des vortrainierten Keras Modells\n",
        "\n",
        "Optionale Fragen:\n",
        "- Wie kÃ¶nnte man mit einem klassischen Ansatz oder auch mit einem neuronalem Netz die WÃ¤hlsequenz extrahieren?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHys5X74cRB"
      },
      "source": [
        "### Laden des vortrainierten Keras Modells\n",
        "\n",
        "- Wir verwenden ein vortrainiertes Netz um uns die Trainingszeit zu ersparen\n",
        "- Das Training kann weiter unten reproduziert werden\n",
        "- Modellarchitektur:\n",
        "  - Im Wesentlichen ein sogenenanntes Conv-Net (Fully Convolutional Net, FCN)\n",
        "  - Einige Downsampling layer (MaxPooling) und Upsampling layer\n",
        "  - Input: Ein Batch mit der Dimension N x T x 1, wobei N die Batch-GrÃ¶ÃŸe und T die LÃ¤nge der Signale darstellt.\n",
        "  - Output: N x T x 17, wobei wir nun 16+1=17 Ausgabesignale haben, ein Signal pro Taste (0,1,2,...,*,#,A,B,C,D) und 1 Signal fÃ¼r \"keine Taste aktiv\"\n",
        "  - Output-Schicht: \"Softmax\" layer. Bedeutet, dass jedes Element in einem 17-dim. Vektor eine Wahrscheinlichkeit darstellt und dass die Summe Ã¼ber jeden 17-dim. Vektor genau 1 ergibt.\n",
        "\n",
        "\n",
        "Optionale Fragen:\n",
        "- Gibt es andere/elegantere MÃ¶glichkeiten um insbesondere ein brauchbares Output zu erzeugen (anstatt eines N x T x 17 Signals)?\n",
        "\n",
        "TODO: EinfÃ¼hrung: Was ist die Eingabe/Ausgabe des Modells\n",
        "Was ist das fÃ¼r ein Modell, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4Tks3yH0ipe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "keras_model = tf.keras.models.load_model(\"dtmf_classifier.keras\") # TODO: load from assets\n",
        "keras_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize using Keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Plot the model graph and save to a temporary file\n",
        "plot_model(keras_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, dpi=60)\n",
        "\n",
        "# Display the plot inline\n",
        "display(Image('model_plot.png'))"
      ],
      "metadata": {
        "id": "krT-bqjRHk0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesc3J6SUBOv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "length = my_dialed_sequence_signal.size\n",
        "keras_pred = keras_model.predict(my_dialed_sequence_signal[:(length//8)*8].reshape(1, -1, 1), verbose=0)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Inferenzzeit:\", round(end - start, 2), \"Sekunden\")\n",
        "\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "\n",
        "for key_idx in range(keras_pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        keras_pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8, title=\"Prognostizierte Tasten\")\n",
        "plt.title(f\"TatsÃ¤chliche WÃ¤hlsequenz: {' '.join(list(my_dialed_sequence_keys))}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_zpgnG6CviY"
      },
      "outputs": [],
      "source": [
        "predicted_key_sequence = dtmf_gen.decode_prediction(keras_pred)\n",
        "print(\"Prognostizierte WÃ¤hlsequenz:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tatsÃ¤chlich gewÃ¤hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-97qYaeo4k86"
      },
      "source": [
        "### Konvertierung des Keras Modells nach ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0niGbjMEhna"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "import tensorflow as tf\n",
        "\n",
        "# This line sets the output names for the Keras model.\n",
        "# It might throw an error, but the ONNX model should still be exported correctly.\n",
        "keras_model.output_names = [\"output\"]\n",
        "\n",
        "# Define the input signature for the model.\n",
        "# This specifies the shape and type of the input tensor.\n",
        "# 'None' in the shape indicates a variable dimension, meaning the model can accept inputs of varying sizes.\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, None, 1], tf.float32, name=\"input\")\n",
        "]\n",
        "\n",
        "# Convert the Keras model to an ONNX model using the specified input signature and opset version.\n",
        "# The opset version defines the set of operations available in the ONNX model.\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(keras_model, input_signature, opset=18)\n",
        "\n",
        "# Save the converted ONNX model to a file.\n",
        "onnx.save(onnx_model, \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-CLAhtx4tTw"
      },
      "source": [
        "### Optimierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5PAAutNg2bE"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import onnxsim\n",
        "\n",
        "# Define the path to the original ONNX model\n",
        "model_path = \"dtmf_classifier.onnx\"\n",
        "\n",
        "# Define the path where the simplified ONNX model will be saved\n",
        "simplified_model_path = \"dtmf_classifier.onnx\"\n",
        "\n",
        "# Load the original ONNX model from the specified file\n",
        "onnx_model = onnx.load(model_path)\n",
        "\n",
        "# Check the model to ensure it is well-formed and valid according to ONNX standards\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# Simplify the ONNX model to make it more efficient and easier to understand\n",
        "onnx_model_simp, check = onnxsim.simplify(onnx_model)\n",
        "\n",
        "# Ensure that the simplified model is valid\n",
        "assert check, \"Simplified ONNX model could not be validated\"\n",
        "\n",
        "# Save the simplified ONNX model to the specified file\n",
        "onnx.save(onnx_model_simp, simplified_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9OUrzZa-bgt"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0s4ULT84ynC"
      },
      "source": [
        "### FP16 Quantisierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOwr_prgiN4"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "onnx_model = onnx.load(\"dtmf_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    onnx_model,\n",
        "    min_positive_val=1e-7,\n",
        "    max_finite_val=1e4,\n",
        "    keep_io_types=True,\n",
        "    disable_shape_infer=False,\n",
        "    op_block_list=None,\n",
        "    node_block_list=None,\n",
        ")\n",
        "onnx.save(onnx_model_fp16, \"dtmf_classifier_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INT8 Quantisierung des ONNX Modells\n",
        "- dynamische INT8 Quantisierung derzeit nicht mÃ¶glich, da die ONNX Runtime dynamisch-quantisierte Conv1D Layer aktuell nicht unterstÃ¼tzt\n",
        "- statische INT8 Quantisierung in ONNX funktioniert, jedoch sind keine Laufzeitvorteile in der ONNX Runtime gegenÃ¼ber des FP32 Modells erkennbar (Code in Anhang)\n",
        "- Auch keine Laufzeitverbesserung mit QAT in TensorFlow und Export nach INT8 ONNX Modell (Code in Anhang)\n",
        "- **Daher**: Verwendung von INT8 Quantisierung in Nvidia TensorRT"
      ],
      "metadata": {
        "id": "8-Q48XtarK-2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGuwxgoDkgGv"
      },
      "source": [
        "### TensorRT Tests\n",
        "\n",
        "TODO: Move below code to .py files and import!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSJVcrVW6gPw"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.04, 0.05),\n",
        "    dur_pause=(0.03, 0.04),\n",
        "    noise_factor=(0.0, 60.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3of1tuYcNrC"
      },
      "outputs": [],
      "source": [
        "def get_gpu_type() -> str:\n",
        "    \"\"\"Get the type of GPU available on the system.\n",
        "\n",
        "    This function checks if a CUDA-capable GPU is available using PyTorch.\n",
        "    If a GPU is available, it returns the name of the GPU in lowercase with spaces replaced by underscores.\n",
        "    If no GPU is available, it returns 'cpu'.\n",
        "\n",
        "    Returns:\n",
        "        str: The type of GPU available or 'cpu' if no GPU is available.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        return \"cpu\"\n",
        "    return \"_\".join(torch.cuda.get_device_name(0).lower().split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5sW5xE4y3Yf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "from cuda import cuda, cudart\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def check_cuda_err(err: cuda.CUresult | cudart.cudaError_t) -> None:\n",
        "    \"\"\"Check for CUDA errors and raise an exception if an error is found.\n",
        "\n",
        "    Args:\n",
        "        err (Union[cuda.CUresult, cudart.cudaError_t]): The CUDA error code.\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: If a CUDA error is detected.\n",
        "    \"\"\"\n",
        "    if isinstance(err, cuda.CUresult) and err != cuda.CUresult.CUDA_SUCCESS:\n",
        "        raise RuntimeError(f\"Cuda Error: {err}\")\n",
        "    if isinstance(err, cudart.cudaError_t):\n",
        "        if err != cudart.cudaError_t.cudaSuccess:\n",
        "            raise RuntimeError(f\"Cuda Runtime Error: {err}\")\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown error type: {err}\")\n",
        "\n",
        "\n",
        "def cuda_call(call: Any) -> Any:\n",
        "    \"\"\"Make a CUDA call and check for errors.\n",
        "\n",
        "    Args:\n",
        "        call (Any): The CUDA call to make.\n",
        "\n",
        "    Returns:\n",
        "        Any: The result of the CUDA call.\n",
        "    \"\"\"\n",
        "    err, res = call[0], call[1:]\n",
        "    check_cuda_err(err)\n",
        "    if len(res) == 1:\n",
        "        res = res[0]\n",
        "    return res\n",
        "\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_host_to_device(device_ptr: int, host_arr: np.ndarray) -> None:\n",
        "    \"\"\"Copy data from host to device.\n",
        "\n",
        "    Args:\n",
        "        device_ptr (int): The device pointer.\n",
        "        host_arr (np.ndarray): The host array.\n",
        "    \"\"\"\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(\n",
        "        cudart.cudaMemcpy(\n",
        "            device_ptr, host_arr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_device_to_host(host_arr: np.ndarray, device_ptr: int) -> None:\n",
        "    \"\"\"Copy data from device to host.\n",
        "\n",
        "    Args:\n",
        "        host_arr (np.ndarray): The host array.\n",
        "        device_ptr (int): The device pointer.\n",
        "    \"\"\"\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(\n",
        "        cudart.cudaMemcpy(\n",
        "            host_arr, device_ptr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "class MNISTEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    \"\"\"INT8 calibrator for our DTMF classifier model.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, training_data: str, cache_file: str, batch_size: int = 16\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the MNISTEntropyCalibrator.\n",
        "\n",
        "        Args:\n",
        "            training_data (str): The path to the training data.\n",
        "            cache_file (str): The path to the cache file.\n",
        "            batch_size (int, optional): The batch size. Defaults to 16.\n",
        "        \"\"\"\n",
        "        # Whenever you specify a custom constructor for a TensorRT class,\n",
        "        # you MUST call the constructor of the parent explicitly.\n",
        "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
        "\n",
        "        self.cache_file = cache_file\n",
        "\n",
        "        # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n",
        "        # self.data = 2 * np.random.rand(32*batch_size, 2**12, 1).astype(np.float32) - 1.0\n",
        "        # self.data = training_data\n",
        "        self.data = dtmf_gen.generate_dataset(\n",
        "            n_samples=32 * batch_size, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        # print(self.data.dtype)\n",
        "        # self.data = self.data.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "        self.current_index = 0\n",
        "\n",
        "        # Allocate enough memory for a whole batch.\n",
        "        # self.device_input = cuda.mem_alloc(self.data[0].nbytes * self.batch_size)\n",
        "        n_bytes = self.data[0].nbytes * self.batch_size\n",
        "        # print(\"n_bytes\", n_bytes)\n",
        "        self.device_input = cuda_call(cudart.cudaMalloc(n_bytes))\n",
        "\n",
        "    def get_batch_size(self) -> int:\n",
        "        \"\"\"Get the batch size.\n",
        "\n",
        "        Returns:\n",
        "            int: The batch size.\n",
        "        \"\"\"\n",
        "        return self.batch_size\n",
        "\n",
        "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
        "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
        "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
        "    def get_batch(self, names: list[str]) -> list[int] | None:\n",
        "        \"\"\"Get a batch of data.\n",
        "\n",
        "        Args:\n",
        "            names (List[str]): The names of the engine bindings.\n",
        "\n",
        "        Returns:\n",
        "            Optional[List[int]]: The device input pointer, or None if there is no more data.\n",
        "        \"\"\"\n",
        "        # print(\"names:\", names)\n",
        "        if self.current_index + self.batch_size > self.data.shape[0]:\n",
        "            return None\n",
        "\n",
        "        current_batch = int(self.current_index / self.batch_size)\n",
        "        if current_batch % 10 == 0:\n",
        "            print(\n",
        "                f\"Calibrating batch {current_batch}, containing {self.batch_size} images\"\n",
        "            )\n",
        "\n",
        "        batch = self.data[\n",
        "            self.current_index : self.current_index + self.batch_size\n",
        "        ].ravel()\n",
        "        # cuda.memcpy_htod(self.device_input, batch)\n",
        "        # memcpy_host_to_device(self.device_input, batch)\n",
        "        memcpy_host_to_device(self.device_input, np.ascontiguousarray(batch))\n",
        "        self.current_index += self.batch_size\n",
        "        # print(\"Schalom!\")\n",
        "        return [int(self.device_input)]\n",
        "\n",
        "    def read_calibration_cache(self) -> bytes | None:\n",
        "        \"\"\"Read the calibration cache.\n",
        "\n",
        "        Returns:\n",
        "            Optional[bytes]: The calibration cache, or None if it does not exist.\n",
        "        \"\"\"\n",
        "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
        "        if Path.exists(self.cache_file):\n",
        "            return Path(self.cache_file).read_bytes()\n",
        "        return None\n",
        "\n",
        "    def write_calibration_cache(self, cache: bytes) -> None:\n",
        "        \"\"\"Write the calibration cache.\n",
        "\n",
        "        Args:\n",
        "            cache (bytes): The calibration cache.\n",
        "        \"\"\"\n",
        "        return  # for now\n",
        "        Path(self.cache_file).write_bytes(cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6k2njAel4z6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import tensorrt as trt\n",
        "\n",
        "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
        "TRT_LOGGER: trt.Logger = trt.Logger(trt.Logger.VERBOSE)\n",
        "\n",
        "\n",
        "def build_engine_onnx(\n",
        "    model_file: str, trt_engine_path: str, precision: str\n",
        ") -> None:\n",
        "    \"\"\"Builds a TensorRT engine from an ONNX model file.\n",
        "\n",
        "    Args:\n",
        "        model_file (str): The path to the ONNX model file.\n",
        "        trt_engine_path (str): The path to save the TensorRT engine.\n",
        "        precision (str): The precision mode to use ('fp16', 'int8', 'mixed').\n",
        "\n",
        "    Returns:\n",
        "        Optional[None]: Returns None if the engine creation fails.\n",
        "    \"\"\"\n",
        "    seq_len: int = 2**12\n",
        "    max_batch_size: list[int] = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
        "    calibration_batch_size: int = 16\n",
        "    builder: trt.Builder = trt.Builder(TRT_LOGGER)\n",
        "    network: trt.INetworkDefinition = builder.create_network(0)\n",
        "    config: trt.IBuilderConfig = builder.create_builder_config()\n",
        "    parser: trt.OnnxParser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "    config.set_memory_pool_limit(\n",
        "        trt.MemoryPoolType.WORKSPACE, 8 * 1 << 30\n",
        "    )  # TODO: Constant\n",
        "\n",
        "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "    if not parser.parse(Path(model_file).read_bytes()):\n",
        "        print(\"ERROR: Failed to parse the ONNX file.\")\n",
        "        for error in range(parser.num_errors):\n",
        "            print(parser.get_error(error))\n",
        "        return\n",
        "\n",
        "    for b in max_batch_size:\n",
        "        profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
        "        profile.set_shape(\"input\", [b//2 + 1, seq_len, 1], [b, seq_len, 1], [b, seq_len, 1])\n",
        "        config.add_optimization_profile(profile)\n",
        "\n",
        "    if precision in [\"fp16\", \"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_fp16:\n",
        "            print(\"FP16 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.FP16)\n",
        "    if precision in [\"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_int8:\n",
        "            print(\"INT8 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.INT8)\n",
        "        # config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "\n",
        "        calib = MNISTEntropyCalibrator(\n",
        "            \"\", cache_file=\"cache.file\", batch_size=calibration_batch_size\n",
        "        )\n",
        "        config.int8_calibrator = calib\n",
        "\n",
        "        calib_profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
        "        calib_profile.set_shape(\n",
        "            \"input\",\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "        )\n",
        "        config.set_calibration_profile(calib_profile)\n",
        "        config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
        "\n",
        "        print(\"int 8 model\")\n",
        "\n",
        "    engine_bytes: bytes | None = builder.build_serialized_network(network, config)\n",
        "\n",
        "    if engine_bytes is None:\n",
        "        print(\"Failed to create the TensorRT engine\")\n",
        "        return\n",
        "    trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "    # Save the engine to a file\n",
        "    Path(trt_engine_path).write_bytes(engine_bytes)\n",
        "\n",
        "    print(f\"TensorRT engine saved to {trt_engine_path}\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "precision: str = \"int8\"\n",
        "onnx_path: str = \"qat_dtmf_classifier.onnx\"\n",
        "trt_path: str = \"dtmf_classifier_\" + precision + \"_\" + get_gpu_type() + \".trt\"\n",
        "build_engine_onnx(onnx_path, trt_path, precision=precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY4AP6jrmJKg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "\n",
        "DEBUG = False\n",
        "\n",
        "\n",
        "def print_dbg(*x: Any) -> None:\n",
        "    \"\"\"Print debug information if DEBUG is set to True.\n",
        "\n",
        "    Args:\n",
        "        *x (Any): The information to print.\n",
        "    \"\"\"\n",
        "    if DEBUG:\n",
        "        print(x)\n",
        "\n",
        "class CustomProfiler(trt.IProfiler):\n",
        "    \"\"\"Custom Profiler for logging layer-wise latency.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        trt.IProfiler.__init__(self)\n",
        "        self.layers = {}\n",
        "\n",
        "    def report_layer_time(self, layer_name, ms):\n",
        "        if layer_name not in self.layers:\n",
        "            self.layers[layer_name] = []\n",
        "\n",
        "        self.layers[layer_name].append(ms)\n",
        "\n",
        "class TensorRTInfer:\n",
        "    # TODO: This code still has a memory leak. The memory allocated by\n",
        "    # cudaMalloc has to be released!\n",
        "    \"\"\"Implements inference for the TensorRT engine.\"\"\"\n",
        "\n",
        "    def __init__(self, engine_path: str) -> None:\n",
        "        \"\"\"Initialize the TensorRTInfer class.\n",
        "\n",
        "        Args:\n",
        "            engine_path (str): The path to the serialized engine to load from disk.\n",
        "        \"\"\"\n",
        "        # Load TRT engine\n",
        "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
        "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
        "        # with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
        "        #    assert runtime\n",
        "        #    self.engine = runtime.deserialize_cuda_engine(f.read())\n",
        "        runtime = trt.Runtime(self.logger)\n",
        "        assert runtime\n",
        "        self.engine = runtime.deserialize_cuda_engine(Path(engine_path).read_bytes())\n",
        "\n",
        "        assert self.engine\n",
        "        self.context = self.engine.create_execution_context()\n",
        "        assert self.context\n",
        "\n",
        "        # Some Infos about the engine\n",
        "        print_dbg(\"num optimization profiles:\", self.engine.num_optimization_profiles)\n",
        "        print_dbg(\"num io tensors:\", self.engine.num_io_tensors)\n",
        "\n",
        "        # Create CUDA stream for asynchronous tasks\n",
        "        _, self.stream = cudart.cudaStreamCreate()\n",
        "\n",
        "        # Setup I/O bindings\n",
        "        self.inputs = []\n",
        "        self.outputs = []\n",
        "        self.allocations = []\n",
        "        for prof_idx in range(self.engine.num_optimization_profiles):\n",
        "            for i in range(self.engine.num_io_tensors):\n",
        "                name = self.engine.get_tensor_name(i)\n",
        "                is_input = False\n",
        "                if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
        "                    is_input = True\n",
        "                dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))\n",
        "                shape = self.engine.get_tensor_shape(name)\n",
        "                if is_input and shape[0] < 0:\n",
        "                    assert self.engine.num_optimization_profiles >= 1\n",
        "                    profile_shape = self.engine.get_tensor_profile_shape(name, prof_idx)\n",
        "                    print_dbg(\"profile_shape\", name, profile_shape)\n",
        "                    assert len(profile_shape) == 3  # min,opt,max\n",
        "\n",
        "                    # Set the *max* profile as binding shape\n",
        "                    self.switch_profile(prof_idx)\n",
        "                    self.context.set_input_shape(name, profile_shape[2])\n",
        "                    shape = self.context.get_tensor_shape(name)\n",
        "\n",
        "                if not is_input:\n",
        "                    shape = self.context.get_tensor_shape(name)\n",
        "                    print_dbg(\"shape for output:\", name, shape)\n",
        "\n",
        "                if is_input:\n",
        "                    self.batch_size = shape[0]\n",
        "                size = dtype.itemsize\n",
        "                for s in shape:\n",
        "                    size *= s\n",
        "                allocation = cuda_call(cudart.cudaMalloc(size))\n",
        "                host_allocation = None if is_input else np.zeros(shape, dtype)\n",
        "                binding = {\n",
        "                    \"index\": i,\n",
        "                    \"name\": name,\n",
        "                    \"dtype\": dtype,\n",
        "                    \"shape\": list(shape),\n",
        "                    \"allocation\": allocation,\n",
        "                    \"host_allocation\": host_allocation,\n",
        "                }\n",
        "                self.allocations.append(allocation)\n",
        "                if is_input:\n",
        "                    self.inputs.append(binding)\n",
        "                else:\n",
        "                    self.outputs.append(binding)\n",
        "                print_dbg(\n",
        "                    \"{} '{}' with shape {} and dtype {}\".format(\n",
        "                        \"Input\" if is_input else \"Output\",\n",
        "                        binding[\"name\"],\n",
        "                        binding[\"shape\"],\n",
        "                        binding[\"dtype\"],\n",
        "                    )\n",
        "                )\n",
        "            print_dbg()\n",
        "\n",
        "        assert self.batch_size > 0\n",
        "        assert len(self.inputs) > 0\n",
        "        assert len(self.outputs) > 0\n",
        "        assert len(self.allocations) > 0\n",
        "\n",
        "    def enable_profiling(self, profiler: trt.IProfiler = None) -> None:\n",
        "        \"\"\"Enable TensorRT profiling.\n",
        "\n",
        "        TensorRT will report time spent on each layer in stdout for each forward run.\n",
        "        \"\"\"\n",
        "        if not self.context.profiler:\n",
        "            self.context.profiler = CustomProfiler() if profiler is None else profiler\n",
        "\n",
        "    def input_spec(self) -> tuple[list[int], np.dtype]:\n",
        "        \"\"\"Get the specs for the input tensor of the network. Useful to prepare memory allocations.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[List[int], np.dtype]: Two items, the shape of the input tensor and its (numpy) datatype.\n",
        "        \"\"\"\n",
        "        # TODO: Index 0 is wrong\n",
        "        return self.inputs[0][\"shape\"], self.inputs[0][\"dtype\"]\n",
        "\n",
        "    def output_spec(self) -> list[tuple[list[int], np.dtype]]:\n",
        "        \"\"\"Get the specs for the output tensors of the network. Useful to prepare memory allocations.\n",
        "\n",
        "        Returns:\n",
        "            List[Tuple[List[int], np.dtype]]: A list with two items per element, the shape and (numpy) datatype of each output tensor.\n",
        "        \"\"\"\n",
        "        specs = []\n",
        "        for o in self.outputs:\n",
        "            specs.append((o[\"shape\"], o[\"dtype\"]))\n",
        "        return specs\n",
        "\n",
        "    def switch_profile(self, idx: int) -> None:\n",
        "        \"\"\"Switch to a different optimization profile.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the optimization profile to switch to.\n",
        "        \"\"\"\n",
        "        self.context.set_optimization_profile_async(\n",
        "            idx, self.stream\n",
        "        )\n",
        "\n",
        "    def infer(self, batch: np.ndarray) -> list[np.ndarray]:\n",
        "        \"\"\"Execute inference on a batch of images.\n",
        "\n",
        "        Args:\n",
        "            batch (np.ndarray): A numpy array holding the image batch.\n",
        "\n",
        "        Returns:\n",
        "            List[np.ndarray]: A list of outputs as numpy arrays.\n",
        "        \"\"\"\n",
        "        # If the optimization profile does not match, change it here:\n",
        "        # In our setup the opt. profiles are selected in a way that the\n",
        "        # optimal batch sizes are powers of 2. In practice, one would not do\n",
        "        # it in this way:\n",
        "        # TODO: If the profile does not fit in the range, find the profile with\n",
        "        # the closest optimal settings...\n",
        "        if True:\n",
        "          expected_profile = int(np.log2(batch.shape[0]))\n",
        "          if self.context.active_optimization_profile != expected_profile:\n",
        "              print(\"Changing to profile\", expected_profile)\n",
        "              self.switch_profile(expected_profile)\n",
        "\n",
        "          if self.context.get_tensor_shape(\"input\") != batch.shape:\n",
        "              print(\"Changing batch size for inference!\")\n",
        "\n",
        "              # Adapt the input shape:\n",
        "              self.context.set_input_shape(\"input\", batch.shape)\n",
        "        print_dbg(\n",
        "            \"self.engine.get_tensor_shape(input)\", self.engine.get_tensor_shape(\"input\")\n",
        "        )\n",
        "        print_dbg(\n",
        "            \"self.context.get_tensor_shape(input)\",\n",
        "            self.context.get_tensor_shape(\"input\"),\n",
        "        )\n",
        "        print_dbg(\n",
        "            \"self.context.get_tensor_shape(output)\",\n",
        "            self.context.get_tensor_shape(\"output\"),\n",
        "        )\n",
        "        print_dbg()\n",
        "\n",
        "        o_idx = self.context.active_optimization_profile\n",
        "        print_dbg(\"Active output index (opt. profile)\", o_idx)\n",
        "\n",
        "        # Copy I/O and Execute\n",
        "        memcpy_host_to_device(self.inputs[o_idx][\"allocation\"], batch)\n",
        "\n",
        "        self.context.execute_v2(self.allocations)\n",
        "        memcpy_device_to_host(\n",
        "            self.outputs[o_idx][\"host_allocation\"], self.outputs[o_idx][\"allocation\"]\n",
        "        )\n",
        "\n",
        "        return [self.outputs[o_idx][\"host_allocation\"]]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Main function to run the TensorRT inference.\"\"\"\n",
        "trt_path = \"dtmf_classifier_int8_tesla_t4.trt\"\n",
        "seq_len = 2**12\n",
        "trt_infer = TensorRTInfer(trt_path)\n",
        "#trt_infer.enable_profiling() # Use only for debugging/analysis purposes, since it slows down inference\n",
        "\n",
        "print(\"Starting inference\")\n",
        "if True:\n",
        "    trt_infer.switch_profile(6)\n",
        "    spec = trt_infer.input_spec()\n",
        "    print(\"spec\", spec)\n",
        "    # batch = my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        "    X, Y = dtmf_gen.generate_dataset(n_samples=256, t_length=seq_len)\n",
        "    o = trt_infer.infer(X.astype(np.float32))[0][: X.shape[0]]\n",
        "    #o = keras_model.predict(X.astype(np.float32), verbose=0)\n",
        "    print(\"o.shape\", o.shape)\n",
        "\n",
        "    thresholded = (o > 0.5).astype(int)\n",
        "    print((thresholded == Y).sum() / Y.size)\n",
        "    for iidx in range(X.shape[0]):\n",
        "        predicted_key_sequence = dtmf_gen.decode_prediction(o[iidx])\n",
        "        original_key_sequence = dtmf_gen.decode_prediction(Y[iidx])\n",
        "        if predicted_key_sequence != original_key_sequence:\n",
        "            print(\"predicted_key_sequence\", predicted_key_sequence)\n",
        "            print(\"original_key_sequence\", original_key_sequence)\n",
        "        else:\n",
        "            print(\"OK\", predicted_key_sequence)\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"No input provided, running in benchmark mode\")\n",
        "    trt_infer.switch_profile(0)\n",
        "    spec = trt_infer.input_spec()\n",
        "\n",
        "    spec = (512, 4096, 1), np.float32\n",
        "\n",
        "    rng = np.random.default_rng()\n",
        "    batch = rng.random(spec[0]).astype(spec[1])\n",
        "    # batch = np.random.rand(*spec[0]).astype(spec[1])\n",
        "\n",
        "    print(\"batch.shape\", batch.shape)\n",
        "    print(\"batch.dtype\", batch.dtype)\n",
        "    print(\"min/max/mean\", batch.min(), batch.max(), batch.mean())\n",
        "    iterations = 100\n",
        "    times = []\n",
        "    for i in range(20):  # GPU warmup iterations\n",
        "        trt_infer.infer(batch)\n",
        "    for i in range(iterations):\n",
        "        start = time.time()\n",
        "        o = trt_infer.infer(batch)\n",
        "        times.append(time.time() - start)\n",
        "        print(f\"Iteration {i + 1} / {iterations}\", end=\"\\r\")\n",
        "    print(\"Benchmark results include time for H2D and D2H memory copies\")\n",
        "    print(f\"Average Latency: {1000 * np.average(times):.3f} ms\")\n",
        "    print(f\"Average Throughput: {trt_infer.batch_size / np.average(times):.1f} ips\")\n",
        "\n",
        "print()\n",
        "print(\"Finished Processing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, o.shape"
      ],
      "metadata": {
        "id": "a2skERGo8hxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X[3,:,0])"
      ],
      "metadata": {
        "id": "6FE57CRX-q1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trt_path"
      ],
      "metadata": {
        "id": "NJxjPLRYoscs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_fp16 = pd.DataFrame([ (k, np.mean(v)) for k, v in trt_infer.context.profiler.layers.items()], columns=[\"Layer\", \"Time (ms)\"])"
      ],
      "metadata": {
        "id": "ZjSx_JaTn9Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_int8.set_index(\"Layer\").add_suffix(' int8'), df_fp16.set_index(\"Layer\").add_suffix(' fp16')], axis=1)"
      ],
      "metadata": {
        "id": "UPSFFqu8pFfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"diff\"] = df[\"Time (ms) fp16\"] - df[\"Time (ms) int8\"]"
      ],
      "metadata": {
        "id": "R461aK52qy2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)  # Display up to 50 columns\n",
        "df.sort_values(\"diff\", ascending=False)"
      ],
      "metadata": {
        "id": "eDZQHQaupi_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in trt_infer.context.profiler.layers.items():\n",
        "  print(k[-40:], np.sum(v))"
      ],
      "metadata": {
        "id": "JK_aoGgKZh69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trt_infer.profiler.report_layer_time(0)"
      ],
      "metadata": {
        "id": "tLg5ItFTYRCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modell-Experimente"
      ],
      "metadata": {
        "id": "xIEjIXGXq_k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laden der einzelnen Modelle fÃ¼r die Inferenz"
      ],
      "metadata": {
        "id": "ajTlV0ndF3j0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYcDlVrLqWwx"
      },
      "outputs": [],
      "source": [
        "from techdays25.onnx_utils import (\n",
        "    OnnxModel,\n",
        "    benchmark_models_on_batch_size,\n",
        "    plot_benchmark_results,\n",
        ")\n",
        "from pathlib import Path\n",
        "\n",
        "# FP32 ONNX Model\n",
        "onnx_classifier = OnnxModel(\"dtmf_classifier.onnx\")\n",
        "\n",
        "# FP16 ONNX Model\n",
        "onnx_classifier_fp16 = OnnxModel(\"dtmf_classifier_fp16.onnx\")\n",
        "\n",
        "# INT8 TensorRT Model\n",
        "tensorrt_classifier_int8 = TensorRTInfer(f\"dtmf_classifier_int8_{get_gpu_type()}.trt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H557RUJyEhf"
      },
      "outputs": [],
      "source": [
        "# TODO: Allow to select model here:\n",
        "onnx_prediction = onnx_classifier_fp16.predict(\n",
        "    my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        ")\n",
        "predicted_key_sequence = dtmf_gen.decode_prediction(onnx_prediction)\n",
        "print(\"Predicted Sequence:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tatsÃ¤chlichen gewÃ¤hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns8srDuD5Ji1"
      },
      "source": [
        "### Laufzeitmessung (Latenz) der individuellen Modelle\n",
        "- Messung der Inferenzzeiten fÃ¼r 4 Modelle:\n",
        "  - Keras, FP32 (ursprÃ¼ngliches Modell)\n",
        "  - ONNX, FP32\n",
        "  - ONNX, FP16\n",
        "  - TensorRT, INT8\n",
        "- Verschiedene Batch-GrÃ¶ÃŸen: 1,2,4,...,\n",
        "- SignallÃ¤nge: 4096\n",
        "- \"AufwÃ¤rmen\" der Modelle: Jeweils 20 DurchlÃ¤ufe fÃ¼r eine Batch-GrÃ¶ÃŸe\n",
        "- 100-fache Wiederholung jeder Messung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0splX4gqHP"
      },
      "outputs": [],
      "source": [
        "n_runs = 100\n",
        "n_warmup = 20\n",
        "signal_length = 2**12\n",
        "batch_sizes = [2**i for i in range(10)]\n",
        "\n",
        "model_dict = {\n",
        "    \"keras (FP32)\": lambda x: keras_model.predict(x, verbose=0),\n",
        "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    \"TRT (INT8)\": tensorrt_classifier_int8.infer,\n",
        "}\n",
        "\n",
        "dtmf_benchmark_results = benchmark_models_on_batch_size(\n",
        "    model_dict=model_dict,\n",
        "    input_shape=(signal_length, 1),\n",
        "    batch_sizes=batch_sizes,\n",
        "    n_runs=n_runs,\n",
        "    n_warmup=n_warmup,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzxwUrIdqNFN"
      },
      "outputs": [],
      "source": [
        "show_models = [\n",
        "    'keras (FP32)',\n",
        "    'ONNX (FP32)',\n",
        "    'ONNX (FP16)',\n",
        "     'TRT (INT8)',\n",
        "]\n",
        "\n",
        "plot_benchmark_results(\n",
        "    results={k: v for k,v in dtmf_benchmark_results.items() if k in show_models},\n",
        "    title=\"Inferenzzeiten von DTMF-Klassifikationsmodellen\",\n",
        "    xscale=\"log\",\n",
        "    yscale=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "df_runtimes = pd.DataFrame( {k: v.median(axis=0)*1000.0 for k,v in dtmf_benchmark_results.items()} )\n",
        "df_runtimes.index.name = 'BatchgrÃ¶ÃŸe'\n",
        "display(HTML(\"<h2>Durchschnittliche Inferenzzeiten in Millisekunden</h2>\"))\n",
        "display(df_runtimes)"
      ],
      "metadata": {
        "id": "rTqqTVpthq3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Speedup der quantisierten Modelle ggÃ¼. Keras-Modell {display-mode: \"form\"}\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_speedup(df, reference_model, batch_size):\n",
        "    # Ensure the batch size exists in the DataFrame\n",
        "    if batch_size not in df.index:\n",
        "        raise ValueError(f\"Batch size {batch_size} not found in the DataFrame index.\")\n",
        "\n",
        "    # Ensure the reference model exists in the DataFrame columns\n",
        "    if reference_model not in df.columns:\n",
        "        raise ValueError(f\"Reference model {reference_model} not found in the DataFrame columns.\")\n",
        "\n",
        "    # Extract the runtimes for the given batch size\n",
        "    runtimes = df.loc[batch_size]\n",
        "\n",
        "    # Calculate the speedup relative to the reference model\n",
        "    reference_runtime = runtimes[reference_model]\n",
        "    speedup = reference_runtime / runtimes\n",
        "\n",
        "    # Plot the bar chart\n",
        "    plt.figure(figsize=(7, 5))\n",
        "\n",
        "    #colors = plt.cm.viridis(np.linspace(0, 1, len(speedup)))  # Use a colormap for different colors\n",
        "    cmap = plt.get_cmap(\"tab10\")\n",
        "\n",
        "    colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "    bars = speedup.plot(kind='bar', color=colors)\n",
        "\n",
        "    # Annotate each bar with the speedup value\n",
        "    for bar in bars.patches:\n",
        "        height = bar.get_height()\n",
        "        bars.annotate(f'x{height:.2f}',\n",
        "                      xy=(bar.get_x() + bar.get_width() / 2, height-0.1),\n",
        "                      xytext=(0, 3),  # 3 points vertical offset\n",
        "                      textcoords=\"offset points\",\n",
        "                      ha='center', va='bottom')\n",
        "\n",
        "    plt.title(f'Speedup relativ zu \"{reference_model}\" fÃ¼r Batch-GrÃ¶ÃŸe {batch_size}')\n",
        "    plt.xlabel('Modell')\n",
        "    plt.ylabel('Speedup')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', which=\"both\")\n",
        "    plt.show()\n",
        "\n",
        "plot_speedup(df_runtimes, reference_model='keras (FP32)', batch_size=512)"
      ],
      "metadata": {
        "id": "Lpfn2IjIk-bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genauigkeit der (quantisierten) Modelle"
      ],
      "metadata": {
        "id": "CFZx9ylH06K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "signal_length = 2**12 # TODO: Increase\n",
        "batch_size = 256\n",
        "noise_levels = [5*i for i in range(21)]\n",
        "\n",
        "model_dict = {\n",
        "    \"keras (FP32)\": lambda x: keras_model.predict(x, verbose=0),\n",
        "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    \"TRT (INT8)\": lambda x: tensorrt_classifier_int8.infer(x)[0],\n",
        "}"
      ],
      "metadata": {
        "id": "difLRtDd1nK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.02, 0.05),\n",
        "    dur_pause=(0.01, 0.03),\n",
        "    noise_factor=None, # We will set this manually ourselves later\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ],
      "metadata": {
        "id": "sv7_Ttzq1Mb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Genaugkeit der einzelnen Modelle fÃ¼r unterschiedliches Rauschverhalten auswerten {display-mode: \"form\"}\n",
        "\n",
        "import Levenshtein\n",
        "\n",
        "# A bit hacky code here...\n",
        "\n",
        "def plot_acc_metrics(df_levenshtein, df_accuracies, avg_sequence_length):\n",
        "  def plot(which_result):\n",
        "    df = df_levenshtein if which_result == \"levenshtein\" else df_accuracies\n",
        "    df.index.name = \"Rauschlevel\"\n",
        "    cmap = plt.get_cmap(\"tab10\")\n",
        "    colors = [cmap(i) for i in range(len(df.columns))]\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for column, color in zip(df.columns, colors):\n",
        "      plt.plot(df[column], color=color, label=column)\n",
        "\n",
        "    plt.xlabel(\"Rauschlevel\")\n",
        "    plt.ylabel(which_result)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.title(f\"Metrik '{which_result}' fÃ¼r ausgewÃ¤hlte Modelle (mittlere SequenzlÃ¤nge: {avg_sequence_length: .2f})\")\n",
        "    plt.show()\n",
        "  return plot\n",
        "\n",
        "def evaluate_dtmf_model(model_fnc, X_val, Y_val):\n",
        "  prediction = model_fnc(X_val.astype(np.float32))\n",
        "\n",
        "  assert prediction.shape == Y_val.shape\n",
        "\n",
        "  # Compute Class Accuracy\n",
        "  pred_classes = prediction.squeeze().argmax(axis=-1)\n",
        "  Y_val_classes = Y_val.squeeze().argmax(axis=-1)\n",
        "  accuracy = (pred_classes == Y_val_classes).sum() / Y_val_classes.size\n",
        "\n",
        "  # For every prediction check, if sequence matches\n",
        "  levenshtein_distance = 0\n",
        "  sequence_length = 0\n",
        "  for idx in range(X_val.shape[0]):\n",
        "      predicted_key_sequence = dtmf_gen.decode_prediction(prediction[idx])\n",
        "      original_key_sequence = dtmf_gen.decode_prediction(Y_val[idx])\n",
        "      levenshtein_distance += Levenshtein.distance(predicted_key_sequence, original_key_sequence)\n",
        "      sequence_length += len(original_key_sequence)\n",
        "  # accuracy and average levenshtein distance\n",
        "  return accuracy, levenshtein_distance / X_val.shape[0], sequence_length / X_val.shape[0]\n",
        "\n",
        "noise_level_accuracies = {}\n",
        "noise_level_levenshtein = {}\n",
        "\n",
        "print(\"Auswertung lÃ¤uft \", end=\"\")\n",
        "for noise_level in noise_levels:\n",
        "  X_val, Y_val = dtmf_gen.generate_dataset(n_samples=batch_size, t_length=signal_length, noise_factor=noise_level)\n",
        "  # print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())\n",
        "\n",
        "  # To be fair, use the same data for all models\n",
        "  all_model_accuracies = {}\n",
        "  all_model_levenshtein = {}\n",
        "  for model_name, model_fnc in model_dict.items():\n",
        "    print(\".\", end=\"\")\n",
        "    accuracy_signal, avg_levenshtein_distance, avg_sequence_length = evaluate_dtmf_model(model_fnc, X_val, Y_val)\n",
        "    #print(accuracy_signal, accuracy_sequence)\n",
        "\n",
        "    all_model_accuracies[model_name] = accuracy_signal\n",
        "    all_model_levenshtein[model_name] = avg_levenshtein_distance\n",
        "\n",
        "  noise_level_accuracies[noise_level] = pd.Series(all_model_accuracies)\n",
        "  noise_level_levenshtein[noise_level] = pd.Series(all_model_levenshtein)\n",
        "\n",
        "df_levenshtein = pd.DataFrame(noise_level_levenshtein).T\n",
        "df_accuracies = pd.DataFrame(noise_level_accuracies).T\n",
        "\n",
        "plot_accuracy_metrics = plot_acc_metrics(df_levenshtein, df_accuracies, avg_sequence_length)"
      ],
      "metadata": {
        "id": "DMCl3eyy2Nn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_metrics(\"levenshtein\")\n",
        "plot_accuracy_metrics(\"accuracy\")"
      ],
      "metadata": {
        "id": "DVqYJn097xKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96Jn4tTY6DJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIWnRYYTuD4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein # TODO: Put into dependencies"
      ],
      "metadata": {
        "id": "tcwDvfRm5dYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN2XVzIyy_Ww"
      },
      "source": [
        "## Anhang 1: Reproduktion des Modells/Erneutes Training des Keras Modells (Optional)\n",
        "\n",
        "**Hinweis:** Da das Training des Modells vergleichsweise viele Ressourcen benÃ¶tigt (RAM/GPU), sollte *jetzt* die Colab Sitzung neugestartet werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y0ndHlTcqzX"
      },
      "source": [
        "# Further Experiments with Data Types\n",
        "\n",
        "TODO: Move to utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frFXsleBYGPT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def float_to_binary_fp32(num: float) -> str:\n",
        "    \"\"\"Converts a built-in floating point number (64-bit) to its FP32 binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the floating point number.\n",
        "    \"\"\"\n",
        "    print(\"fp32:\", num)\n",
        "    return \"\".join(f\"{c:0>8b}\" for c in struct.pack(\"!f\", num))\n",
        "\n",
        "\n",
        "def float_to_binary_fp16(num: float) -> str:\n",
        "    \"\"\"Converts a builtin-in floating point number to a 16-bit floating point number and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the 16-bit floating point number.\n",
        "    \"\"\"\n",
        "    # Convert the number to a float16\n",
        "    float16_num = np.float16(num)\n",
        "\n",
        "    print(\"fp16:\", float16_num)\n",
        "\n",
        "    # Convert the float16 to bytes\n",
        "    float16_bytes = float16_num.tobytes()\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(float16_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_bf16(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to bfloat16  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the bfloat16 floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to bfloat16\n",
        "    bf = a.bfloat16()\n",
        "\n",
        "    print(\"bf16\", bf)\n",
        "\n",
        "    # Convert the bfloat16 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(bf_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e4m3(num: float) -> str:\n",
        "    \"\"\"Converts a  floating point number to float8 (e4m3) and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e4m3) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e4m3)\n",
        "    bf = a.to(torch.float8_e4m3fn)\n",
        "\n",
        "    print(\"fp8_e4m3\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e5m2(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to float8 (e5m2)  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e5m2) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e5m2)\n",
        "    bf = a.to(torch.float8_e5m2)\n",
        "\n",
        "    print(\"fp8_e5m2\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_int(num: float, bit_length: int = 8) -> str:\n",
        "    \"\"\"Converts a floating point number to its binary representation as an integer.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "        bit_length (int, optional): The bit length of the binary representation. Defaults to 8.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the integer part of the floating point number.\n",
        "    \"\"\"\n",
        "    return np.binary_repr(round(num), width=bit_length)\n",
        "\n",
        "\n",
        "num = -8.875074538462327 - 2**-7 - 2**-8\n",
        "float_to_binary_fp32(num)\n",
        "# float_to_binary_fp16(num)\n",
        "# float_to_binary_bf16(num)\n",
        "# float_to_binary_fp8_e4m3(num)\n",
        "# float_to_binary_fp8_e5m2(num)\n",
        "# float_to_binary_int(num, bit_length=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-X1F7z9BUS8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "s = \"1100100001111100\"\n",
        "b = int(s, base=2).to_bytes(2, \"little\")\n",
        "print(b)\n",
        "c = np.frombuffer(b, dtype=np.float16, count=1)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjV-2lyBUS9"
      },
      "outputs": [],
      "source": [
        "# Binary string\n",
        "binary_string = \"11000001000011111000101100101011\"\n",
        "\n",
        "# Convert the binary string to an integer\n",
        "binary_int = int(binary_string, 2)\n",
        "\n",
        "# Convert the integer to bytes (4 bytes for float32)\n",
        "binary_bytes = binary_int.to_bytes(4, byteorder=\"big\")\n",
        "\n",
        "# Unpack the bytes to a float\n",
        "float_value = struct.unpack(\">f\", binary_bytes)[0]\n",
        "\n",
        "print(float_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeF16bolNFX1"
      },
      "source": [
        "# Anhang 2: Analyse eines kleinen DTMF Klassifikationsmodells im Frequenzbereich"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Callable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def multiple_formatter(\n",
        "    denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
        ") -> Callable[[float, int], str]:\n",
        "    \"\"\"Creates a formatter function for matplotlib that formats axis labels as multiples of a given number.\n",
        "\n",
        "    Args:\n",
        "        denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
        "        number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
        "        latex (str, optional): The LaTeX string to use for the base number.\n",
        "\n",
        "    Returns:\n",
        "        Callable[[float, int], str]: A function that formats a given value as a LaTeX fraction of the base number.\n",
        "    \"\"\"\n",
        "\n",
        "    def gcd(a: int, b: int) -> int:\n",
        "        \"\"\"Computes the greatest common divisor of two integers.\n",
        "\n",
        "        Args:\n",
        "            a (int): The first integer.\n",
        "            b (int): The second integer.\n",
        "\n",
        "        Returns:\n",
        "            int: The greatest common divisor of a and b.\n",
        "        \"\"\"\n",
        "        while b:\n",
        "            a, b = b, a % b\n",
        "        return a\n",
        "\n",
        "    def _multiple_formatter(x: float, pos: int) -> str:\n",
        "        \"\"\"Formats a given value as a LaTeX fraction of the base number.\n",
        "\n",
        "        Args:\n",
        "            x (float): The value to format.\n",
        "            pos (int): The position (not used in this implementation).\n",
        "\n",
        "        Returns:\n",
        "            str: The formatted string.\n",
        "        \"\"\"\n",
        "        den = denominator\n",
        "        num = np.int64(np.rint(den * x / number))\n",
        "        com = gcd(num, den)\n",
        "        (num, den) = (int(num / com), int(den / com))\n",
        "        if den == 1:\n",
        "            if num == 0:\n",
        "                return r\"$0$\"\n",
        "            if num == 1:\n",
        "                return rf\"${latex}$\"\n",
        "            if num == -1:\n",
        "                return rf\"$-{latex}$\"\n",
        "            return rf\"${num}{latex}$\"\n",
        "        if num == 1:\n",
        "            return rf\"$\\frac{{{latex}}}{{{den}}}$\"\n",
        "        if num == -1:\n",
        "            return rf\"$\\frac{{-{latex}}}{{{den}}}$\"\n",
        "        return rf\"$\\frac{{{num}{latex}}}{{{den}}}$\"\n",
        "\n",
        "    return _multiple_formatter\n",
        "\n",
        "\n",
        "class Multiple:\n",
        "    \"\"\"A class to create locators and formatters for matplotlib axes based on multiples of a given number.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
        "    ):\n",
        "        \"\"\"Initializes the Multiple class with the given parameters.\n",
        "\n",
        "        Args:\n",
        "            denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
        "            number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
        "            latex (str, optional): The LaTeX string to use for the base number.\n",
        "        \"\"\"\n",
        "        self.denominator = denominator\n",
        "        self.number = number\n",
        "        self.latex = latex\n",
        "\n",
        "    def locator(self) -> plt.MultipleLocator:\n",
        "        \"\"\"Creates a locator for matplotlib axes based on multiples of the base number.\n",
        "\n",
        "        Returns:\n",
        "            plt.MultipleLocator: A locator for matplotlib axes.\n",
        "        \"\"\"\n",
        "        return plt.MultipleLocator(self.number / self.denominator)\n",
        "\n",
        "    def formatter(self) -> plt.FuncFormatter:\n",
        "        \"\"\"Creates a formatter for matplotlib axes that formats labels as multiples of the base number.\n",
        "\n",
        "        Returns:\n",
        "            plt.FuncFormatter: A formatter for matplotlib axes.\n",
        "        \"\"\"\n",
        "        return plt.FuncFormatter(\n",
        "            multiple_formatter(self.denominator, self.number, self.latex)\n",
        "        )"
      ],
      "metadata": {
        "id": "iEAt6KPLZd0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze0NbFHqNO-K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(\"simple_dtmf_classifier.keras\")\n",
        "\n",
        "# Recreate the intermediate model\n",
        "intermediate_output = loaded_model.get_layer('concat').output\n",
        "recreated_intermediate_model = Model(inputs=loaded_model.input, outputs=intermediate_output, name=\"RecreatedIntermediateModel\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Plot the model graph and save to a temporary file\n",
        "plot_model(loaded_model, to_file='simple_dtmf_classifier.png', show_shapes=False, show_layer_names=True, dpi=50)\n",
        "\n",
        "# Display the plot inline\n",
        "display(Image('simple_dtmf_classifier.png'))"
      ],
      "metadata": {
        "id": "1i9AFr9Hmy0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_layer_by_name(model, layer_name):\n",
        "  for layer in model.layers:\n",
        "    if layer.name == layer_name:\n",
        "      return layer\n",
        "  return None\n"
      ],
      "metadata": {
        "id": "vDxjMxd4jGSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVexf_PdNVDg"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  for n in range(len(loaded_model.layers)):\n",
        "      if loaded_model.layers[n].name == layer_name:\n",
        "          break\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "  # Assuming 'model' is your Keras model and 'n' is the index of the layer you are interested in\n",
        "  n = 4  # Example: Get the weights and name of the 3rd layer (indexing starts from 0)\n",
        "\n",
        "  # Access the n-th layer\n",
        "  nth_layer = model.layers[n]\n",
        "\n",
        "  # Get the weights of the n-th layer\n",
        "  weights = nth_layer.get_weights()\n",
        "\n",
        "  # Get the name of the n-th layer\n",
        "  layer_name = nth_layer.name\n",
        "\n",
        "  # Print the name and weights of the n-th layer\n",
        "  print(f\"Name der {n + 1}. Schicht (Index {n}): {layer_name}\")\n",
        "  # print(f\"Gewichte der {n+1}. Schicht (Index {n}):\\n\", weights)\n",
        "  print(f\"Dimension des Layers: {weights[0].shape} (kernel_size x input_channels x  num_filters)\" ) # (kernel_size, input_channels, num_filters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = \"conv_1_1\"\n",
        "layer = find_layer_by_name(loaded_model, layer_name =  layer_name)\n",
        "\n",
        "# Print the name and weights of the n-th layer\n",
        "#print(f\"Name der {n + 1}. Schicht (Index {n}): {layer_name}\")\n",
        "# print(f\"Gewichte der {n+1}. Schicht (Index {n}):\\n\", weights)\n",
        "print(f\"Dimension des Layers: {layer.get_weights()[0].shape} (kernel_size x input_channels x  num_filters)\" ) # (kernel_size, input_channels, num_filters)"
      ],
      "metadata": {
        "id": "9nXkiac8jHe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following is necessary, since we have several downsampling layers in the model\n",
        "# Note that this computation is specific to this particular model\n",
        "freq_multiplier = 1\n",
        "if \"conv\" in layer_name:\n",
        "  freq_multiplier *= 2** (int(layer_name.split(\"_\")[1]) + 1)\n",
        "freq_multiplier"
      ],
      "metadata": {
        "id": "3D31qIHvd1Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = [freq_multiplier*2.0 * np.pi * f / dtmf_gen.get_sample_rate() for f in dtmf_gen.FREQS]"
      ],
      "metadata": {
        "id": "RCvM88wLWa3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay9hPpIUPf-M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "fig = plt.figure(figsize=(15, 16))\n",
        "\n",
        "for z in range(1):\n",
        "    dil_rate = 1 # Is always 1 in this example...\n",
        "    b = weights[0][:, 0, z]  # (kernel_size, channels, num_filters)\n",
        "    w, h = signal.freqz(b[::-1])\n",
        "    if dil_rate > 1:\n",
        "        m = b.shape\n",
        "        out = np.zeros((dil_rate) * m[0], dtype=b.dtype)\n",
        "        out[::dil_rate] = b\n",
        "        b = out[: -dil_rate + 1]\n",
        "        w, h = signal.freqz(b[::-1])\n",
        "\n",
        "    ax1 = fig.add_subplot(421 + z)\n",
        "\n",
        "    #ax1.set_title(\"Dilation rate q=\" + str(dil_rate))\n",
        "    ax1.set_title(f\"Frequenzantwort fÃ¼r Schicht {layer_name}\")\n",
        "\n",
        "    # plt.plot(w, 20 * np.log10(abs(h)), 'b')\n",
        "    plt.plot(w, abs(h), \"b\")\n",
        "    if z % 2 == 0:\n",
        "        plt.ylabel(\"Amplitude [dB]\", color=\"b\")\n",
        "    if z // 2 == 1:\n",
        "        plt.xlabel(r\"$\\hat\\omega$ [rad]\")  # Frequency [rad/sample]\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    angles = np.unwrap(np.angle(h))\n",
        "    # angles = angles % (2 * np.pi) - np.pi\n",
        "    plt.plot(w, angles, \"g\")\n",
        "    if z % 2 == 1:\n",
        "        plt.ylabel(\"Angle [rad]\", color=\"g\")\n",
        "    plt.grid()\n",
        "    # plt.axis('tight')\n",
        "\n",
        "    ax1.xaxis.grid(True)\n",
        "    ax1.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n",
        "    ax1.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 10))\n",
        "    ax1.xaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
        "\n",
        "    ax2.yaxis.grid(True)\n",
        "    ax2.yaxis.set_major_locator(plt.MultipleLocator(dil_rate * np.pi))\n",
        "    # ax2.yaxis.set_minor_locator(plt.MultipleLocator(2*np.pi))\n",
        "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
        "\n",
        "    # Plot vertical lines at specified frequencies\n",
        "    if frequencies:\n",
        "        for freq in frequencies:\n",
        "            ax1.axvline(x=freq, color='r', linestyle='--')\n",
        "\n",
        "plt.tight_layout(pad=0.5)\n",
        "# plt.savefig(\"pdf/example-frequency-response-ecg1.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FNI7hwmWHzP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def zplane(b, a=np.array([1])):\n",
        "    \"\"\"Plot the complex z-plane given a transfer function.\"\"\"\n",
        "    # Create a unit circle\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    ax = plt.subplot(1, 1, 1)\n",
        "    unit_circle = plt.Circle((0, 0), 1, color=\"gray\", fill=False, linestyle=\"dotted\")\n",
        "    ax.add_artist(unit_circle)\n",
        "\n",
        "    # Plot zeros and poles\n",
        "    zeros = np.roots(b)\n",
        "    poles = np.roots(a)\n",
        "    plt.scatter(\n",
        "        np.real(zeros),\n",
        "        np.imag(zeros),\n",
        "        s=50,\n",
        "        marker=\"o\",\n",
        "        facecolors=\"none\",\n",
        "        edgecolors=\"b\",\n",
        "        label=\"Zeros\",\n",
        "    )\n",
        "    plt.scatter(\n",
        "        np.real(poles), np.imag(poles), s=50, marker=\"x\", color=\"r\", label=\"Poles\"\n",
        "    )\n",
        "\n",
        "    # Set plot limits and labels\n",
        "    plt.xlim(-1.5, 1.5)\n",
        "    plt.ylim(-1.5, 1.5)\n",
        "    plt.axhline(0, color=\"black\", lw=1)\n",
        "    plt.axvline(0, color=\"black\", lw=1)\n",
        "    plt.xlabel(\"Real Part\")\n",
        "    plt.ylabel(\"Imaginary Part\")\n",
        "    plt.title(\"Z-Plane Diagram\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example: Design a low-pass FIR filter using the window method\n",
        "# numtaps = 21  # Number of filter coefficients (taps)\n",
        "# cutoff = 0.3  # Normalized cutoff frequency (0 to 1, where 1 corresponds to Nyquist frequency)\n",
        "# b = firwin(numtaps, cutoff)\n",
        "\n",
        "# Plot the z-plane diagram for the FIR filter\n",
        "zplane(b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import chirp\n",
        "\n",
        "# Define parameters\n",
        "dur = 2.0  # Duration of the chirp signal in seconds\n",
        "sample_rate = 44100  # Sampling rate in Hz\n",
        "f1 = 0  # Start frequency of the chirp in Hz\n",
        "f2 = 2000  # End frequency of the chirp in Hz\n",
        "\n",
        "f_interest = [697, 770, 852, 941, 1209, 1336, 1477, 1633]\n",
        "\n",
        "# Generate the time vector\n",
        "tt = np.arange(0.0, dur, 1 / sample_rate)\n",
        "\n",
        "# Generate the chirp signal\n",
        "chirp_signal = chirp(tt, f0=f1, f1=f2, t1=dur, method='linear')\n",
        "\n",
        "# Calculate the time points for the frequencies of interest\n",
        "t_interest = [(f - f1) / (f2 - f1) * dur for f in f_interest]\n",
        "\n",
        "# Plot the chirp signal\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.plot(tt, chirp_signal, label='Chirp Signal')\n",
        "\n",
        "# Add markers for the frequencies of interest\n",
        "for f, t in zip(f_interest, t_interest):\n",
        "    plt.axvline(x=t, color='r', linestyle='--', alpha=0.5)\n",
        "    plt.text(t, 0, f'{f} Hz', rotation=90, verticalalignment='bottom', color='r')\n",
        "\n",
        "plt.title(f'Chirp Signal from {f1} Hz to {f2} Hz')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XLsaVUMcP9Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = intermediate_model.predict(chirp_signal.reshape(1, -1, 1))\n",
        "result.shape"
      ],
      "metadata": {
        "id": "UbbzOWRPOjz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate example data (896x8)\n",
        "# In practice, you would load your actual data here\n",
        "data = result.squeeze()\n",
        "\n",
        "# Create a figure with 8 subplots arranged vertically\n",
        "fig, axes = plt.subplots(4, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "# Plot each time series in its respective subplot\n",
        "for i in range(4):\n",
        "    ax_data = data[:len(tt), i]\n",
        "    axes[i].plot(tt, ax_data, alpha=0.8)\n",
        "    #axes[i].set_title(f'Time Series {i+1}')\n",
        "    axes[i].grid(True)\n",
        "\n",
        "    # Add markers for the frequencies of interest\n",
        "    for f, t in zip(f_interest, t_interest):\n",
        "        axes[i].axvline(x=t, color='r', linestyle='--', alpha=0.5)\n",
        "        axes[i].text(t*1.01, min(ax_data), f'{f} Hz', rotation=90, verticalalignment='bottom', color='r')\n",
        "\n",
        "# Set common labels\n",
        "fig.text(0.5, 0.04, 'Time', ha='center')\n",
        "fig.text(0.04, 0.5, 'Amplitude', va='center', rotation='vertical')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout(rect=[0.03, 0.03, 1, 0.97])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7aHPwaGFN7Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO"
      ],
      "metadata": {
        "id": "v9SuALdPYq5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AWzMtPVQkgb"
      },
      "outputs": [],
      "source": [
        "# from collections.abc import Callable\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shl0yW5zcdri"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.02, 0.1),\n",
        "    dur_pause=(0.01, 0.05),\n",
        "    noise_factor=(0.0,60.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This model can be used as a basis to analyze it in the frequency domain.\n",
        "# It appears to show some interesting insights in the frequency domain.\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Concatenate, Activation\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (None, 1)  # Example: sequence length is variable, and there are 3 features per time step\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "# Learn a filter for the input:\n",
        "conv_layer_input = Conv1D(filters=1, kernel_size=32, padding='same', activation='linear', name=f'input_filter', use_bias=False)(inputs)\n",
        "\n",
        "# Do some downsampling first\n",
        "avg_pooled = layers.AveragePooling1D(padding=\"same\", pool_size=2)(conv_layer_input)\n",
        "avg_pooled_1 = layers.AveragePooling1D(padding=\"same\", pool_size=2)(avg_pooled)\n",
        "\n",
        "# Define 4 different Conv1D layers\n",
        "conv_layers = []\n",
        "for i in range(4):\n",
        "    conv_layer = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_1_{i+1}', use_bias=False)(avg_pooled_1)\n",
        "\n",
        "    max_pooled_layer =  layers.AveragePooling1D(padding=\"same\", pool_size=2)(conv_layer)\n",
        "    conv_layer_1 = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_2_{i+1}', use_bias=False)(max_pooled_layer)\n",
        "\n",
        "    max_pooled_layer_2 = layers.MaxPooling1D(padding=\"same\")(conv_layer_1)\n",
        "    conv_layer_2 = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_3_{i+1}', use_bias=False)(max_pooled_layer_2)\n",
        "    upsamp_layer = layers.UpSampling1D(size=16)(conv_layer_2)\n",
        "\n",
        "    conv_layers.append(upsamp_layer)\n",
        "\n",
        "# Concatenate the outputs of the Conv1D layers\n",
        "concatenated = Concatenate(name=\"concat\")(conv_layers)\n",
        "\n",
        "# Final 1x1 Conv1D layer with softmax activation\n",
        "output = Conv1D(filters=dtmf_gen.get_num_keys() + 1, kernel_size=1, activation='softmax', name=\"final_conv\", use_bias=False)(concatenated)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=output, name=\"MultiConv1DModel\")\n",
        "\n",
        "# Create an additional model to output the concatenated layer\n",
        "intermediate_model = Model(inputs=inputs, outputs=concatenated, name=\"IntermediateModel\")\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "tjb5kdPBgrrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_hSCvRHtgy"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX1JtkVWTrI5"
      },
      "outputs": [],
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcganU0yPkdG"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=50, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"simple_dtmf_classifier.keras\")"
      ],
      "metadata": {
        "id": "lKhU_0SSM5xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEgSKqSPParf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IoHrDuOGcvj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RViibMMa6XF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anhang 3: Experimente mit \"Quantization Aware Training\" in TensorFlow"
      ],
      "metadata": {
        "id": "5W5cGlTk9FgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "FU2p0U14qYpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrpNO97eX3Y"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX8x5Lym9upH"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.02, 0.1),\n",
        "    dur_pause=(0.01, 0.05),\n",
        "    noise_factor=(0.0,60.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (None, 1)\n",
        "num_classes = dtmf_gen.get_num_keys() + 1\n",
        "\n",
        "model = keras.Sequential([\n",
        "        keras.layers.Input(shape=input_shape),\n",
        "\n",
        "        keras.layers.Reshape((-1, input_shape[1], 1)),\n",
        "\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "\n",
        "        # Final layer\n",
        "        keras.layers.Conv2D(num_classes, kernel_size=(1,1), activation=\"softmax\", padding=\"same\"),\n",
        "\n",
        "        keras.layers.Reshape((-1, num_classes))\n",
        "    ])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "faIwam7j9upI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmgDwbmD9upI"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")  # multi-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYwO54_A9upI"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
        "\n",
        "\n",
        "#X_train, Y_train = np.expand_dims(X_train, -1), np.expand_dims(Y_train, -2)\n",
        "#X_val, Y_val = np.expand_dims(X_val, -1), np.expand_dims(Y_val, -2)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eypmk8Ab9upJ"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"pre_qat_dtmf_classifier.keras\")"
      ],
      "metadata": {
        "id": "JRXPVGIC_R-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "q_aware_model = quantize_model(model) # throws error\n",
        "\n",
        "#q_aware_model = tfmot.quantization.keras.quantize_annotate_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "id": "D0n21Nyspudg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.fit(X_train, Y_train, batch_size=64, epochs=2, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "id": "mrLpJt3Rp9AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "import tensorflow as tf\n",
        "\n",
        "which_model = \"qat_dtmf_classifier\"\n",
        "\n",
        "my_model = q_aware_model if which_model == \"qat_dtmf_classifier\" else model\n",
        "\n",
        "\n",
        "# This line sets the output names for the Keras model.\n",
        "# It might throw an error, but the ONNX model should still be exported correctly.\n",
        "my_model.output_names = [\"output\"]\n",
        "\n",
        "# Define the input signature for the model.\n",
        "# This specifies the shape and type of the input tensor.\n",
        "# 'None' in the shape indicates a variable dimension, meaning the model can accept inputs of varying sizes.\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, None, 1], tf.float32, name=\"input\")\n",
        "]\n",
        "\n",
        "# Convert the Keras model to an ONNX model using the specified input signature and opset version.\n",
        "# The opset version defines the set of operations available in the ONNX model.\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(my_model, input_signature, opset=18)\n",
        "\n",
        "# Save the converted ONNX model to a file.\n",
        "onnx.save(onnx_model, which_model + \".onnx\")"
      ],
      "metadata": {
        "id": "Xezsp71L-xrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "euGiqbOVAWsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anhang 4: ONNX INT8 Quantizatisierung vom DTMF-Klassifizierungsmodells"
      ],
      "metadata": {
        "id": "h2g33IROY5vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process"
      ],
      "metadata": {
        "id": "VbQpRe5Fzgyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = Path(\"dtmf_classifier.onnx\")\n",
        "# First try static quantization and then switch to dynamic quantization\n",
        "# and see how the results change\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = dtmf_gen.generate_dataset(\n",
        "            n_samples=32, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        extra_options={\"CalibTensorRangeSymmetric\":True}\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ],
      "metadata": {
        "id": "e6ohocSdz4GK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}