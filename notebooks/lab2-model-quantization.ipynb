{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusThill/techdays25/blob/feature-lab2-initial-draft/notebooks/lab2-model-quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWrVTJSVVy4"
      },
      "source": [
        "# üöÄ Lab 2: Effiziente Quantisierung tiefer neuronaler Netze\n",
        "- Dieses Jupyter Notebook **ben√∂tigt eine GPU Laufzeit**. Falls nicht bereits voreingestellt, kann daher der Laufzeittyp im Men√º unter \"Laufzeit\" > \"Laufzeittyp √§ndern\" > \"Hardwarebeschleuniger\" > **\"T4 GPU\"** ge√§ndert werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2hhcmOjXQXB"
      },
      "source": [
        "Strukturierung:\n",
        "- Teil 1: Darstellung numerischer Datentypen\n",
        "- Teil 2:\n",
        "  - Quantisierung des einfachen Modells aus Lab 1\n",
        "  - Diverse Betrachtungen auf dem quantisierten Modell (Genauigkeit, etc.)\n",
        "  - Gotchas (Optional): Overflow/Underflow am Beispiel eines Average Pooling layers\n",
        "  - Subnormal Numbers\n",
        "  - ...\n",
        "- Teil 3: Quantisierung eines DTMF Klassifikationsmodells\n",
        "  - Illustration: Erzeugung einer DTMF W√§hlsequenz und Abspielen derselben\n",
        "  - Laden eines vortrainierten DTMF-Klassifikationsmodells (ConvNet; Keras oder PyTorch)\n",
        "  - Konvertierung nach ONNX\n",
        "  - Quantisierung nach FP16\n",
        "  - Messung der Inferenzzeiten (auch f√ºr verschiedene Batch-Sizes) und vergleich von FP32, FP16-Modell\n",
        "  - Vergleich der Genauigkeit von FP16 und FP32 Modell (wie √§ndert sich die Fehlerrate)\n",
        "  - Optional: Konvertierung nach FP8 und Wiederholung der obigen Schritte\n",
        "  - Optional: Profiling der ONNX Modelle. Wo liegen die \"Hotspots\" des Modells?\n",
        "  - Optional: Trainieren des Modells auf de\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHjiyBN9VVy4"
      },
      "source": [
        "# Vorbereitungen: Installation der n√∂tigen Abh√§ngigkeiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zRp0QsBVVy5"
      },
      "outputs": [],
      "source": [
        "# Remove the `%%capture`, if you have the impression that something is going wrong during the setup\n",
        "# %%capture\n",
        "!pip install \"techdays25[lab2] @ git+https://github.com/MarkusThill/techdays25.git@feature-lab2-initial-draft\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PetUdSKZVVy5"
      },
      "source": [
        "**WICHTIG: Nach der Installation der Abh√§ngigkeiten (siehe oben) muss die Google Colab Laufzeit neugestartet werden! Im Anschluss kann mit der Ausf√ºhrung der n√§chsten Zellen fortgefahren werden werden.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf2wjy7rVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Some Colab-Specific Configuration {display-mode: \"form\"}\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "\n",
        "    output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPuTmcJKVVy5"
      },
      "source": [
        "## üìò Einleitung\n",
        "- DTMF\n",
        "- Quanstisierungsans√§tze\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-emxsEEVVy5"
      },
      "source": [
        "## üìñ Wiederholung: Darstellung numerischer Datentypen (Optional)\n",
        "- Zweierkomplementdarstellung\n",
        "- IEEE-754 Standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0MW1AnSVVy5"
      },
      "source": [
        "### Ganzahldarstellungen/Zweierkomplementdarstellung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfRcqICXVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit Integer Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Initialize 8 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"40px\")\n",
        "    )\n",
        "    for _ in range(8)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Hex representation (2 hex digits for 8 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>{bit_string}</code><br>\n",
        "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
        "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
        "            Hexadecimal: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.HBox(bit_toggles))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDlSxZqOVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Grundlegendes Setzen von Bits: Setze das 3. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
        "Erwartete Antwort: 4\n",
        "\n",
        "- Setzen mehrerer Bits: Setze das 1., 3. und 5. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
        "Erwartete Antwort: 21\n",
        "\n",
        "- Was ist die gr√∂√ütm√∂gliche bzw. kleinstm√∂gliche Zahl die mit 8 Bit dargestellt werden k√∂nnen? Antwort: -128, +127\n",
        "  - Was w√§re die Antwort, wenn wir statt 8-bit Integer, nun 32-bit Integer haben?\n",
        "\n",
        "- Signed vs. Unsigned Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -128, Unsigned: 128\n",
        "\n",
        "- Was charakterisiert eine negative Zahl in der Zweierkomplementdarstellung (unsigned integer) im Allgmeinen? Antwort: Zumindest das vorderste Bit ist gesetzt.\n",
        "\n",
        "- Wie negiere ich eine Zahl (z.B. 32 -> -32 bzw. -71 -> 71)? Antwort: Invertieren alle Bits und Addition  von 1\n",
        "\n",
        "- Angenommen ich habe -33 als 8-bit Zahl vorliegen. Wie w√ºrde ich daraus eine 32-bit unsigned Integer Zahl machen? Antwort: Einfach noch drei Bytes voranh√§ngen in denen alle Bits gesetzt sind.\n",
        "\n",
        "- Kombinieren von Bits: Setze das 2., 4. und 6. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: 42, Unsigned: 42\n",
        "\n",
        "- Negative Zahlen in der Signed-Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) und das 1. Bit (niederwertigstes Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -127, Unsigned: 129\n",
        "\n",
        "- Maximale und minimale Werte: Was ist der maximale Wert, den man mit einer 8-Bit unsigned Zahl darstellen kann? Was ist der minimale Wert, den man mit einer 8-Bit signed Zahl darstellen kann?\n",
        "Erwartete Antwort: Maximale unsigned: 255, Minimale signed: -128\n",
        "\n",
        "- Bitmuster und Werte: Setze die Bits, um die Bin√§rzahl 10101010 zu bilden. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -86, Unsigned: 170\n",
        "\n",
        "- Alle Bits gesetzt: Setze alle Bits einer 8-Bit-Zahl auf 1. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -1, Unsigned: 255\n",
        "\n",
        "\n",
        "- Verst√§ndnis von √úberlauf: Was passiert, wenn du 1 zum maximalen Wert einer 8-Bit unsigned Zahl hinzuf√ºgst? Was passiert bei einer 8-Bit signed Zahl?\n",
        "Erwartete Antwort: Bei unsigned wird es auf 0 zur√ºckgesetzt. Bei signed verursacht es einen √úberlauf und wird auf den minimalen Wert (-128) zur√ºckgesetzt.\n",
        "Zweierkomplement:\n",
        "\n",
        "- Erkl√§re, wie die Zweierkomplement-Darstellung f√ºr negative Zahlen in einer 8-Bit signed Zahl funktioniert.\n",
        "Erwartete Antwort: Im Zweierkomplement ist das h√∂chstwertige Bit (MSB) das Vorzeichenbit. Um das Zweierkomplement einer Zahl zu finden, invertiere alle Bits und addiere 1 zum niederwertigsten Bit (LSB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q1kp8MaVVy6"
      },
      "source": [
        "### Fixkommadarstellungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCrHNptuVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit Festkomma-Zahlen (engl.: fixpoint binary representations) {display-mode: \"form\"}\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Initialize 16 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, integer part, and fractional part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 7\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "# def twos_complement(bits):\n",
        "#    \"\"\"Convert list of bits to signed integer using two's complement.\"\"\"\n",
        "#    if bits[0] == 0:\n",
        "#        return int(\"\".join(str(b) for b in bits), 2)\n",
        "#\n",
        "#    # If MSB is 1, it's negative\n",
        "#    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "#    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "#    return -incremented\n",
        "\n",
        "\n",
        "def fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to a fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = twos_complement(integer_part)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Fixed-point value\n",
        "    fixed_point_decimal = fixed_point_value(bit_values)\n",
        "\n",
        "    # Hex representation (4 hex digits for 16 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:8]}</span>.\n",
        "                <span style=\"color: blue;\">{bit_string[8:]}</span>\n",
        "            </code><br>\n",
        "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
        "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
        "            Fixed-Point Decimal: <b>{fixed_point_decimal}</b><br>\n",
        "            Hexadecimal: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN_oFcfjVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmRekLfxVVy6"
      },
      "source": [
        "### Flie√ükommadarstellungen nach IEEE-754\n",
        "- TODO: Subnormal Numbers\n",
        "- Webseite mit noch mehr Darstellungen: https://evanw.github.io/float-toy/\n",
        "- Verschiedene FP8-Darstellungen: https://asawicki.info/articles/fp8_tables.php\n",
        "- https://onnx.ai/onnx/technical/float8.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8LgC7KNVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit (FP16) Flie√ükomma-Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import struct\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, exponent, and mantissa\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 5\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show FP16 value and components\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def bits_to_float16(bits: list[int]) -> np.float16:\n",
        "    \"\"\"Convert list of bits to FP16 float value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        np.float16: The FP16 float value of the binary number.\n",
        "    \"\"\"\n",
        "    bit_string = \"\".join(str(b) for b in bits)\n",
        "    # Convert binary string to integer\n",
        "    int_value = int(bit_string, 2)\n",
        "    # Pack as unsigned 16-bit int, then unpack as float16 using numpy\n",
        "    packed = struct.pack(\"<H\", int_value)  # Big endian 16-bit unsigned int\n",
        "    return np.frombuffer(packed, dtype=np.float16)[0]\n",
        "\n",
        "\n",
        "def update_display(*args):\n",
        "    \"\"\"Update the display with the current binary, FP16 float value, and its components.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Extract components\n",
        "    sign = bit_values[0]\n",
        "    exponent_bits = bit_values[1:6]\n",
        "    mantissa_bits = bit_values[6:]\n",
        "\n",
        "    exponent = int(\"\".join(str(b) for b in exponent_bits), 2)\n",
        "    exponent_unbiased = exponent - 15  # Bias = 15\n",
        "\n",
        "    mantissa_raw = \"\".join(str(b) for b in mantissa_bits)\n",
        "    (\n",
        "        1 + sum(int(b) * 2 ** (-i) for i, b in enumerate(mantissa_bits, start=1))\n",
        "        if exponent != 0\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "    # Convert to float16 value\n",
        "    fp16_value = bits_to_float16(bit_values)\n",
        "\n",
        "    # Clear previous output and display new info\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:6]}</span>\n",
        "                <span style=\"color: blue;\">{bit_string[6:]}</span>\n",
        "            </code><br>\n",
        "            Sign (1 bit): <b>{sign}</b> ({\"-\" if sign else \"+\"})<br>\n",
        "            Exponent (5 bits): <b>{\"\".join(str(b) for b in exponent_bits)} (biased: {exponent}, unbiased: {exponent_unbiased})</b><br>\n",
        "            Mantissa (10 bits): <b>{mantissa_raw}</b><br>\n",
        "            <hr>\n",
        "            <b>FP16 Value:</b> {fp16_value}\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize output\n",
        "update_display()  # 0 01111 0000000001 ^=^ 1.00097656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBCmHSNeVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Gibt es einen Unterschied zwischen +0.0 und -0.0?\n",
        "- Wie stelle ich `+Inf` bzw. `-Inf` dar?\n",
        "- Wie stelle ich `NaN` dar?\n",
        "- Was ergibt der Vergleich `float(\"nan\") != float(\"nan\")`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7youIav3VVy7"
      },
      "source": [
        "# Case Study 1: Quantisierung eines einfachen Modells (aus Lab 1)\n",
        "- Gotchas: zu gro√üe, kleine inputs, numerische Abweichungen. Ggfs.: Sehr kleines Gewicht, sehr gro√üer Input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5i-XeVZVVy7"
      },
      "source": [
        "# Case Study 2: Klassifizierung von DTMF (dual-tone multi-frequency) W√§hlsignalen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG6JRjlfVVy7"
      },
      "source": [
        "## Einf√ºhrung: Generierung und Dekodierung von Dual Tone Multiple Frequency (DTMF)-Signalen <a class=\"anchor\" id=\"part0\"></a>\n",
        "\n",
        "\n",
        "Das Dualton-Mehrfrequenzwahlverfahren (DTMF) ist ein Signalisierungssystem f√ºr das W√§hlen eines Telefons, das in den fr√ºhen 1960er Jahren von Western Electric entwickelt und sp√§ter von Bell System kommerziell an Telefonkunden geliefert wurde.\n",
        "Wenn eine Taste auf dem Telefon gedr√ºckt wird, werden zwei harmonische Tonsignale erzeugt, und die Superposition/√úberlagerung beider Signale wird verwendet, um die entsprechende Telefontaste zu charakterisieren. Wenn zum Beispiel die Taste ‚Äû5‚Äú gedr√ºckt wird, entsteht ein Dualtontonsignal, das sich aus den Frequenzen 770 Hz und 1336 Hz zusammensetzt. Die beiden Frequenzen, die jede Taste beschreiben, sind in der folgenden Tabelle aufgef√ºhrt:\n",
        "\n",
        "|   | 1209Hz  | 1336 Hz  | 1477 Hz   | 1633 Hz  |\n",
        "|---|:---:|:---:|:---:|:---:|\n",
        "| **697 Hz**  |  1 | 2  | 3  | A  |\n",
        "| **770 Hz**  |  4 | 5  | 6  | B  |\n",
        "| **852 Hz**  |  7 | 8  | 9  | C  |\n",
        "| **941 Hz**  |  * | 0  | #  | D  |\n",
        "\n",
        "In diesem Beispiel werden wir uns ansehen, wie man solche DTMF-W√§hlsequenzen generiert, sie in einer Audiodatei speichert und das Audiosignal mit einem einfachen KI-Modell wieder dekodiert.\n",
        "\n",
        "Wir werden die folgenden Schritte durchf√ºhren, um ein DTMF-Signal zu erzeugen und zu dekodieren:\n",
        "1. Erzeugung des Signals und der Audiodatei mit `scipy` und `numpy`. Wir speichern die erzeugte Audiodatei in einer `.wav` Datei, die in diesem Notebook oder in deinem lokalen Audioplayer abgespielt werden kann\n",
        "2. Wir entwerfen eine einfaches KI-Modell ... TODO\n",
        "3. Extraktion der gew√§hlten Tastenfolge aus der `.wav`-Datei unter Verwendung des KI-Modells\n",
        "4. Quantisierung & Export des Modells nach ONNX im FP32 und FP16 Format\n",
        "5. Laufzeit Untersuchungen f√ºr FP16/FP32, unterschiedliche Batch-Gr√∂√üen und Signall√§ngen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXOs32MVVy7"
      },
      "outputs": [],
      "source": [
        "# Trainiere Modell\n",
        "# Konvertiere Modell nach ONNX (einmal FP32, einmal FP16)\n",
        "# Untersuche Laufzeitunterschiede (auch nach batchsize)\n",
        "# Untersuche Abweichungen. Wie √§ndert sich die Fehlerrate des Modells f√ºr FP32/Fp16?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51a6fcd-760a-4926-8d68-7f75eddb906a"
      },
      "source": [
        "## Signal and Audio File Generation <a class=\"anchor\" id=\"part1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9360855-39ba-450f-975b-ebd7f48a5521"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# from collections.abc import Callable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kR8O3oWRKR"
      },
      "outputs": [],
      "source": [
        "# @title Phone Dialer Widget {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize a text widget to display the dial sequence\n",
        "dial_sequence = widgets.Text(\n",
        "    value=\"\",\n",
        "    placeholder=\"Dial sequence will appear here...\",\n",
        "    description=\"Dial Sequence:\",\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width=\"300px\"),\n",
        ")\n",
        "\n",
        "\n",
        "# Function to handle button clicks\n",
        "def on_button_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    dial_sequence.value += b.description\n",
        "\n",
        "\n",
        "# Create buttons for the phone dialer\n",
        "buttons = []\n",
        "for row in [[\"1\", \"2\", \"3\"], [\"4\", \"5\", \"6\"], [\"7\", \"8\", \"9\"], [\"*\", \"0\", \"#\"]]:\n",
        "    button_row = []\n",
        "    for label in row:\n",
        "        button = widgets.Button(\n",
        "            description=label, layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        "        )\n",
        "        button.on_click(on_button_click)\n",
        "        button_row.append(button)\n",
        "    buttons.append(widgets.HBox(button_row))\n",
        "\n",
        "# Create a clear button\n",
        "clear_button = widgets.Button(\n",
        "    description=\"Clear\", layout=widgets.Layout(width=\"160px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "\n",
        "def on_clear_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    dial_sequence.value = \"\"\n",
        "\n",
        "\n",
        "clear_button.on_click(on_clear_click)\n",
        "\n",
        "# Display the dialer\n",
        "display(dial_sequence)\n",
        "for button_row in buttons:\n",
        "    display(button_row)\n",
        "display(clear_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAyM34wYqx_A"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.2, 0.3),\n",
        "    dur_pause=(0.01, 0.1),\n",
        "    noise_factor=(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTrWU67_tbP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62132ef1-c61f-4653-9f6c-a4d9f892781e"
      },
      "outputs": [],
      "source": [
        "wav_file_name = \"my_dtmf_file.wav\"\n",
        "\n",
        "# Either generate a random sequence:\n",
        "# my_dialed_sequence_keys = \"\".join([random.choice(\"1234567890ABCD*#\") for i in range(10)])\n",
        "\n",
        "# ... or use a simple sequence for debugging purposes\n",
        "# my_dialed_sequence_keys = \"1234567890ABCD*#\" # for debug purposes...\n",
        "\n",
        "# ... or use a slightly longer sequence (which also contains all symbols)\n",
        "my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "\n",
        "# Try changing the following arguments: dur_key=0.05, dur_pause=0.02\n",
        "my_dialed_sequence_signal = dtmf_gen.get_tone_sequence(my_dialed_sequence_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWiuyJ_7BUS6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal[: 10**4])\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJe9QX8Ee9aA"
      },
      "outputs": [],
      "source": [
        "quant = np.quantile(my_dialed_sequence_signal, 0.99)\n",
        "start_index = np.where(my_dialed_sequence_signal > quant)[0][10]\n",
        "start_index\n",
        "plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42af11c2-3c15-4a57-afa8-f62b8e82925d"
      },
      "outputs": [],
      "source": [
        "# Now let us listen to the generated WAV file\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "wavfile.write(\n",
        "    wav_file_name,\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (my_dialed_sequence_signal * np.iinfo(np.int32).max).astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(wav_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51a52767-7e0e-444f-8028-f5a52fce4820"
      },
      "outputs": [],
      "source": [
        "print(\"Dialed sequence: \", my_dialed_sequence_keys)\n",
        "print(\"Used symbols: \", len(set(my_dialed_sequence_keys)))\n",
        "print(\"Total length of signal:\", my_dialed_sequence_signal.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b763fef4-360e-4a01-910b-add573007fd3"
      },
      "source": [
        "### Spectrogram of the signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7827a985-0dd0-40c0-993c-e002523ef0e9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "Pxx, freqs, bins, im = plt.specgram(\n",
        "    my_dialed_sequence_signal, NFFT=1024, Fs=dtmf_gen.get_sample_rate()\n",
        ")\n",
        "plt.ylim(0, 2000)\n",
        "plt.xlabel(\"t [s]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "plt.title(\"Spektrogramm des generierten Telefonw√§hlsignals\")\n",
        "plt.show(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_hSCvRHtgy"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AWzMtPVQkgb"
      },
      "outputs": [],
      "source": [
        "# from collections.abc import Callable\n",
        "from collections.abc import Callable\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "N = 128\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(None,1)),\n",
        "        layers.Conv1D(N, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1D(N, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1D(N, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1D(N, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1D(17, kernel_size=1, activation=\"softmax\"),\n",
        "    ])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX1JtkVWTrI5"
      },
      "outputs": [],
      "source": [
        "# from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "model = build_dtmf_classifier_model((None, 1), dtmf_gen.get_num_keys() + 1)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")  # multi-label\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcganU0yPkdG"
      },
      "outputs": [],
      "source": [
        "# model.fit(X_train, Y_train, batch_size=64, epochs=50, validation_data=(X_val, Y_val))\n",
        "model.save(\"model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrpNO97eX3Y"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoeSluZ-MoYQ"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "idx = 9\n",
        "\n",
        "# TODO: Duplicate Code below:\n",
        "pred = model.predict(X_val[idx : idx + 1])\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(X_val[idx, :, 0])\n",
        "\n",
        "for key_idx in range(pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
        "plt.show()\n",
        "\n",
        "wavfile.write(\n",
        "    \"val.wav\",\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (X_val[idx] * np.iinfo(np.int32).max).flatten().astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(\"val.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SozwcF8LNNIZ"
      },
      "outputs": [],
      "source": [
        "# Compute Accuracy\n",
        "pred = model.predict(X_val)\n",
        "thresholded = (pred > 0.5).astype(int)\n",
        "\n",
        "(thresholded == Y_val).sum() / Y_val.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesc3J6SUBOv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "start = time.time()\n",
        "keras_pred = model.predict(my_dialed_sequence_signal.reshape(1, -1, 1))\n",
        "end = time.time()\n",
        "\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "\n",
        "for key_idx in range(keras_pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        keras_pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
        "plt.title(f\"Tats√§chliche Wahlsequenz: {' '.join(list(my_dialed_sequence_keys))}\")\n",
        "plt.show()\n",
        "print(\"Inferenz-Dauer:\", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_zpgnG6CviY"
      },
      "outputs": [],
      "source": [
        "predicted_key_sequence = dtmf_gen.decode_prediction(keras_pred)\n",
        "print(\"Prognostizierte W√§hlsequenz:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0niGbjMEhna"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "\n",
        "# Diese Zelle k√∂nnte einen Fehler werfen.\n",
        "# Dennoch sollte das ONNX Modell korrekt exportiert werden\n",
        "model.output_names = [\"output\"]\n",
        "\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, 2**12, 1], tf.float32, name=\"input\")\n",
        "]  # TODO: time axis fixed or dynamic?\n",
        "# Use from_function for tf functions\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=18)\n",
        "onnx.save(onnx_model, \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-simplifier # TODO: Add to deps"
      ],
      "metadata": {
        "id": "Skoq4dR7koyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxsim\n",
        "\n",
        "model_path = \"dtmf_classifier.onnx\"\n",
        "simplified_model_path = \"dtmf_classifier.onnx\"\n",
        "onnx_model = onnx.load(model_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_simp, check = onnxsim.simplify(onnx_model)\n",
        "assert check, \"Simplified ONNX model could not be validated\"\n",
        "onnx.save(onnx_model_simp, simplified_model_path)"
      ],
      "metadata": {
        "id": "D5PAAutNg2bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9OUrzZa-bgt"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOwr_prgiN4"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "onnx_model = onnx.load(\"dtmf_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    onnx_model,\n",
        "    min_positive_val=1e-7,\n",
        "    max_finite_val=1e4,\n",
        "    keep_io_types=True,\n",
        "    disable_shape_infer=False,\n",
        "    op_block_list=None,\n",
        "    node_block_list=None,\n",
        ")\n",
        "onnx.save(onnx_model_fp16, \"dtmf_classifier_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYcDlVrLqWwx"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_models import DtmfClassifierOnnx\n",
        "\n",
        "# Import tensorrt_libs\n",
        "import tensorrt_libs\n",
        "\n",
        "# FP32 ONNX Model\n",
        "onnx_classifier = DtmfClassifierOnnx(\"dtmf_classifier.onnx\")\n",
        "\n",
        "# FP16 ONNX Model\n",
        "onnx_classifier_fp16 = DtmfClassifierOnnx(\"dtmf_classifier_fp16.onnx\")\n",
        "\n",
        "# FP16 TensorRT Model\n",
        "trt_provider = (\n",
        "        \"TensorrtExecutionProvider\",\n",
        "        {\n",
        "            \"device_id\": 0,  # The device ID\n",
        "            'trt_max_workspace_size': 4e9, # Maximum workspace size for TensorRT engine (1e9 ‚âà 1GB)\n",
        "            \"trt_fp16_enable\": True,\n",
        "            \"trt_int8_enable\": False,\n",
        "            \"trt_int8_use_native_calibration_table\": False,\n",
        "            \"trt_engine_cache_enable\": False,\n",
        "            \"trt_engine_cache_path\": \"./trt_catch_dir\",\n",
        "            #\"trt_profile_opt_shapes\": \"input:32x4096x1\",\n",
        "            #\"trt_profile_min_shapes\": \"input:1x4096x1\",\n",
        "            #\"trt_profile_max_shapes\": \"input:32x4096x1\",\n",
        "        },\n",
        "    )\n",
        "#tensorrt_classifier_fp16 = DtmfClassifierOnnx(\"dtmf_classifier.onnx\", provider=trt_provider)\n",
        "\n",
        "tensorrt_classifier_fp32 = TensorRTInfer(\"dtmf_classifier_fp32_nvidia_l4.trt\")\n",
        "tensorrt_classifier_fp16 = TensorRTInfer(\"dtmf_classifier_fp16_nvidia_l4.trt\")\n",
        "tensorrt_classifier_int8 = TensorRTInfer(\"dtmf_classifier_int8_nvidia_l4.trt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H557RUJyEhf"
      },
      "outputs": [],
      "source": [
        "onnx_prediction = onnx_classifier.predict(\n",
        "    my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        ")\n",
        "predicted_key_sequence = dtmf_gen.decode_prediction(onnx_prediction)\n",
        "print(\"Predicted Sequence:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZZNC80qUvnP"
      },
      "outputs": [],
      "source": [
        "# TODO: TensorRT Execution Provider\n",
        "# TODO: Validate ONNX models and Keras Model on Validation/Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_rvzFHFjpZy"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_models import measure_latency\n",
        "import pandas as pd\n",
        "\n",
        "n_runs = 100\n",
        "n_warmup = 20\n",
        "signal_length = 2**12\n",
        "batch_sizes = [2**i for i in range(11)]\n",
        "# model_dict = {\"keras\": lambda x: sum(np.median(x) for i in range(10)),\n",
        "#         \"onnx\": lambda x: sum(np.median(x) for i in range(5))}\n",
        "model_dict = {\n",
        "    #\"keras\": lambda x: model.predict(x, verbose=0),\n",
        "    #\"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    \"TRT (FP32)\": tensorrt_classifier_fp32.infer,\n",
        "    \"TRT (FP16)\": tensorrt_classifier_fp16.infer,\n",
        "    \"TRT (INT8)\": tensorrt_classifier_int8.infer,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, f_predict in model_dict.items():\n",
        "    print(model_name)\n",
        "    timings = {}\n",
        "    for batch_size in batch_sizes:\n",
        "        tensor_shape = (batch_size, signal_length, 1)\n",
        "        batch_timings = measure_latency(\n",
        "            f_predict, tensor_shape=tensor_shape, n_runs=n_runs, n_warmup=n_warmup\n",
        "        )\n",
        "        timings[batch_size] = batch_timings\n",
        "\n",
        "    df = pd.DataFrame(timings)\n",
        "    results[model_name] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzxwUrIdqNFN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "cmap = plt.get_cmap(\"tab10\")\n",
        "colors = [cmap(i) for i in range(len(results))]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "for (model_name, df), color in zip(results.items(), colors):\n",
        "    # Convert columns to integers for sorting\n",
        "    df.columns = df.columns.astype(int)\n",
        "    df = df[sorted(df.columns)]\n",
        "\n",
        "    # Compute medians and standard deviations\n",
        "    medians = df.median()\n",
        "    stds = df.std()\n",
        "\n",
        "    # X-axis values (sorted batch sizes)\n",
        "    x = medians.index\n",
        "\n",
        "    # Plot with connected points and error bars\n",
        "\n",
        "    plt.errorbar(\n",
        "        x,\n",
        "        medians,\n",
        "        yerr=stds,\n",
        "        fmt=\"-o\",\n",
        "        capsize=5,\n",
        "        color=color,\n",
        "        ecolor=color,\n",
        "        elinewidth=2,\n",
        "        markerfacecolor=\"white\",\n",
        "        label=model_name,\n",
        "    )\n",
        "\n",
        "# Make it pretty\n",
        "plt.xlabel(\"Batch-Gr√∂√üe\")\n",
        "plt.ylabel(\"Latenz [s]\")\n",
        "plt.title(\"TODO\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6, which=\"both\")\n",
        "# plt.xticks(x)\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.xscale(\"log\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb6KDq61AI_G"
      },
      "outputs": [],
      "source": [
        "# import onnx\n",
        "# Load the ONNX model\n",
        "# model_path = \"dtmf_classifier.onnx\"\n",
        "# model = onnx.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzrpNGACjEDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl6erovhKUfL"
      },
      "outputs": [],
      "source": [
        "from onnxruntime.quantization.shape_inference import quant_pre_process\n",
        "\n",
        "quant_pre_process(\"dtmf_classifier.onnx\", \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dIsBgCdAk-U"
      },
      "outputs": [],
      "source": [
        "from onnxruntime.quantization import (\n",
        "    quantize_dynamic,\n",
        "    QuantType,\n",
        "    CalibrationDataReader,\n",
        "    quantize_static,\n",
        "    QuantFormat,\n",
        "    quantize_dynamic,\n",
        ")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    def __init__(self):\n",
        "        # self.data = calibration_data\n",
        "        # self.data_iter = iter(self.data)\n",
        "        self.counter = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.counter >= 10:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X, _ = dtmf_gen.generate_dataset(n_samples=64, t_length=2**12)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data = None\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "# Quantize the model\n",
        "quantized_model_path = \"dtmf_classifier_int8.onnx\"\n",
        "\n",
        "quantize_static(\n",
        "    # quantize_dynamic(\n",
        "    \"dtmf_classifier_pre.onnx\",\n",
        "    quantized_model_path,\n",
        "    calibration_data_reader,\n",
        "    # quant_format=QuantFormat.QOperator\n",
        "    # quant_format=QuantType.QInt8,\n",
        "    # per_channel=True,\n",
        "    # weight_type=QuantType.QInt8,\n",
        "    # optimize_model=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUvZQOpBDmME"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "\n",
        "# Load the quantized model\n",
        "quantized_model = ort.InferenceSession(quantized_model_path)\n",
        "\n",
        "# Run inference with the quantized model\n",
        "X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=2**10)\n",
        "input_name = quantized_model.get_inputs()[0].name\n",
        "output_name = quantized_model.get_outputs()[0].name\n",
        "\n",
        "result = quantized_model.run([output_name], {input_name: X.astype(np.float32)})[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk0jgMEAE8a6"
      },
      "outputs": [],
      "source": [
        "thresholded = (result > 0.5).astype(int)\n",
        "(thresholded == Y).sum() / Y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onROy1OoTfL_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOiAOUUfH7oQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2P3-yuoH7w8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorRT Tests"
      ],
      "metadata": {
        "id": "FGuwxgoDkgGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gpu_type():\n",
        "  import torch\n",
        "  if not torch.cuda.is_available():\n",
        "    return \"cpu\"\n",
        "  return \"_\".join(torch.cuda.get_device_name(0).lower().split(\" \"))"
      ],
      "metadata": {
        "id": "a3of1tuYcNrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.2, 0.3),\n",
        "    dur_pause=(0.01, 0.1),\n",
        "    noise_factor=(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ],
      "metadata": {
        "id": "fSJVcrVW6gPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "from cuda import cudart\n",
        "from cuda import cuda, cudart\n",
        "\n",
        "def check_cuda_err(err):\n",
        "    if isinstance(err, cuda.CUresult):\n",
        "        if err != cuda.CUresult.CUDA_SUCCESS:\n",
        "            raise RuntimeError(\"Cuda Error: {}\".format(err))\n",
        "    if isinstance(err, cudart.cudaError_t):\n",
        "        if err != cudart.cudaError_t.cudaSuccess:\n",
        "            raise RuntimeError(\"Cuda Runtime Error: {}\".format(err))\n",
        "    else:\n",
        "        raise RuntimeError(\"Unknown error type: {}\".format(err))\n",
        "\n",
        "def cuda_call(call):\n",
        "    err, res = call[0], call[1:]\n",
        "    check_cuda_err(err)\n",
        "    if len(res) == 1:\n",
        "        res = res[0]\n",
        "    return res\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_host_to_device(device_ptr: int, host_arr: np.ndarray):\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(cudart.cudaMemcpy(device_ptr, host_arr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice))\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_device_to_host(host_arr: np.ndarray, device_ptr: int):\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(cudart.cudaMemcpy(host_arr, device_ptr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost))\n",
        "\n",
        "\n",
        "class MNISTEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    def __init__(self, training_data, cache_file, batch_size=16):\n",
        "        # Whenever you specify a custom constructor for a TensorRT class,\n",
        "        # you MUST call the constructor of the parent explicitly.\n",
        "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
        "\n",
        "        self.cache_file = cache_file\n",
        "\n",
        "        # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n",
        "        #self.data = 2 * np.random.rand(32*batch_size, 2**12, 1).astype(np.float32) - 1.0\n",
        "        # self.data = training_data\n",
        "        self.data = dtmf_gen.generate_dataset(n_samples=32*batch_size, t_length=2**12, with_labels=None).astype(np.float32)\n",
        "        #print(self.data.dtype)\n",
        "        #self.data = self.data.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "        self.current_index = 0\n",
        "\n",
        "        # Allocate enough memory for a whole batch.\n",
        "        #self.device_input = cuda.mem_alloc(self.data[0].nbytes * self.batch_size)\n",
        "        n_bytes = self.data[0].nbytes * self.batch_size\n",
        "        # print(\"n_bytes\", n_bytes)\n",
        "        self.device_input = cuda_call(cudart.cudaMalloc(n_bytes))\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
        "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
        "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
        "    def get_batch(self, names):\n",
        "        # print(\"names:\", names)\n",
        "        if self.current_index + self.batch_size > self.data.shape[0]:\n",
        "            return None\n",
        "\n",
        "        current_batch = int(self.current_index / self.batch_size)\n",
        "        if current_batch % 10 == 0:\n",
        "            print(\"Calibrating batch {:}, containing {:} images\".format(current_batch, self.batch_size))\n",
        "\n",
        "        batch = self.data[self.current_index:self.current_index + self.batch_size].ravel()\n",
        "        #cuda.memcpy_htod(self.device_input, batch)\n",
        "        #memcpy_host_to_device(self.device_input, batch)\n",
        "        memcpy_host_to_device(self.device_input, np.ascontiguousarray(batch)\n",
        "            )\n",
        "        self.current_index += self.batch_size\n",
        "        # print(\"Schalom!\")\n",
        "        return [int(self.device_input)]\n",
        "\n",
        "\n",
        "    def read_calibration_cache(self):\n",
        "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
        "        if os.path.exists(self.cache_file):\n",
        "            with open(self.cache_file, \"rb\") as f:\n",
        "                return f.read()\n",
        "\n",
        "    def write_calibration_cache(self, cache):\n",
        "        return None # for now\n",
        "        with open(self.cache_file, \"wb\") as f:\n",
        "            f.write(cache)"
      ],
      "metadata": {
        "id": "l5sW5xE4y3Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
        "\n",
        "\n",
        "# The Onnx path is used for Onnx models.\n",
        "def build_engine_onnx(model_file, trt_engine_path, precision):\n",
        "    seq_len = 2**12\n",
        "    max_batch_size = [1,2,4,8,16,32,64,128,256,512, 1024]\n",
        "    calibration_batch_size = 16\n",
        "    builder = trt.Builder(TRT_LOGGER)\n",
        "    network = builder.create_network(0)\n",
        "    config = builder.create_builder_config()\n",
        "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 8*1<<30) # TODO: Constant\n",
        "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "    with open(model_file, \"rb\") as model:\n",
        "        if not parser.parse(model.read()):\n",
        "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
        "            for error in range(parser.num_errors):\n",
        "                print(parser.get_error(error))\n",
        "            return None\n",
        "\n",
        "    for b in max_batch_size:\n",
        "      profile = builder.create_optimization_profile()\n",
        "      profile.set_shape(\"input\", [1,seq_len,1], [b,seq_len,1], [b,seq_len,1])\n",
        "      config.add_optimization_profile(profile)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if precision in [\"fp16\", \"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_fp16:\n",
        "            print(\"FP16 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.FP16)\n",
        "    if precision in [\"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_int8:\n",
        "            print(\"INT8 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.INT8)\n",
        "        # config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "\n",
        "        calib = MNISTEntropyCalibrator(\"\", cache_file=\"cache.file\", batch_size=calibration_batch_size)\n",
        "        config.int8_calibrator = calib\n",
        "\n",
        "        calib_profile = builder.create_optimization_profile()\n",
        "        calib_profile.set_shape(\"input\", [calibration_batch_size,seq_len,1], [calibration_batch_size,seq_len,1], [calibration_batch_size,seq_len,1])\n",
        "        config.set_calibration_profile(calib_profile)\n",
        "        config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
        "\n",
        "        print(\"int 8 model\")\n",
        "\n",
        "    engine_bytes = builder.build_serialized_network(network, config)\n",
        "\n",
        "    if engine_bytes is None:\n",
        "        print(\"Failed to create the TensorRT engine\")\n",
        "        return None\n",
        "    runtime = trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "    # Save the engine to a file\n",
        "    with open(trt_engine_path, \"wb\") as f:\n",
        "        f.write(engine_bytes)\n",
        "\n",
        "    print(f\"TensorRT engine saved to {trt_engine_path}\")\n",
        "\n",
        "    #return runtime.deserialize_cuda_engine(engine_bytes)\n",
        "\n",
        "# Example Usage\n",
        "precision = \"fp32\"\n",
        "onnx_path = \"dtmf_classifier.onnx\"\n",
        "trt_path = \"dtmf_classifier_\"+ precision + \"_\" + get_gpu_type() + \".trt\"\n",
        "build_engine_onnx(onnx_path, trt_path, precision=precision)\n"
      ],
      "metadata": {
        "id": "J6k2njAel4z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "def print_dbg(*x):\n",
        "  if DEBUG:\n",
        "    print(x)\n",
        "\n",
        "class TensorRTInfer:\n",
        "  # TODO: This code still has a memory leak. The memory allocated by\n",
        "  # cudaMalloc has to be released!\n",
        "    \"\"\"\n",
        "    Implements inference for the TensorRT engine.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, engine_path):\n",
        "        \"\"\"\n",
        "        :param engine_path: The path to the serialized engine to load from disk.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load TRT engine\n",
        "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
        "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
        "        with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
        "            assert runtime\n",
        "            self.engine = runtime.deserialize_cuda_engine(f.read())\n",
        "        assert self.engine\n",
        "        self.context = self.engine.create_execution_context()\n",
        "        assert self.context\n",
        "\n",
        "        # Some Infos about the engine\n",
        "        print_dbg(\"num optimization profiles:\", self.engine.num_optimization_profiles)\n",
        "        print_dbg(\"num io tensors:\", self.engine.num_io_tensors)\n",
        "\n",
        "        # Create CUDA stream for asynchronous tasks\n",
        "        _, self.stream = cudart.cudaStreamCreate()\n",
        "\n",
        "        # Setup I/O bindings\n",
        "        self.inputs = []\n",
        "        self.outputs = []\n",
        "        self.allocations = []\n",
        "        for prof_idx in range(self.engine.num_optimization_profiles):\n",
        "          for i in range(self.engine.num_io_tensors):\n",
        "              name = self.engine.get_tensor_name(i)\n",
        "              is_input = False\n",
        "              if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
        "                  is_input = True\n",
        "              dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))\n",
        "              shape = self.engine.get_tensor_shape(name)\n",
        "              if is_input and shape[0] < 0:\n",
        "                  assert self.engine.num_optimization_profiles > 1\n",
        "                  profile_shape = self.engine.get_tensor_profile_shape(name, prof_idx)\n",
        "                  print_dbg(\"profile_shape\", name, profile_shape)\n",
        "                  assert len(profile_shape) == 3  # min,opt,max\n",
        "\n",
        "                  # Set the *max* profile as binding shape\n",
        "                  self.switch_profile(prof_idx)\n",
        "                  self.context.set_input_shape(name, profile_shape[2])\n",
        "                  shape = self.context.get_tensor_shape(name)\n",
        "\n",
        "              if not is_input:\n",
        "                shape = self.context.get_tensor_shape(name)\n",
        "                print_dbg(\"shape for output:\", name, shape)\n",
        "\n",
        "              if is_input:\n",
        "                  self.batch_size = shape[0]\n",
        "              size = dtype.itemsize\n",
        "              for s in shape:\n",
        "                  size *= s\n",
        "              allocation = cuda_call(cudart.cudaMalloc(size))\n",
        "              host_allocation = None if is_input else np.zeros(shape, dtype)\n",
        "              binding = {\n",
        "                  \"index\": i,\n",
        "                  \"name\": name,\n",
        "                  \"dtype\": dtype,\n",
        "                  \"shape\": list(shape),\n",
        "                  \"allocation\": allocation,\n",
        "                  \"host_allocation\": host_allocation,\n",
        "              }\n",
        "              self.allocations.append(allocation)\n",
        "              if is_input:\n",
        "                  self.inputs.append(binding)\n",
        "              else:\n",
        "                  self.outputs.append(binding)\n",
        "              print_dbg(\n",
        "                  \"{} '{}' with shape {} and dtype {}\".format(\n",
        "                      \"Input\" if is_input else \"Output\",\n",
        "                      binding[\"name\"],\n",
        "                      binding[\"shape\"],\n",
        "                      binding[\"dtype\"],\n",
        "                  )\n",
        "              )\n",
        "          print_dbg()\n",
        "\n",
        "        assert self.batch_size > 0\n",
        "        assert len(self.inputs) > 0\n",
        "        assert len(self.outputs) > 0\n",
        "        assert len(self.allocations) > 0\n",
        "\n",
        "\n",
        "\n",
        "    def input_spec(self):\n",
        "        \"\"\"\n",
        "        Get the specs for the input tensor of the network. Useful to prepare memory allocations.\n",
        "        :return: Two items, the shape of the input tensor and its (numpy) datatype.\n",
        "        \"\"\"\n",
        "        # TODO: Index 0 is wrong\n",
        "        return self.inputs[0][\"shape\"], self.inputs[0][\"dtype\"]\n",
        "\n",
        "    def output_spec(self):\n",
        "        \"\"\"\n",
        "        Get the specs for the output tensors of the network. Useful to prepare memory allocations.\n",
        "        :return: A list with two items per element, the shape and (numpy) datatype of each output tensor.\n",
        "        \"\"\"\n",
        "        specs = []\n",
        "        for o in self.outputs:\n",
        "            specs.append((o[\"shape\"], o[\"dtype\"]))\n",
        "        return specs\n",
        "\n",
        "    def switch_profile(self, idx: int):\n",
        "      self.context.set_optimization_profile_async(idx, self.stream)  # Switch to profile 1 (index 1)\n",
        "\n",
        "    def infer(self, batch):\n",
        "        \"\"\"\n",
        "        Execute inference on a batch of images.\n",
        "        :param batch: A numpy array holding the image batch.\n",
        "        :return A list of outputs as numpy arrays.\n",
        "        \"\"\"\n",
        "\n",
        "        # If the optimization profile does not match, change it here:\n",
        "          # In out setup the opt. profiles are selected in a wa that the\n",
        "          # optimal batch sizes are powers of 2. In practice, one would not do\n",
        "          # it in this way:\n",
        "        expected_profile = int(np.log2(batch.shape[0]))\n",
        "        if self.context.active_optimization_profile != expected_profile:\n",
        "          print(\"Chaninging to profile\", expected_profile)\n",
        "          self.switch_profile(expected_profile)\n",
        "\n",
        "        if self.context.get_tensor_shape(\"input\") != batch.shape:\n",
        "          print(\"Changing batch size for inference!\")\n",
        "\n",
        "          # Adapt the input shape:\n",
        "          self.context.set_input_shape(\"input\", batch.shape)\n",
        "        print_dbg(\"self.engine.get_tensor_shape(input)\", self.engine.get_tensor_shape(\"input\"))\n",
        "        print_dbg(\"self.context.get_tensor_shape(input)\", self.context.get_tensor_shape(\"input\"))\n",
        "        print_dbg(\"self.context.get_tensor_shape(output)\", self.context.get_tensor_shape(\"output\"))\n",
        "        print_dbg()\n",
        "\n",
        "        o_idx = self.context.active_optimization_profile\n",
        "        print_dbg(\"Active output index (opt. profile)\", o_idx)\n",
        "\n",
        "        # Copy I/O and Execute\n",
        "        memcpy_host_to_device(self.inputs[o_idx][\"allocation\"], batch)\n",
        "\n",
        "        self.context.execute_v2(self.allocations)\n",
        "        memcpy_device_to_host(\n",
        "                self.outputs[o_idx][\"host_allocation\"], self.outputs[o_idx][\"allocation\"]\n",
        "            )\n",
        "\n",
        "        return [self.outputs[o_idx][\"host_allocation\"]]\n",
        "\n",
        "def main():\n",
        "    seq_len = 2**12\n",
        "    trt_infer = TensorRTInfer(trt_path)\n",
        "\n",
        "    print(\"Starting inference\")\n",
        "    if False:\n",
        "      spec = trt_infer.input_spec()\n",
        "      print(\"spec\", spec)\n",
        "      # batch = my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        "      X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=seq_len)\n",
        "      o = trt_infer.infer(X.astype(np.float32))[0][:X.shape[0]]\n",
        "      print(\"o.shape\", o.shape)\n",
        "\n",
        "      thresholded = (o > 0.5).astype(int)\n",
        "      print( (thresholded == Y).sum() / Y.size )\n",
        "      for iidx in range(X.shape[0]):\n",
        "        predicted_key_sequence = dtmf_gen.decode_prediction(o[iidx])\n",
        "        original_key_sequence = dtmf_gen.decode_prediction(Y[iidx])\n",
        "        if predicted_key_sequence != original_key_sequence:\n",
        "          print(\"predicted_key_sequence\", predicted_key_sequence)\n",
        "          print(\"original_key_sequence\", original_key_sequence)\n",
        "      print(\"Done!\")\n",
        "    else:\n",
        "        print(\"No input provided, running in benchmark mode\")\n",
        "        trt_infer.switch_profile(1)\n",
        "        spec = trt_infer.input_spec()\n",
        "        # TODO:\n",
        "        spec = (1,4096,1), np.float32\n",
        "\n",
        "        batch = np.random.rand(*spec[0]).astype(spec[1])\n",
        "        print(\"batch.shape\", batch.shape)\n",
        "        print(\"batch.dtype\", batch.dtype)\n",
        "        print(\"min/max/mean\", batch.min(), batch.max(), batch.mean())\n",
        "        iterations = 100\n",
        "        times = []\n",
        "        for i in range(20):  # GPU warmup iterations\n",
        "            trt_infer.infer(batch)\n",
        "        for i in range(iterations):\n",
        "            start = time.time()\n",
        "            o = trt_infer.infer(batch)\n",
        "            #print(\"o.shape\", o[0].shape)\n",
        "            times.append(time.time() - start)\n",
        "            print(\"Iteration {} / {}\".format(i + 1, iterations), end=\"\\r\")\n",
        "        print(\"Benchmark results include time for H2D and D2H memory copies\")\n",
        "        print(\"Average Latency: {:.3f} ms\".format(1000 * np.average(times)))\n",
        "        print(\n",
        "            \"Average Throughput: {:.1f} ips\".format(\n",
        "                trt_infer.batch_size / np.average(times)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    print()\n",
        "    print(\"Finished Processing\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VY4AP6jrmJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRTExec"
      ],
      "metadata": {
        "id": "jgfqAPHRf7OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a\n",
        "!cat /etc/os-release\n",
        "!ls -l /usr/local\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8dNOfG_zsJAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/NVIDIA/TensorRT.git"
      ],
      "metadata": {
        "id": "oNF6VAAXf9c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export LD_LIBRARY_PATH=/usr/local/lib/python3.11/dist-packages/tensorrt_libs/"
      ],
      "metadata": {
        "id": "5bmGz0fzgCD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt\n",
        "tensorrt.__version__"
      ],
      "metadata": {
        "id": "6-LkjeFSqfDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export LD_LIBRARY_PATH=/usr/local/lib/python3.11/dist-packages/tensorrt_libs/ && \\\n",
        "./trtexec --onnx=dtmf_classifier.onnx"
      ],
      "metadata": {
        "id": "j61a8sHE6UQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhtGJcVZ8ag7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ayEwe5ir9LAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with different Data Types"
      ],
      "metadata": {
        "id": "PKxcfRC-l55h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyFnYjTSIBz-"
      },
      "outputs": [],
      "source": [
        "# Load cuDNN libraries\n",
        "import ctypes\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "from nvidia import cudnn\n",
        "\n",
        "\n",
        "def try_load(library):\n",
        "    try:\n",
        "        ctypes.CDLL(\n",
        "            library, mode=ctypes.RTLD_GLOBAL\n",
        "        )  # Use RTLD_GLOBAL to make symbols available\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "\n",
        "def try_load_libs_from_dir(path):\n",
        "    # Load all .so files (Linux)\n",
        "    for lib in glob.iglob(os.path.join(path, \"*.so*\")):\n",
        "        print(\"try:\", lib)\n",
        "        try_load(lib)\n",
        "\n",
        "\n",
        "# Get the cudnn library path\n",
        "CUDNN_LIB_DIR = os.path.join(cudnn.__path__[0], \"lib\")\n",
        "print(CUDNN_LIB_DIR)\n",
        "\n",
        "# Try loading all libraries in the cudnn lib directory\n",
        "# try_load_libs_from_dir(CUDNN_LIB_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbQfmvwtIUei"
      },
      "outputs": [],
      "source": [
        "# Import tensorrt_libs\n",
        "import tensorrt_libs\n",
        "\n",
        "# Import ONNX dependencies\n",
        "import onnxruntime as ort  # Import the ONNX Runtime\n",
        "from onnxruntime.tools.symbolic_shape_infer import SymbolicShapeInference\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    CalibrationMethod,\n",
        "    create_calibrator,\n",
        "    write_calibration_table,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNDD5F2_c3Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pbX5_v4da18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PmebktFfdSr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av7uiBncTrdZ"
      },
      "outputs": [],
      "source": [
        "ort.get_available_providers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXvqz8RSJH_P"
      },
      "outputs": [],
      "source": [
        "providers = [\n",
        "    (\n",
        "        \"TensorrtExecutionProvider\",\n",
        "        {\n",
        "            \"device_id\": 0,  # The device ID\n",
        "            'trt_max_workspace_size': 4e9, # Maximum workspace size for TensorRT engine (1e9 ‚âà 1GB)\n",
        "            \"trt_fp16_enable\": False,\n",
        "            \"trt_int8_enable\": True,\n",
        "            \"trt_int8_use_native_calibration_table\": False,\n",
        "            \"trt_engine_cache_enable\": False,\n",
        "            \"trt_engine_cache_path\": \"./trt_catch_dir\",\n",
        "            #\"trt_profile_opt_shapes\": \"input:1x4096\",\n",
        "            #\"trt_profile_min_shapes\": \"input:1x4096\",\n",
        "            #\"trt_profile_max_shapes\": \"input:2x4096\",\n",
        "        },\n",
        "    )\n",
        "]\n",
        "\n",
        "sess_opt = ort.SessionOptions()\n",
        "sess_opt.log_severity_level = 0  # 0 is the most verbose level\n",
        "sess_opt.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "# sess_opt.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
        "\n",
        "# Load the model and create an InferenceSession\n",
        "session = ort.InferenceSession(\n",
        "    \"dtmf_classifier.onnx\", sess_options=sess_opt, providers=providers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIIulQNILIaO"
      },
      "outputs": [],
      "source": [
        "# Run inference with the quantized model\n",
        "X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=2**12)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "result = session.run([output_name], {input_name: X[0:1].astype(np.float32)})[0]\n",
        "# result = session.run([output_name], {input_name: np.ones( (5,1) ).astype(np.float32)})[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twzCNuMFrgvd"
      },
      "outputs": [],
      "source": [
        "# <TODO>: Add custom ONNX layer which does the pre-scaling of the input signal...\n",
        "# and post-processing: rle of the signal, discard keys which are short than 23 ms\n",
        "# Save inference times of each algo in a csv file (in case of a crash)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDOsXA3oy3Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7Cuomwoy3UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Experiments with Data Types"
      ],
      "metadata": {
        "id": "4y0ndHlTcqzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlBaeR_oBUS7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.float_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frFXsleBYGPT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def float_to_binary_fp32(num: float) -> str:\n",
        "    \"\"\"Converts a built-in floating point number (64-bit) to its FP32 binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the floating point number.\n",
        "    \"\"\"\n",
        "    print(\"fp32:\", num)\n",
        "    return \"\".join(f\"{c:0>8b}\" for c in struct.pack(\"!f\", num))\n",
        "\n",
        "\n",
        "def float_to_binary_fp16(num: float) -> str:\n",
        "    \"\"\"Converts a builtin-in floating point number to a 16-bit floating point number and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the 16-bit floating point number.\n",
        "    \"\"\"\n",
        "    # Convert the number to a float16\n",
        "    float16_num = np.float16(num)\n",
        "\n",
        "    print(\"fp16:\", float16_num)\n",
        "\n",
        "    # Convert the float16 to bytes\n",
        "    float16_bytes = float16_num.tobytes()\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(float16_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_bf16(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to bfloat16  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the bfloat16 floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to bfloat16\n",
        "    bf = a.bfloat16()\n",
        "\n",
        "    print(\"bf16\", bf)\n",
        "\n",
        "    # Convert the bfloat16 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(bf_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e4m3(num: float) -> str:\n",
        "    \"\"\"Converts a  floating point number to float8 (e4m3) and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e4m3) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e4m3)\n",
        "    bf = a.to(torch.float8_e4m3fn)\n",
        "\n",
        "    print(\"fp8_e4m3\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e5m2(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to float8 (e5m2)  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e5m2) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e5m2)\n",
        "    bf = a.to(torch.float8_e5m2)\n",
        "\n",
        "    print(\"fp8_e5m2\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_int(num: float, bit_length: int = 8) -> str:\n",
        "    \"\"\"Converts a floating point number to its binary representation as an integer.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "        bit_length (int, optional): The bit length of the binary representation. Defaults to 8.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the integer part of the floating point number.\n",
        "    \"\"\"\n",
        "    return np.binary_repr(round(num), width=bit_length)\n",
        "\n",
        "\n",
        "num = -8.875074538462327 - 2**-7 - 2**-8\n",
        "float_to_binary_fp32(num)\n",
        "# float_to_binary_fp16(num)\n",
        "# float_to_binary_bf16(num)\n",
        "# float_to_binary_fp8_e4m3(num)\n",
        "# float_to_binary_fp8_e5m2(num)\n",
        "# float_to_binary_int(num, bit_length=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubud1lCaBUS8"
      },
      "outputs": [],
      "source": [
        "-num - 2**3 - 2**-1 - 2**-2 - 2**-3 - 2**-7 - 2**-8\n",
        "\n",
        "\n",
        "(int(\"1111011100011101\", base=2) - 2**16) / 2**8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-X1F7z9BUS8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "s = \"1100100001111100\"\n",
        "b = int(s, base=2).to_bytes(2, \"little\")\n",
        "print(b)\n",
        "c = np.frombuffer(b, dtype=np.float16, count=1)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjV-2lyBUS9"
      },
      "outputs": [],
      "source": [
        "# Binary string\n",
        "binary_string = \"11000001000011111000101100101011\"\n",
        "\n",
        "# Convert the binary string to an integer\n",
        "binary_int = int(binary_string, 2)\n",
        "\n",
        "# Convert the integer to bytes (4 bytes for float32)\n",
        "binary_bytes = binary_int.to_bytes(4, byteorder=\"big\")\n",
        "\n",
        "# Unpack the bytes to a float\n",
        "float_value = struct.unpack(\">f\", binary_bytes)[0]\n",
        "\n",
        "print(float_value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}