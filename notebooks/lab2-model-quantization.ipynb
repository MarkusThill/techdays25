{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MarkusThill/techdays25/blob/feature-lab2-initial-draft/notebooks/lab2-model-quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKWrVTJSVVy4"
   },
   "source": [
    "# üöÄ Lab 2: Effiziente Quantisierung tiefer neuronaler Netze\n",
    "- Dieses Jupyter Notebook **ben√∂tigt eine GPU Laufzeit**. Falls nicht bereits voreingestellt, kann daher der Laufzeittyp im Men√º unter \"Laufzeit\" > \"Laufzeittyp √§ndern\" > \"Hardwarebeschleuniger\" > **\"T4 GPU\"** ge√§ndert werden!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2hhcmOjXQXB"
   },
   "source": [
    "Strukturierung:\n",
    "- Teil 1: Darstellung numerischer Datentypen\n",
    "- Teil 2:\n",
    "  - Quantisierung des einfachen Modells aus Lab 1\n",
    "  - Diverse Betrachtungen auf dem quantisierten Modell (Genauigkeit, etc.)\n",
    "  - Gotchas (Optional): Overflow/Underflow am Beispiel eines Average Pooling layers\n",
    "  - Subnormal Numbers\n",
    "  - ...\n",
    "- Teil 3: Quantisierung eines DTMF Klassifikationsmodells\n",
    "  - Illustration: Erzeugung einer DTMF W√§hlsequenz und Abspielen derselben\n",
    "  - Laden eines vortrainierten DTMF-Klassifikationsmodells (ConvNet; Keras oder PyTorch)\n",
    "  - Konvertierung nach ONNX\n",
    "  - Quantisierung nach FP16\n",
    "  - Messung der Inferenzzeiten (auch f√ºr verschiedene Batch-Sizes) und vergleich von FP32, FP16-Modell\n",
    "  - Vergleich der Genauigkeit von FP16 und FP32 Modell (wie √§ndert sich die Fehlerrate)\n",
    "  - Optional: Konvertierung nach FP8 und Wiederholung der obigen Schritte\n",
    "  - Optional: Profiling der ONNX Modelle. Wo liegen die \"Hotspots\" des Modells?\n",
    "  - Optional: Trainieren des Modells auf de\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHjiyBN9VVy4"
   },
   "source": [
    "# Vorbereitungen: Installation der n√∂tigen Abh√§ngigkeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zRp0QsBVVy5"
   },
   "outputs": [],
   "source": [
    "# Remove the `%%capture`, if you have the impression that something is going wrong during the setup\n",
    "# %%capture\n",
    "!pip install \"techdays25[lab2] @ git+https://github.com/MarkusThill/techdays25.git@feature-lab2-initial-draft\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PetUdSKZVVy5"
   },
   "source": [
    "**WICHTIG: Nach der Installation der Abh√§ngigkeiten (siehe oben) muss die Google Colab Laufzeit neugestartet werden! Im Anschluss kann mit der Ausf√ºhrung der n√§chsten Zellen fortgefahren werden werden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gf2wjy7rVVy5"
   },
   "outputs": [],
   "source": [
    "# @title Colab-spezifische Konfigurationen {display-mode: \"form\"}\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import output\n",
    "\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPuTmcJKVVy5"
   },
   "source": [
    "# üìò Einleitung\n",
    "- DTMF\n",
    "- Quanstisierungsans√§tze\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-emxsEEVVy5"
   },
   "source": [
    "# üìñ Teil 1: Darstellung numerischer Datentypen\n",
    "- Zweierkomplementdarstellung\n",
    "- IEEE-754 Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0MW1AnSVVy5"
   },
   "source": [
    "### Ganzahldarstellungen/Zweierkomplementdarstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfRcqICXVVy5"
   },
   "outputs": [],
   "source": [
    "# @title Darstellung von 8-Bit Integer Zahlen {display-mode: \"form\"}\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Initialize 8 toggle buttons (bits, MSB to LSB)\n",
    "bit_toggles = [\n",
    "    widgets.ToggleButton(\n",
    "        value=False, description=\"0\", layout=widgets.Layout(width=\"40px\")\n",
    "    )\n",
    "    for _ in range(8)\n",
    "]\n",
    "\n",
    "# Output widget to show results\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def twos_complement(bits: list[int]) -> int:\n",
    "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
    "\n",
    "    Args:\n",
    "        bits (list[int]): A list of bits representing the binary number.\n",
    "\n",
    "    Returns:\n",
    "        int: The signed integer value of the binary number.\n",
    "    \"\"\"\n",
    "    if bits[0] == 0:\n",
    "        return int(\"\".join(str(b) for b in bits), 2)\n",
    "    # If MSB is 1, it's negative\n",
    "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
    "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
    "    return -incremented\n",
    "\n",
    "\n",
    "def update_display(*args) -> None:\n",
    "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
    "    # Read bit values (MSB to LSB)\n",
    "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
    "    bit_string = \"\".join(str(b) for b in bit_values)\n",
    "\n",
    "    # Unsigned decimal value\n",
    "    unsigned_decimal = int(bit_string, 2)\n",
    "\n",
    "    # Signed decimal value (two's complement)\n",
    "    signed_decimal = twos_complement(bit_values)\n",
    "\n",
    "    # Hex representation (2 hex digits for 8 bits)\n",
    "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
    "\n",
    "    # Clear previous output and update\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        display(\n",
    "            HTML(f\"\"\"\n",
    "        <h3>\n",
    "            Binary: <code>{bit_string}</code><br>\n",
    "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
    "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
    "            Hexadecimal: <b>{hex_value}</b>\n",
    "        </h3>\n",
    "        \"\"\")\n",
    "        )\n",
    "\n",
    "    # Update button labels (0/1)\n",
    "    for btn, value in zip(bit_toggles, bit_values):\n",
    "        btn.description = str(value)\n",
    "\n",
    "\n",
    "# Attach observer to all buttons\n",
    "for btn in bit_toggles:\n",
    "    btn.observe(update_display, \"value\")\n",
    "\n",
    "# Display widget\n",
    "display(widgets.HBox(bit_toggles))\n",
    "display(output)\n",
    "\n",
    "# Initialize display\n",
    "update_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDlSxZqOVVy6"
   },
   "source": [
    "#### √úbungsfragen (Optional):\n",
    "- Grundlegendes Setzen von Bits: Setze das 3. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
    "Erwartete Antwort: 4\n",
    "\n",
    "- Setzen mehrerer Bits: Setze das 1., 3. und 5. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
    "Erwartete Antwort: 21\n",
    "\n",
    "- Was ist die gr√∂√ütm√∂gliche bzw. kleinstm√∂gliche Zahl die mit 8 Bit dargestellt werden k√∂nnen? Antwort: -128, +127\n",
    "  - Was w√§re die Antwort, wenn wir statt 8-bit Integer, nun 32-bit Integer haben?\n",
    "\n",
    "- Signed vs. Unsigned Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
    "Erwartete Antwort: Signed: -128, Unsigned: 128\n",
    "\n",
    "- Was charakterisiert eine negative Zahl in der Zweierkomplementdarstellung (unsigned integer) im Allgmeinen? Antwort: Zumindest das vorderste Bit ist gesetzt.\n",
    "\n",
    "- Wie negiere ich eine Zahl (z.B. 32 -> -32 bzw. -71 -> 71)? Antwort: Invertieren alle Bits und Addition  von 1\n",
    "\n",
    "- Angenommen ich habe -33 als 8-bit Zahl vorliegen. Wie w√ºrde ich daraus eine 32-bit unsigned Integer Zahl machen? Antwort: Einfach noch drei Bytes voranh√§ngen in denen alle Bits gesetzt sind.\n",
    "\n",
    "- Kombinieren von Bits: Setze das 2., 4. und 6. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
    "Erwartete Antwort: Signed: 42, Unsigned: 42\n",
    "\n",
    "- Negative Zahlen in der Signed-Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) und das 1. Bit (niederwertigstes Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
    "Erwartete Antwort: Signed: -127, Unsigned: 129\n",
    "\n",
    "- Maximale und minimale Werte: Was ist der maximale Wert, den man mit einer 8-Bit unsigned Zahl darstellen kann? Was ist der minimale Wert, den man mit einer 8-Bit signed Zahl darstellen kann?\n",
    "Erwartete Antwort: Maximale unsigned: 255, Minimale signed: -128\n",
    "\n",
    "- Bitmuster und Werte: Setze die Bits, um die Bin√§rzahl 10101010 zu bilden. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
    "Erwartete Antwort: Signed: -86, Unsigned: 170\n",
    "\n",
    "- Alle Bits gesetzt: Setze alle Bits einer 8-Bit-Zahl auf 1. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
    "Erwartete Antwort: Signed: -1, Unsigned: 255\n",
    "\n",
    "\n",
    "- Verst√§ndnis von √úberlauf: Was passiert, wenn du 1 zum maximalen Wert einer 8-Bit unsigned Zahl hinzuf√ºgst? Was passiert bei einer 8-Bit signed Zahl?\n",
    "Erwartete Antwort: Bei unsigned wird es auf 0 zur√ºckgesetzt. Bei signed verursacht es einen √úberlauf und wird auf den minimalen Wert (-128) zur√ºckgesetzt.\n",
    "Zweierkomplement:\n",
    "\n",
    "- Erkl√§re, wie die Zweierkomplement-Darstellung f√ºr negative Zahlen in einer 8-Bit signed Zahl funktioniert.\n",
    "Erwartete Antwort: Im Zweierkomplement ist das h√∂chstwertige Bit (MSB) das Vorzeichenbit. Um das Zweierkomplement einer Zahl zu finden, invertiere alle Bits und addiere 1 zum niederwertigsten Bit (LSB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q1kp8MaVVy6"
   },
   "source": [
    "### Fixkommadarstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCrHNptuVVy6"
   },
   "outputs": [],
   "source": [
    "# @title Darstellung von 16-Bit Festkomma-Zahlen (engl.: fixpoint binary representations) {display-mode: \"form\"}\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Initialize 16 toggle buttons (bits, MSB to LSB)\n",
    "bit_toggles = [\n",
    "    widgets.ToggleButton(\n",
    "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
    "    )\n",
    "    for _ in range(16)\n",
    "]\n",
    "\n",
    "# Color bars for sign, integer part, and fractional part\n",
    "color_bars = [\n",
    "    widgets.HTML(\n",
    "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
    "    )\n",
    "    if i == 0\n",
    "    else widgets.HTML(\n",
    "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
    "    )\n",
    "    if 1 <= i <= 7\n",
    "    else widgets.HTML(\n",
    "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
    "    )\n",
    "    for i in range(16)\n",
    "]\n",
    "\n",
    "# Output widget to show results\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "# def twos_complement(bits):\n",
    "#    \"\"\"Convert list of bits to signed integer using two's complement.\"\"\"\n",
    "#    if bits[0] == 0:\n",
    "#        return int(\"\".join(str(b) for b in bits), 2)\n",
    "#\n",
    "#    # If MSB is 1, it's negative\n",
    "#    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
    "#    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
    "#    return -incremented\n",
    "\n",
    "\n",
    "def fixed_point_value(bits: list[int]) -> float:\n",
    "    \"\"\"Convert a list of bits to a fixed-point value.\n",
    "\n",
    "    Args:\n",
    "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
    "\n",
    "    Returns:\n",
    "        float: The fixed-point value of the binary number.\n",
    "    \"\"\"\n",
    "    integer_part = bits[:8]\n",
    "    fractional_part = bits[8:]\n",
    "\n",
    "    # Calculate integer value\n",
    "    integer_value = twos_complement(integer_part)\n",
    "\n",
    "    # Calculate fractional value\n",
    "    fractional_value = sum(\n",
    "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
    "    )\n",
    "\n",
    "    return integer_value + fractional_value\n",
    "\n",
    "\n",
    "def update_display(*args) -> None:\n",
    "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
    "    # Read bit values (MSB to LSB)\n",
    "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
    "    bit_string = \"\".join(str(b) for b in bit_values)\n",
    "\n",
    "    # Unsigned decimal value\n",
    "    unsigned_decimal = int(bit_string, 2)\n",
    "\n",
    "    # Signed decimal value (two's complement)\n",
    "    signed_decimal = twos_complement(bit_values)\n",
    "\n",
    "    # Fixed-point value\n",
    "    fixed_point_decimal = fixed_point_value(bit_values)\n",
    "\n",
    "    # Hex representation (4 hex digits for 16 bits)\n",
    "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
    "\n",
    "    # Clear previous output and update\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        display(\n",
    "            HTML(f\"\"\"\n",
    "        <h3>\n",
    "            Binary: <code>\n",
    "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
    "                <span style=\"color: green;\">{bit_string[1:8]}</span>.\n",
    "                <span style=\"color: blue;\">{bit_string[8:]}</span>\n",
    "            </code><br>\n",
    "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
    "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
    "            Fixed-Point Decimal: <b>{fixed_point_decimal}</b><br>\n",
    "            Hexadecimal: <b>{hex_value}</b>\n",
    "        </h3>\n",
    "        \"\"\")\n",
    "        )\n",
    "\n",
    "    # Update button labels (0/1)\n",
    "    for btn, value in zip(bit_toggles, bit_values):\n",
    "        btn.description = str(value)\n",
    "\n",
    "\n",
    "# Attach observer to all buttons\n",
    "for btn in bit_toggles:\n",
    "    btn.observe(update_display, \"value\")\n",
    "\n",
    "# Display widget\n",
    "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
    "display(output)\n",
    "\n",
    "# Initialize display\n",
    "update_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN_oFcfjVVy6"
   },
   "source": [
    "#### √úbungsfragen (Optional):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmRekLfxVVy6"
   },
   "source": [
    "### Flie√ükommadarstellungen nach IEEE-754\n",
    "- TODO: Subnormal Numbers\n",
    "- Webseite mit noch mehr Darstellungen: https://evanw.github.io/float-toy/\n",
    "- Verschiedene FP8-Darstellungen: https://asawicki.info/articles/fp8_tables.php\n",
    "- https://onnx.ai/onnx/technical/float8.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8LgC7KNVVy6"
   },
   "outputs": [],
   "source": [
    "# @title Darstellung von 16-Bit (FP16) Flie√ükomma-Zahlen {display-mode: \"form\"}\n",
    "\n",
    "import struct\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "# Initialize 16 toggle buttons (bits)\n",
    "bit_toggles = [\n",
    "    widgets.ToggleButton(\n",
    "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
    "    )\n",
    "    for _ in range(16)\n",
    "]\n",
    "\n",
    "# Color bars for sign, exponent, and mantissa\n",
    "color_bars = [\n",
    "    widgets.HTML(\n",
    "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
    "    )\n",
    "    if i == 0\n",
    "    else widgets.HTML(\n",
    "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
    "    )\n",
    "    if 1 <= i <= 5\n",
    "    else widgets.HTML(\n",
    "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
    "    )\n",
    "    for i in range(16)\n",
    "]\n",
    "\n",
    "# Output widget to show FP16 value and components\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def bits_to_float16(bits: list[int]) -> np.float16:\n",
    "    \"\"\"Convert list of bits to FP16 float value.\n",
    "\n",
    "    Args:\n",
    "        bits (list[int]): A list of bits representing the binary number.\n",
    "\n",
    "    Returns:\n",
    "        np.float16: The FP16 float value of the binary number.\n",
    "    \"\"\"\n",
    "    bit_string = \"\".join(str(b) for b in bits)\n",
    "    # Convert binary string to integer\n",
    "    int_value = int(bit_string, 2)\n",
    "    # Pack as unsigned 16-bit int, then unpack as float16 using numpy\n",
    "    packed = struct.pack(\"<H\", int_value)  # Big endian 16-bit unsigned int\n",
    "    return np.frombuffer(packed, dtype=np.float16)[0]\n",
    "\n",
    "\n",
    "def update_display(*args):\n",
    "    \"\"\"Update the display with the current binary, FP16 float value, and its components.\"\"\"\n",
    "    # Read bit values (MSB to LSB)\n",
    "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
    "    bit_string = \"\".join(str(b) for b in bit_values)\n",
    "\n",
    "    # Extract components\n",
    "    sign = bit_values[0]\n",
    "    exponent_bits = bit_values[1:6]\n",
    "    mantissa_bits = bit_values[6:]\n",
    "\n",
    "    exponent = int(\"\".join(str(b) for b in exponent_bits), 2)\n",
    "    exponent_unbiased = exponent - 15  # Bias = 15\n",
    "\n",
    "    mantissa_raw = \"\".join(str(b) for b in mantissa_bits)\n",
    "    (\n",
    "        1 + sum(int(b) * 2 ** (-i) for i, b in enumerate(mantissa_bits, start=1))\n",
    "        if exponent != 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    # Convert to float16 value\n",
    "    fp16_value = bits_to_float16(bit_values)\n",
    "\n",
    "    # Clear previous output and display new info\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        display(\n",
    "            HTML(f\"\"\"\n",
    "        <h3>\n",
    "            Binary: <code>\n",
    "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
    "                <span style=\"color: green;\">{bit_string[1:6]}</span>\n",
    "                <span style=\"color: blue;\">{bit_string[6:]}</span>\n",
    "            </code><br>\n",
    "            Sign (1 bit): <b>{sign}</b> ({\"-\" if sign else \"+\"})<br>\n",
    "            Exponent (5 bits): <b>{\"\".join(str(b) for b in exponent_bits)} (biased: {exponent}, unbiased: {exponent_unbiased})</b><br>\n",
    "            Mantissa (10 bits): <b>{mantissa_raw}</b><br>\n",
    "            <hr>\n",
    "            <b>FP16 Value:</b> {fp16_value}\n",
    "        </h3>\n",
    "        \"\"\")\n",
    "        )\n",
    "\n",
    "    # Update button labels\n",
    "    for btn, value in zip(bit_toggles, bit_values):\n",
    "        btn.description = str(value)\n",
    "\n",
    "\n",
    "# Attach observer to all buttons\n",
    "for btn in bit_toggles:\n",
    "    btn.observe(update_display, \"value\")\n",
    "\n",
    "# Display widget\n",
    "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
    "display(output)\n",
    "\n",
    "# Initialize output\n",
    "update_display()  # 0 01111 0000000001 ^=^ 1.00097656"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBCmHSNeVVy6"
   },
   "source": [
    "#### √úbungsfragen (Optional):\n",
    "- Gibt es einen Unterschied zwischen +0.0 und -0.0?\n",
    "- Wie stelle ich `+Inf` bzw. `-Inf` dar?\n",
    "- Wie stelle ich `NaN` dar?\n",
    "- Was ergibt der Vergleich `float(\"nan\") != float(\"nan\")`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqJpD_KdjXoi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7youIav3VVy7"
   },
   "source": [
    "# üî¢Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
    "- Gotchas: zu gro√üe, kleine inputs, numerische Abweichungen. Ggfs.: Sehr kleines Gewicht, sehr gro√üer Input.\n",
    "- Abweichungen bestimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move to\n",
    "# Load necessary libs\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnx\n",
    "import pandas as pd\n",
    "from onnxconverter_common import float16\n",
    "\n",
    "from techdays25.onnx_utils import (\n",
    "    OnnxModel,\n",
    "    benchmark_models_on_batch_size,\n",
    "    plot_benchmark_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantisiere ONNX Modell nach FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbYQ_9fjMCUD"
   },
   "outputs": [],
   "source": [
    "# Specify, which model to use:\n",
    "onnx_model_path = Path(\"../assets/lab1/pytorch_regression.onnx\")\n",
    "\n",
    "# Load the previously saved FP32 ONNX model\n",
    "regression_model_fp32 = onnx.load(onnx_model_path)\n",
    "\n",
    "# Convert the FP32 ONNX model to FP16 precision\n",
    "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
    "onnx_model_fp16 = float16.convert_float_to_float16(\n",
    "    regression_model_fp32,  # path to the onnx model\n",
    "    min_positive_val=1e-7,  # Constant values will be clipped to these bounds\n",
    "    max_finite_val=1e4,  # same as above\n",
    "    keep_io_types=True,  # If set to false, the IO types will change to FP16\n",
    "    disable_shape_infer=False,  # Skips running onnx shape/type inference\n",
    "    op_block_list=None,  # A list of OPs which shall not be quantized\n",
    "    node_block_list=None,  # A list of nodes which shall not be converted\n",
    ")\n",
    "\n",
    "# Define the path where the FP16 ONNX model will be saved\n",
    "onnx_model_fp16_path = onnx_model_path.stem + \"_fp16\" + onnx_model_path.suffix\n",
    "\n",
    "# Save the converted FP16 ONNX model to the specified path\n",
    "onnx.save(onnx_model_fp16, onnx_model_fp16_path)\n",
    "\n",
    "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
    "print(f\"ONNX model (FP16) saved to {onnx_model_fp16_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantisiere Modell nach INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "from onnxruntime.quantization import (\n",
    "    CalibrationDataReader,\n",
    "    QuantType,\n",
    "    quantize_dynamic,\n",
    "    quantize_static,\n",
    ")\n",
    "from onnxruntime.quantization.shape_inference import quant_pre_process\n",
    "\n",
    "static_quantization = True  # toggles between static and dynamic quantization\n",
    "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
    "\n",
    "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
    "\n",
    "\n",
    "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
    "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
    "\n",
    "        This class implements a calibration data reader for INT8 calibration.\n",
    "        It generates synthetic data for calibration purposes.\n",
    "        \"\"\"\n",
    "        self.counter: int = 0\n",
    "\n",
    "    def get_next(self) -> dict[str, Any] | None:\n",
    "        \"\"\"Get the next batch of calibration data.\n",
    "\n",
    "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
    "\n",
    "        Returns:\n",
    "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
    "            or None if there are no more batches.\n",
    "        \"\"\"\n",
    "        if self.counter >= 16:\n",
    "            return None\n",
    "        self.counter += 1\n",
    "        X = np.linspace(-10, 10, 1000).reshape(-1, 1)\n",
    "        return {\"input\": X.astype(np.float32)}\n",
    "\n",
    "\n",
    "# Prepare calibration data\n",
    "calibration_data_reader = CalibrationDataReaderImpl()\n",
    "\n",
    "if static_quantization:\n",
    "    quantize_static(\n",
    "        onnx_model_path_int8 + \".pre\",\n",
    "        onnx_model_path_int8,\n",
    "        calibration_data_reader,\n",
    "        # quant_format=QuantFormat.QOperator,\n",
    "        per_channel=True,\n",
    "        weight_type=QuantType.QInt8,\n",
    "    )\n",
    "else:\n",
    "    quantize_dynamic(\n",
    "        onnx_model_path_int8,\n",
    "        onnx_model_path_int8,\n",
    "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
    "        per_channel=True,  # Enable per-channel quantization\n",
    "        reduce_range=True,  # Reduce the quantization range\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netron Visualisierung der ONNX Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from techdays25 import onnx_utils\n",
    "\n",
    "# Change model path accordingly:\n",
    "onnx_utils.netron_visualize(\"onnx_model_fp16_path.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich der quantisierten Modellvarianten mit urspr√ºnglichem Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_fp32_cpu = OnnxModel(onnx_model_path, provider=\"CPUExecutionProvider\")\n",
    "reg_model_fp16_cpu = OnnxModel(onnx_model_fp16_path, provider=\"CPUExecutionProvider\")\n",
    "reg_model_int8_cpu = OnnxModel(onnx_model_path_int8, provider=\"CPUExecutionProvider\")\n",
    "\n",
    "reg_model_fp32_gpu = OnnxModel(onnx_model_path, provider=\"CUDAExecutionProvider\")\n",
    "reg_model_fp16_gpu = OnnxModel(onnx_model_fp16_path, provider=\"CUDAExecutionProvider\")\n",
    "reg_model_int8_gpu = OnnxModel(onnx_model_path_int8, provider=\"CUDAExecutionProvider\")\n",
    "\n",
    "print(\"\\nSpezifikation des FP16 Modells:\")\n",
    "print(reg_model_fp16_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGYkUWNzMJGz"
   },
   "outputs": [],
   "source": [
    "# Create some random data and compare the results of the FP16 and FP32 models\n",
    "u_range = (-10, 10)  # set range for which input values shall be generated\n",
    "\n",
    "models = {\n",
    "    \"FP32/CPU\": reg_model_fp32_cpu,  # first model is the reference\n",
    "    \"FP16/CPU\": reg_model_fp16_cpu,\n",
    "    \"INT8/CPU\": reg_model_int8_cpu,\n",
    "    \"FP32/GPU\": reg_model_fp32_gpu,\n",
    "    \"FP16/GPU\": reg_model_fp16_gpu,\n",
    "    \"INT8/GPU\": reg_model_int8_gpu,\n",
    "}\n",
    "\n",
    "uu = np.linspace(*u_range, 15).reshape(-1, 1).astype(np.float32)\n",
    "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
    "\n",
    "# Extract the first key-value pair (this is the reference)\n",
    "first_key = next(iter(ii_predictions))\n",
    "first_value = ii_predictions[first_key]\n",
    "ii_diffs = {\n",
    "    \"Œî\" + k: first_value - v for k, v in ii_predictions.items() if k != first_key\n",
    "}\n",
    "\n",
    "df_data = {\"Input [U/V]\": uu.flatten()}\n",
    "\n",
    "df_data.update(ii_predictions)\n",
    "df_data.update(ii_diffs)\n",
    "\n",
    "pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragen:\n",
    "- Wie verhalten sich die Modellausgaben/Differenzen der beiden obigen Modelle f√ºr unterschiedliche Bereiche, die in `u_range` spezifiziert werden, z.B. f√ºr `u_range=(0,100)` oder `u_range=(-1000, 1000)`? \n",
    "- Wie lassen sich m√∂gliche Abweichungen erkl√§ren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# systematically evaluate the model differences for a larger range\n",
    "uu = np.linspace(-20, 20, 100000).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
    "# Extract the first key-value pair (this is the reference)\n",
    "ref_key = next(iter(ii_predictions))\n",
    "ref_value = ii_predictions[ref_key]\n",
    "ii_diffs = {k: ref_value - v for k, v in ii_predictions.items() if k != ref_key}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# plt.plot(uu, ii_fp32_ - ii_fp16_)\n",
    "for k, v in ii_diffs.items():\n",
    "    plt.plot(uu, v, label=k)\n",
    "\n",
    "# plt.yscale(\"symlog\", linthresh=.0001)\n",
    "plt.grid(which=\"both\")\n",
    "plt.xlabel(\"U [V]\")\n",
    "plt.ylabel(r\"$\\hat{I}_{FP32} - \\hat{I}_{FP16}$ [mA]\")\n",
    "plt.legend()\n",
    "plt.title(f\"Abweichungen diverser ONNX Modelle zur Referenz {first_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [2**i for i in range(10, 20)]\n",
    "model_dict = {\n",
    "    \"ONNX Regression Model (FP32/CPU)\": reg_model_fp32_cpu.predict,\n",
    "    \"ONNX Regression Model (FP16/CPU)\": reg_model_fp16_cpu.predict,\n",
    "    \"ONNX Regression Model (INT8/CPU)\": reg_model_int8_cpu.predict,\n",
    "    \"ONNX Regression Model (FP32/GPU)\": reg_model_fp32_gpu.predict,\n",
    "    \"ONNX Regression Model (FP16/GPU)\": reg_model_fp16_gpu.predict,\n",
    "    \"ONNX Regression Model (INT8/GPU)\": reg_model_int8_gpu.predict,\n",
    "}\n",
    "\n",
    "benchmark_results = benchmark_models_on_batch_size(\n",
    "    model_dict=model_dict,\n",
    "    input_shape=(1,),\n",
    "    batch_sizes=batch_sizes,\n",
    "    n_runs=100,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_results(results=benchmark_results, title=\"\", xscale=\"log\", yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fd481-eMB-R"
   },
   "source": [
    "# üï∏ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
    "\n",
    "In diesem Teil werden wir uns damit befassen, welche Probleme bei der Modellquantisierung auftreten k√∂nnen und dies anhand eines Beispiels illustrieren. Folgende Schritte werden durchgef√ºhrt:\n",
    "- Erstellen eines benutzerdefinierten Modells in Keras zur Mittelwertbildung √ºber entlang der Zeitachse.\n",
    "- Konvertieren des Keras-Modells in das ONNX-Format.\n",
    "- Quantisieren des ONNX-Modells von FP32 auf FP16.\n",
    "- Generierung von 3-dimensionalen Zeitreihendaten f√ºr die Modellinferenz.\n",
    "- Modellinferenz mit dem Keras-Modell.\n",
    "- Modellinferenz mit den FP32/FP16 ONNX-Modellen:\n",
    "  - Laden und Ausf√ºhren von ONNX-Modellen mit der ONNX Runtime.\n",
    "  - Vergleich der Ausgaben von FP32- und FP16-ONNX-Modellen.\n",
    "- Diskussion der Beobachtungen und m√∂glicher L√∂sungen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pncih_L8dWVa"
   },
   "source": [
    "## Modelldefinition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya6rTWHfamy3"
   },
   "source": [
    "Unser Modell unten nimmt einen 3-dimensionalen Eingabetensor mit den Dimensionen (Batch-Gr√∂√üe, Sequenzl√§nge, Merkmalsanzahl) entgegen. In unserem Beispiel hat der Eingabetensor die Form (2, 10000, 3), was bedeutet, dass wir zwei Batch-Elemente haben, jedes mit einer Sequenzl√§nge von 10000 und 3 Merkmalen pro Zeitschritt.\n",
    "\n",
    "Nach der Verarbeitung durch das Modell wird die Zeitdimension reduziert, und die Ausgabe hat die Form (Batch-Gr√∂√üe, Merkmalsanzahl). F√ºr unser Beispiel ergibt sich eine Ausgabe mit der Form (2, 3). Die Ausgabe repr√§sentiert den Durchschnitt der Merkmale √ºber die gesamte Sequenzl√§nge f√ºr jedes Batch-Element.\n",
    "\n",
    "**Beispiel**\n",
    "\n",
    "Eingabetensor (2 x 4 x 3):\n",
    "```\n",
    "[\n",
    "    [3, 4, 5],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "  ],\n",
    "  [\n",
    "    [2, 4, 6],\n",
    "    [8, 10, 12],\n",
    "    [14, 16, 18],\n",
    "    [20, 22, 24]\n",
    "  ]\n",
    "]\n",
    "```\n",
    "\n",
    "Ausgabetensor (2 x 3):\n",
    "```\n",
    "[\n",
    "  [ 6,  7,  8],\n",
    "  [11, 13, 15]\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBhX8Vul3feC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Layer\n",
    "\n",
    "\n",
    "class SumLayer(Layer):\n",
    "    \"\"\"Custom Layer to sum over time dimension of a tensor.\"\"\"\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Reduce (sum) the input tensor along the time axis (axis=1).\n",
    "\n",
    "        Args:\n",
    "            inputs (tf.Tensor): The input tensor of shape (batch_size, sequence_length, feature_dim).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The reduced tensor of shape (batch_size, feature_dim).\n",
    "        \"\"\"\n",
    "        return tf.reduce_sum(inputs, axis=1)\n",
    "\n",
    "\n",
    "# Custom Layer: Division by sequence length\n",
    "class DivisionLayer(Layer):\n",
    "    \"\"\"Divide a tensor by the length of the given sequence.\"\"\"\n",
    "\n",
    "    def call(self, inputs: tuple[tf.Tensor, tf.Tensor]) -> tf.Tensor:\n",
    "        \"\"\"Divide the summed tensor by the sequence length to get the average.\n",
    "\n",
    "        Args:\n",
    "            inputs (Tuple[tf.Tensor, tf.Tensor]): A tuple containing the summed tensor and the original input tensor.\n",
    "                - tensor_x (tf.Tensor): The summed tensor of shape (batch_size, feature_dim).\n",
    "                - original_input (tf.Tensor): The original input tensor of shape (batch_size, sequence_length, feature_dim).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The averaged tensor of shape (batch_size, feature_dim).\n",
    "        \"\"\"\n",
    "        tensor_x, original_input = inputs\n",
    "        seq_length = tf.shape(original_input)[\n",
    "            1\n",
    "        ]  # Get the dynamic sequence length (length of the time dimension)\n",
    "        return tensor_x / tf.cast(seq_length, dtype=tensor_x.dtype)\n",
    "\n",
    "\n",
    "# Define model with separate Sum and Division layers\n",
    "def global_average_pooling_1d() -> Model:\n",
    "    \"\"\"Define a Keras model with separate Sum and Division layers for global average pooling.\n",
    "\n",
    "    Returns:\n",
    "        Model: A Keras model that performs global average pooling over the time dimension.\n",
    "    \"\"\"\n",
    "    inputs = Input(\n",
    "        shape=(None, 3), name=\"input\"\n",
    "    )  # Define the input layer with shape (sequence_length=None, feature_dim=3)\n",
    "    sum_x = SumLayer(name=\"sum\")(inputs)  # Apply the SumLayer to the inputs\n",
    "    output = DivisionLayer(name=\"divide\")([\n",
    "        sum_x,\n",
    "        inputs,\n",
    "    ])  # Apply the DivisionLayer to the summed tensor and the original inputs\n",
    "    return Model(\n",
    "        inputs, output, name=\"GlobalAveragePooling1D\"\n",
    "    )  # Create the Keras model with the specified input and output\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = global_average_pooling_1d()\n",
    "\n",
    "# Print model summary to see the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8_5U6zHgR-_"
   },
   "source": [
    "## Modellkonvertierung nach ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-9pMzIv6oUY"
   },
   "outputs": [],
   "source": [
    "# Convert our GlobalAveragePooling1D Model to ONNX format\n",
    "import onnx  # ONNX library for handling ONNX models\n",
    "import tf2onnx  # TensorFlow to ONNX conversion library\n",
    "from onnxconverter_common import float16  # Utility for FP16 conversion\n",
    "\n",
    "# Define the path where the FP32 ONNX model will be saved\n",
    "onnx_model_path_fp32 = \"gap1d_model_fp32.onnx\"\n",
    "\n",
    "# Convert the Keras model to ONNX format with FP32 precision\n",
    "# Define the input specification for the model conversion\n",
    "spec = (tf.TensorSpec((None, None, 3), tf.float32, name=\"input\"),)\n",
    "# Convert the Keras model to ONNX using tf2onnx\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=18)\n",
    "\n",
    "# Save the converted FP32 ONNX model to the specified path\n",
    "onnx.save(onnx_model, onnx_model_path_fp32)\n",
    "print(f\"ONNX model (FP32) saved to {onnx_model_path_fp32}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdLdCuQBgaLi"
   },
   "source": [
    "## Quantisierung des ONNX Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8A1tP9V679a"
   },
   "outputs": [],
   "source": [
    "# Now quantize the ONNX model to FP16 and save it\n",
    "\n",
    "# Load the previously saved FP32 ONNX model\n",
    "onnx_model_fp32 = onnx.load(onnx_model_path_fp32)\n",
    "\n",
    "# Convert the FP32 ONNX model to FP16 precision\n",
    "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
    "onnx_model_fp16 = float16.convert_float_to_float16(onnx_model_fp32, keep_io_types=True)\n",
    "\n",
    "# Define the path where the FP16 ONNX model will be saved\n",
    "onnx_model_path_fp16 = \"gap1d_model_fp16.onnx\"\n",
    "\n",
    "# Save the converted FP16 ONNX model to the specified path\n",
    "onnx.save(onnx_model_fp16, onnx_model_path_fp16)\n",
    "\n",
    "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
    "print(f\"ONNX model (FP16) saved to {onnx_model_path_fp16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4z7m2fr58kMm"
   },
   "outputs": [],
   "source": [
    "from techdays25 import onnx_utils\n",
    "\n",
    "onnx_utils.netron_visualize(\"gap1d_model_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R_B8RE7ggas"
   },
   "source": [
    "## Datengenerierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PORbJXNx4yav"
   },
   "outputs": [],
   "source": [
    "# First create some data and put it through the Keras model\n",
    "import matplotlib.pyplot as plt  # Library for plotting\n",
    "import numpy as np  # Library for numerical operations\n",
    "\n",
    "# Create a random input tensor with a batch size of 2\n",
    "# Generate a sequence of numbers from 0 to 9999 and reshape it to (1, 10000, 1)\n",
    "tt = np.arange(10_000).reshape(1, -1, 1)\n",
    "\n",
    "# Create an offset array and reverse it\n",
    "off = (np.array(np.arange(6)).astype(np.float32) + 4)[::-1]\n",
    "\n",
    "# Generate a 3-dimensional time series data using a sine function with the offset\n",
    "xx = 0.4 * np.sin(4 * np.pi * 1e-5 * off**2 * tt) + off\n",
    "\n",
    "# Reshape the data to have dimensions (sequence_length, batch_size, feature_dim)\n",
    "xx = xx.reshape(-1, 2, 3)\n",
    "\n",
    "# Swap the axes to get the shape (batch_size, sequence_length, feature_dim)\n",
    "xx = np.swapaxes(xx, 0, 1)\n",
    "\n",
    "# Convert the data to float32 type\n",
    "x_input = xx.astype(np.float32)\n",
    "\n",
    "# Print the dimensions of the input tensor\n",
    "print(\"Dimensions of the input tensor:\", x_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGQTVao-GYZM"
   },
   "outputs": [],
   "source": [
    "# Plot the generated time series data\n",
    "import matplotlib.pyplot as plt  # Library for plotting (re-imported for completeness)\n",
    "\n",
    "# Create a new figure with a specified size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the first batch (b$_1$) of the time series data\n",
    "plt.plot(xx[0, :, :], label=\"b$_1$\")\n",
    "\n",
    "# Plot the second batch (b$_2$) of the time series data\n",
    "plt.plot(xx[1, :, :], label=\"b$_2$\")\n",
    "\n",
    "# Set the label for the x-axis\n",
    "plt.xlabel(\"Index\")\n",
    "\n",
    "# Set the label for the y-axis\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title(\"Ein Batch bestehend aus jeweils zwei 3-dimensionalen Zeitreihen\")\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(1.1, 0.6), ncol=2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRHQY_j_gzEj"
   },
   "source": [
    "## Inferenz mit dem Keras Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9EP5mXQ-Ln2"
   },
   "outputs": [],
   "source": [
    "# Put the data through the Keras model\n",
    "\n",
    "# Use the Keras model to make predictions on the input data\n",
    "y_output_keras = model.predict(x_input)\n",
    "\n",
    "# Print the dimensions of the input tensor\n",
    "print(\"Dimensionen des Eingabetensors:\", x_input.shape)  # Erwartete Form: (2, 10000, 3)\n",
    "\n",
    "# Print the dimensions of the Keras model output\n",
    "print(\n",
    "    \"Dimensionen der Keras-Modellausgabe:\", y_output_keras.shape\n",
    ")  # Erwartete Form: (2, 3) -> Zeitdimension reduziert!\n",
    "\n",
    "# Print the output of the Keras model\n",
    "print(\"Keras-Modellausgabe:\\n\", y_output_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tq_N1o4Sg7p9"
   },
   "source": [
    "## Inferenz mit den FP32/FP16 ONNX Modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8LdB2clSPgQ"
   },
   "outputs": [],
   "source": [
    "# Run the FP32 ONNX model\n",
    "# run_onnx_model(onnx_model_path=\"gap1d_model_fp32.onnx\", x_input=x_input)\n",
    "OnnxModel(onnx_model_path=\"gap1d_model_fp32.onnx\").predict(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8wCn4znSZ_s"
   },
   "outputs": [],
   "source": [
    "# Run the FP16 ONNX model\n",
    "# run_onnx_model(onnx_model_path=\"gap1d_model_fp16.onnx\", x_input=x_input)\n",
    "OnnxModel(onnx_model_path=\"gap1d_model_fp16.onnx\").predict(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsQD-7RzO2Ao"
   },
   "source": [
    "## Fragen / Diskussion\n",
    "- Welche Ergebnisse erwarten wir? Stimmen die Ergebnisse mit den Erwartungen √ºberein?\n",
    "- Was f√§llt bei der Ausgabe des quantisierten FP16 Modells auf?\n",
    "  - Wie k√∂nnte man sich dieses Ergebnis erkl√§ren?\n",
    "  - L√§sst sich das Problem ggfs. vermeiden?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5i-XeVZVVy7"
   },
   "source": [
    "# üìû Teil 4: Quantisierung eines DTMF Klassifikationsmodells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG6JRjlfVVy7"
   },
   "source": [
    "## Einf√ºhrung: Generierung und Dekodierung/Klassifizierung von DTMF (dual-tone multi-frequency) Signalen <a class=\"anchor\" id=\"part0\"></a>\n",
    "\n",
    "\n",
    "Das Dualton-Mehrfrequenzwahlverfahren (DTMF) ist ein Signalisierungssystem f√ºr das W√§hlen eines Telefons, das in den fr√ºhen 1960er Jahren von Western Electric entwickelt und sp√§ter von Bell System kommerziell an Telefonkunden geliefert wurde.\n",
    "Wenn eine Taste auf dem Telefon gedr√ºckt wird, werden zwei harmonische Tonsignale erzeugt, und die Superposition/√úberlagerung beider Signale wird verwendet, um die entsprechende Telefontaste zu charakterisieren. Wenn zum Beispiel die Taste ‚Äû5‚Äú gedr√ºckt wird, entsteht ein Dualtontonsignal, das sich aus den Frequenzen 770 Hz und 1336 Hz zusammensetzt. Die beiden Frequenzen, die jede Taste beschreiben, sind in der folgenden Tabelle aufgef√ºhrt:\n",
    "\n",
    "|   | 1209Hz  | 1336 Hz  | 1477 Hz   | 1633 Hz  |\n",
    "|---|:---:|:---:|:---:|:---:|\n",
    "| **697 Hz**  |  1 | 2  | 3  | A  |\n",
    "| **770 Hz**  |  4 | 5  | 6  | B  |\n",
    "| **852 Hz**  |  7 | 8  | 9  | C  |\n",
    "| **941 Hz**  |  * | 0  | #  | D  |\n",
    "\n",
    "In diesem Beispiel werden wir uns ansehen, wie man solche DTMF-W√§hlsequenzen generiert, sie in einer Audiodatei speichert und das Audiosignal mit einem einfachen KI-Modell wieder dekodiert.\n",
    "\n",
    "Wir werden die folgenden Schritte durchf√ºhren, um ein DTMF-Signal zu erzeugen und mit einem Klassifikationsmodell zu dekodieren:\n",
    "1. Erzeugung des Signals und der Audiodatei mit `scipy` und `numpy`. Wir speichern die erzeugte Audiodatei in einer `.wav` Datei, die in diesem Notebook oder in deinem lokalen Audioplayer abgespielt werden kann\n",
    "2. Wir entwerfen eine einfaches KI-Modell ... TODO\n",
    "3. Extraktion der gew√§hlten Tastenfolge aus der `.wav`-Datei unter Verwendung des KI-Modells\n",
    "4. Quantisierung & Export des Modells nach ONNX im FP32 und FP16 Format. Quantisierung nach INT8 und Export nach TensorRT.\n",
    "5. Laufzeituntersuchungen f√ºr FP32/FP16/INT8, unterschiedliche Batch-Gr√∂√üen und Signall√§ngen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNXOs32MVVy7"
   },
   "outputs": [],
   "source": [
    "# Trainiere Modell\n",
    "# Konvertiere Modell nach ONNX (einmal FP32, einmal FP16)\n",
    "# Untersuche Laufzeitunterschiede (auch nach batchsize)\n",
    "# Untersuche Abweichungen. Wie √§ndert sich die Fehlerrate des Modells f√ºr FP32/Fp16?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d51a6fcd-760a-4926-8d68-7f75eddb906a"
   },
   "source": [
    "## Signal- und Audiodatei-Generierung <a class=\"anchor\" id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9360855-39ba-450f-975b-ebd7f48a5521"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# from collections.abc import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6kR8O3oWRKR"
   },
   "outputs": [],
   "source": [
    "# @title Tastenfeld-Widget f√ºr Generierung der W√§hlsequenz' {display-mode: \"form\"}\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "# Initialize a text widget to display the dial sequence\n",
    "dial_sequence = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Dial sequence will appear here...\",\n",
    "    description=\"\",\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width=\"300px\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Function to handle button clicks\n",
    "def on_button_click(b):\n",
    "    \"\"\"_summary_.\n",
    "\n",
    "    Args:\n",
    "        b (_type_): _description_\n",
    "    \"\"\"\n",
    "    dial_sequence.value += b.description\n",
    "\n",
    "\n",
    "# Create buttons for the phone dialer\n",
    "buttons = []\n",
    "for row in [\n",
    "    [\"1\", \"2\", \"3\", \"A\"],\n",
    "    [\"4\", \"5\", \"6\", \"B\"],\n",
    "    [\"7\", \"8\", \"9\", \"C\"],\n",
    "    [\"*\", \"0\", \"#\", \"D\"],\n",
    "]:\n",
    "    button_row = []\n",
    "    for label in row:\n",
    "        button = widgets.Button(\n",
    "            description=label, layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
    "        )\n",
    "        button.on_click(on_button_click)\n",
    "        button_row.append(button)\n",
    "    buttons.append(widgets.HBox(button_row))\n",
    "\n",
    "# Create a clear button\n",
    "clear_button = widgets.Button(\n",
    "    description=\"Clear\", layout=widgets.Layout(width=\"158px\", height=\"50px\")\n",
    ")\n",
    "\n",
    "back_button = widgets.Button(\n",
    "    description=\"‚¨Ö\", layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
    ")\n",
    "\n",
    "\n",
    "def on_clear_click(b):\n",
    "    \"\"\"_summary_.\n",
    "\n",
    "    Args:\n",
    "        b (_type_): _description_\n",
    "    \"\"\"\n",
    "    global dial_sequence\n",
    "    dial_sequence.value = \"\"\n",
    "\n",
    "\n",
    "def on_back_click(b):\n",
    "    \"\"\"_summary_.\n",
    "\n",
    "    Args:\n",
    "        b (_type_): _description_\n",
    "    \"\"\"\n",
    "    global dial_sequence\n",
    "    dial_sequence.value = dial_sequence.value[:-1]\n",
    "\n",
    "\n",
    "clear_button.on_click(on_clear_click)\n",
    "\n",
    "\n",
    "back_button.on_click(on_back_click)\n",
    "\n",
    "# Display the dialer\n",
    "display(dial_sequence)\n",
    "for button_row in buttons:\n",
    "    display(button_row)\n",
    "display(widgets.HBox([clear_button, back_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V728NfPmsAQr"
   },
   "outputs": [],
   "source": [
    "print(\"Gew√§hlte Sequenz:\", dial_sequence.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8i2MsZF3o0g"
   },
   "source": [
    "### Generierung des W√§hl-Audiosignals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAyM34wYqx_A"
   },
   "outputs": [],
   "source": [
    "from techdays25.dtmf_generation import DtmfGenerator\n",
    "\n",
    "dtmf_gen = DtmfGenerator(\n",
    "    dur_key=(0.2, 0.3),\n",
    "    dur_pause=(0.01, 0.1),\n",
    "    noise_factor=(10.0, 50.0),\n",
    "    noise_freq_range=(0.0, 20000.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62132ef1-c61f-4653-9f6c-a4d9f892781e"
   },
   "outputs": [],
   "source": [
    "# Either use the dialed sequence from above:\n",
    "my_dialed_sequence_keys = dial_sequence.value\n",
    "\n",
    "# ... or generate a random sequence:\n",
    "# my_dialed_sequence_keys = \"\".join([random.choice(\"1234567890ABCD*#\") for i in range(10)])\n",
    "\n",
    "# ... or use a simple sequence for debugging purposes\n",
    "# my_dialed_sequence_keys = \"1234567890ABCD*#\" # for debug purposes...\n",
    "\n",
    "# ... or use a slightly longer sequence (which also contains all symbols)\n",
    "# my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
    "if not my_dialed_sequence_keys:\n",
    "    my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
    "\n",
    "# Try changing the following arguments: dur_key=0.05, dur_pause=0.02\n",
    "my_dialed_sequence_signal = dtmf_gen.get_tone_sequence(my_dialed_sequence_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-9x6ncx3wiD"
   },
   "source": [
    "### Visualisierung des Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aarMEIq3vS0m"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(my_dialed_sequence_signal)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Das vollst√§ndige gew√§hlte Signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWiuyJ_7BUS6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(my_dialed_sequence_signal[: 10**4])\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Die ersten 10000 Datenpunkte des gew√§hlten Signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJe9QX8Ee9aA"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "quant = np.quantile(my_dialed_sequence_signal, 0.99)\n",
    "start_index = np.where(my_dialed_sequence_signal > quant)[0][10]\n",
    "plt.plot(my_dialed_sequence_signal)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Weiterer Zoom-In\")\n",
    "plt.xlim(start_index, start_index + 1.5 * 10**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42af11c2-3c15-4a57-afa8-f62b8e82925d"
   },
   "outputs": [],
   "source": [
    "# Now let us listen to the generated WAV file\n",
    "import IPython\n",
    "import numpy as np\n",
    "\n",
    "wav_file_name = \"my_dtmf_file.wav\"\n",
    "\n",
    "wavfile.write(\n",
    "    wav_file_name,\n",
    "    dtmf_gen.get_sample_rate(),\n",
    "    (my_dialed_sequence_signal * np.iinfo(np.int32).max).astype(np.int32),\n",
    ")\n",
    "IPython.display.Audio(wav_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51a52767-7e0e-444f-8028-f5a52fce4820"
   },
   "outputs": [],
   "source": [
    "print(\"Dialed sequence: \", my_dialed_sequence_keys)\n",
    "print(\"Used symbols: \", len(set(my_dialed_sequence_keys)))\n",
    "print(\"Total length of signal:\", my_dialed_sequence_signal.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b763fef4-360e-4a01-910b-add573007fd3"
   },
   "source": [
    "### Signal-Spektrogramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7827a985-0dd0-40c0-993c-e002523ef0e9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "Pxx, freqs, bins, im = plt.specgram(\n",
    "    my_dialed_sequence_signal, NFFT=1024, Fs=dtmf_gen.get_sample_rate()\n",
    ")\n",
    "plt.ylim(0, 2000)\n",
    "plt.xlabel(\"t [s]\")\n",
    "plt.ylabel(\"f [Hz]\")\n",
    "plt.title(\"Spektrogramm des generierten Telefonw√§hlsignals\")\n",
    "plt.show(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aio7fvyo4ZUy"
   },
   "source": [
    "## Experimente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtHys5X74cRB"
   },
   "source": [
    "### Laden des vortrainierten Keras Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4Tks3yH0ipe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "keras_model = tf.keras.models.load_model(\"dtmf_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kesc3J6SUBOv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = time.time()\n",
    "keras_pred = keras_model.predict(my_dialed_sequence_signal.reshape(1, -1, 1))\n",
    "end = time.time()\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "\n",
    "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(my_dialed_sequence_signal)\n",
    "\n",
    "for key_idx in range(keras_pred.shape[-1] - 1):  # last index represents pauses\n",
    "    plt.plot(\n",
    "        keras_pred[0, :, key_idx],\n",
    "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
    "        color=colors[key_idx],\n",
    "    )\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
    "plt.title(f\"Tats√§chliche Wahlsequenz: {' '.join(list(my_dialed_sequence_keys))}\")\n",
    "plt.show()\n",
    "print(\"Inferenz-Dauer:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_zpgnG6CviY"
   },
   "outputs": [],
   "source": [
    "predicted_key_sequence = dtmf_gen.decode_prediction(keras_pred)\n",
    "print(\"Prognostizierte W√§hlsequenz:\", predicted_key_sequence)\n",
    "print(\n",
    "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
    "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-97qYaeo4k86"
   },
   "source": [
    "### Konvertierung des Keras Modells nach ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0niGbjMEhna"
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tf2onnx\n",
    "\n",
    "# Diese Zelle k√∂nnte einen Fehler werfen.\n",
    "# Dennoch sollte das ONNX Modell korrekt exportiert werden\n",
    "keras_model.output_names = [\"output\"]\n",
    "\n",
    "input_signature = [\n",
    "    tf.TensorSpec([None, 2**12, 1], tf.float32, name=\"input\")\n",
    "]  # TODO: time axis fixed or dynamic?\n",
    "# Use from_function for tf functions\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(keras_model, input_signature, opset=18)\n",
    "onnx.save(onnx_model, \"dtmf_classifier.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-CLAhtx4tTw"
   },
   "source": [
    "### Optimierung des ONNX Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5PAAutNg2bE"
   },
   "outputs": [],
   "source": [
    "import onnxsim\n",
    "\n",
    "model_path = \"dtmf_classifier.onnx\"\n",
    "simplified_model_path = \"dtmf_classifier.onnx\"\n",
    "onnx_model = onnx.load(model_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx_model_simp, check = onnxsim.simplify(onnx_model)\n",
    "assert check, \"Simplified ONNX model could not be validated\"\n",
    "onnx.save(onnx_model_simp, simplified_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9OUrzZa-bgt"
   },
   "outputs": [],
   "source": [
    "from techdays25 import onnx_utils\n",
    "\n",
    "onnx_utils.netron_visualize(\"dtmf_classifier.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0s4ULT84ynC"
   },
   "source": [
    "### Quantisierung des ONNX Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EOwr_prgiN4"
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxconverter_common import float16\n",
    "\n",
    "onnx_model = onnx.load(\"dtmf_classifier.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx_model_fp16 = float16.convert_float_to_float16(\n",
    "    onnx_model,\n",
    "    min_positive_val=1e-7,\n",
    "    max_finite_val=1e4,\n",
    "    keep_io_types=True,\n",
    "    disable_shape_infer=False,\n",
    "    op_block_list=None,\n",
    "    node_block_list=None,\n",
    ")\n",
    "onnx.save(onnx_model_fp16, \"dtmf_classifier_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYcDlVrLqWwx"
   },
   "outputs": [],
   "source": [
    "# Import tensorrt_libs\n",
    "\n",
    "from techdays25.onnx_utils import OnnxModel\n",
    "\n",
    "# FP32 ONNX Model\n",
    "onnx_classifier = OnnxModel(\"dtmf_classifier.onnx\")\n",
    "\n",
    "# FP16 ONNX Model\n",
    "onnx_classifier_fp16 = OnnxModel(\"dtmf_classifier_fp16.onnx\")\n",
    "\n",
    "# FP16 TensorRT Model\n",
    "trt_provider = (\n",
    "    \"TensorrtExecutionProvider\",\n",
    "    {\n",
    "        \"device_id\": 0,  # The device ID\n",
    "        \"trt_max_workspace_size\": 4e9,  # Maximum workspace size for TensorRT engine (1e9 ‚âà 1GB)\n",
    "        \"trt_fp16_enable\": True,\n",
    "        \"trt_int8_enable\": False,\n",
    "        \"trt_int8_use_native_calibration_table\": False,\n",
    "        \"trt_engine_cache_enable\": False,\n",
    "        \"trt_engine_cache_path\": \"./trt_catch_dir\",\n",
    "        # \"trt_profile_opt_shapes\": \"input:32x4096x1\",\n",
    "        # \"trt_profile_min_shapes\": \"input:1x4096x1\",\n",
    "        # \"trt_profile_max_shapes\": \"input:32x4096x1\",\n",
    "    },\n",
    ")\n",
    "# tensorrt_classifier_fp16 = OnnxModel(\"dtmf_classifier.onnx\", provider=trt_provider)\n",
    "\n",
    "# tensorrt_classifier_fp32 = TensorRTInfer(\"dtmf_classifier_fp32_nvidia_l4.trt\")\n",
    "# tensorrt_classifier_fp16 = TensorRTInfer(\"dtmf_classifier_fp16_nvidia_l4.trt\")\n",
    "# tensorrt_classifier_int8 = TensorRTInfer(\"dtmf_classifier_int8_nvidia_a100-sxm4-40gb.trt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7H557RUJyEhf"
   },
   "outputs": [],
   "source": [
    "# TODO: Allow to select model here:\n",
    "onnx_prediction = onnx_classifier.predict(\n",
    "    my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
    ")\n",
    "predicted_key_sequence = dtmf_gen.decode_prediction(onnx_prediction)\n",
    "print(\"Predicted Sequence:\", predicted_key_sequence)\n",
    "print(\n",
    "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
    "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZZNC80qUvnP"
   },
   "outputs": [],
   "source": [
    "# TODO: Validate ONNX models and Keras Model on Validation/Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns8srDuD5Ji1"
   },
   "source": [
    "### Peformanzmessung (Latenz) der individuellen Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 100\n",
    "n_warmup = 20\n",
    "signal_length = 2**12\n",
    "batch_sizes = [2**i for i in range(11)]\n",
    "\n",
    "model_dict = {\n",
    "    # \"keras\": lambda x: model.predict(x, verbose=0),\n",
    "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
    "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
    "    # \"TRT (FP32)\": tensorrt_classifier_fp32.infer,\n",
    "    # \"TRT (FP16)\": tensorrt_classifier_fp16.infer,\n",
    "    # \"TRT (INT8)\": tensorrt_classifier_int8.infer,\n",
    "}\n",
    "\n",
    "results = benchmark_models_on_batch_size(\n",
    "    model_dict=model_dict,\n",
    "    input_shape=(signal_length, 1),\n",
    "    batch_sizes=batch_sizes,\n",
    "    n_runs=n_runs,\n",
    "    n_warmup=n_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzxwUrIdqNFN"
   },
   "outputs": [],
   "source": [
    "plot_benchmark_results(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xb6KDq61AI_G"
   },
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# Load the ONNX model\n",
    "# model_path = \"dtmf_classifier.onnx\"\n",
    "# model = onnx.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGuwxgoDkgGv"
   },
   "source": [
    "## TensorRT Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3of1tuYcNrC"
   },
   "outputs": [],
   "source": [
    "def get_gpu_type() -> str:\n",
    "    \"\"\"Get the type of GPU available on the system.\n",
    "\n",
    "    This function checks if a CUDA-capable GPU is available using PyTorch.\n",
    "    If a GPU is available, it returns the name of the GPU in lowercase with spaces replaced by underscores.\n",
    "    If no GPU is available, it returns 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        str: The type of GPU available or 'cpu' if no GPU is available.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        return \"cpu\"\n",
    "    return \"_\".join(torch.cuda.get_device_name(0).lower().split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSJVcrVW6gPw"
   },
   "outputs": [],
   "source": [
    "from techdays25.dtmf_generation import DtmfGenerator\n",
    "\n",
    "dtmf_gen = DtmfGenerator(\n",
    "    dur_key=(0.2, 0.3),\n",
    "    dur_pause=(0.01, 0.1),\n",
    "    noise_factor=(10.0, 50.0),\n",
    "    noise_freq_range=(0.0, 20000.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5sW5xE4y3Yf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from cuda import cuda, cudart\n",
    "\n",
    "\n",
    "def check_cuda_err(err: cuda.CUresult | cudart.cudaError_t) -> None:\n",
    "    \"\"\"Check for CUDA errors and raise an exception if an error is found.\n",
    "\n",
    "    Args:\n",
    "        err (Union[cuda.CUresult, cudart.cudaError_t]): The CUDA error code.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If a CUDA error is detected.\n",
    "    \"\"\"\n",
    "    if isinstance(err, cuda.CUresult) and err != cuda.CUresult.CUDA_SUCCESS:\n",
    "        raise RuntimeError(f\"Cuda Error: {err}\")\n",
    "    if isinstance(err, cudart.cudaError_t):\n",
    "        if err != cudart.cudaError_t.cudaSuccess:\n",
    "            raise RuntimeError(f\"Cuda Runtime Error: {err}\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unknown error type: {err}\")\n",
    "\n",
    "\n",
    "def cuda_call(call: Any) -> Any:\n",
    "    \"\"\"Make a CUDA call and check for errors.\n",
    "\n",
    "    Args:\n",
    "        call (Any): The CUDA call to make.\n",
    "\n",
    "    Returns:\n",
    "        Any: The result of the CUDA call.\n",
    "    \"\"\"\n",
    "    err, res = call[0], call[1:]\n",
    "    check_cuda_err(err)\n",
    "    if len(res) == 1:\n",
    "        res = res[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
    "def memcpy_host_to_device(device_ptr: int, host_arr: np.ndarray) -> None:\n",
    "    \"\"\"Copy data from host to device.\n",
    "\n",
    "    Args:\n",
    "        device_ptr (int): The device pointer.\n",
    "        host_arr (np.ndarray): The host array.\n",
    "    \"\"\"\n",
    "    nbytes = host_arr.size * host_arr.itemsize\n",
    "    cuda_call(\n",
    "        cudart.cudaMemcpy(\n",
    "            device_ptr, host_arr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
    "def memcpy_device_to_host(host_arr: np.ndarray, device_ptr: int) -> None:\n",
    "    \"\"\"Copy data from device to host.\n",
    "\n",
    "    Args:\n",
    "        host_arr (np.ndarray): The host array.\n",
    "        device_ptr (int): The device pointer.\n",
    "    \"\"\"\n",
    "    nbytes = host_arr.size * host_arr.itemsize\n",
    "    cuda_call(\n",
    "        cudart.cudaMemcpy(\n",
    "            host_arr, device_ptr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class MNISTEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "    \"\"\"INT8 calibrator for our DTMF classifier model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, training_data: str, cache_file: str, batch_size: int = 16\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the MNISTEntropyCalibrator.\n",
    "\n",
    "        Args:\n",
    "            training_data (str): The path to the training data.\n",
    "            cache_file (str): The path to the cache file.\n",
    "            batch_size (int, optional): The batch size. Defaults to 16.\n",
    "        \"\"\"\n",
    "        # Whenever you specify a custom constructor for a TensorRT class,\n",
    "        # you MUST call the constructor of the parent explicitly.\n",
    "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
    "\n",
    "        self.cache_file = cache_file\n",
    "\n",
    "        # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n",
    "        # self.data = 2 * np.random.rand(32*batch_size, 2**12, 1).astype(np.float32) - 1.0\n",
    "        # self.data = training_data\n",
    "        self.data = dtmf_gen.generate_dataset(\n",
    "            n_samples=32 * batch_size, t_length=2**12, with_labels=None\n",
    "        ).astype(np.float32)\n",
    "        # print(self.data.dtype)\n",
    "        # self.data = self.data.astype(np.float32)\n",
    "        self.batch_size = batch_size\n",
    "        self.current_index = 0\n",
    "\n",
    "        # Allocate enough memory for a whole batch.\n",
    "        # self.device_input = cuda.mem_alloc(self.data[0].nbytes * self.batch_size)\n",
    "        n_bytes = self.data[0].nbytes * self.batch_size\n",
    "        # print(\"n_bytes\", n_bytes)\n",
    "        self.device_input = cuda_call(cudart.cudaMalloc(n_bytes))\n",
    "\n",
    "    def get_batch_size(self) -> int:\n",
    "        \"\"\"Get the batch size.\n",
    "\n",
    "        Returns:\n",
    "            int: The batch size.\n",
    "        \"\"\"\n",
    "        return self.batch_size\n",
    "\n",
    "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
    "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
    "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
    "    def get_batch(self, names: list[str]) -> list[int] | None:\n",
    "        \"\"\"Get a batch of data.\n",
    "\n",
    "        Args:\n",
    "            names (List[str]): The names of the engine bindings.\n",
    "\n",
    "        Returns:\n",
    "            Optional[List[int]]: The device input pointer, or None if there is no more data.\n",
    "        \"\"\"\n",
    "        # print(\"names:\", names)\n",
    "        if self.current_index + self.batch_size > self.data.shape[0]:\n",
    "            return None\n",
    "\n",
    "        current_batch = int(self.current_index / self.batch_size)\n",
    "        if current_batch % 10 == 0:\n",
    "            print(\n",
    "                f\"Calibrating batch {current_batch}, containing {self.batch_size} images\"\n",
    "            )\n",
    "\n",
    "        batch = self.data[\n",
    "            self.current_index : self.current_index + self.batch_size\n",
    "        ].ravel()\n",
    "        # cuda.memcpy_htod(self.device_input, batch)\n",
    "        # memcpy_host_to_device(self.device_input, batch)\n",
    "        memcpy_host_to_device(self.device_input, np.ascontiguousarray(batch))\n",
    "        self.current_index += self.batch_size\n",
    "        # print(\"Schalom!\")\n",
    "        return [int(self.device_input)]\n",
    "\n",
    "    def read_calibration_cache(self) -> bytes | None:\n",
    "        \"\"\"Read the calibration cache.\n",
    "\n",
    "        Returns:\n",
    "            Optional[bytes]: The calibration cache, or None if it does not exist.\n",
    "        \"\"\"\n",
    "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
    "        if Path.exists(self.cache_file):\n",
    "            return Path(self.cache_file).read_bytes()\n",
    "            # with open(self.cache_file, \"rb\") as f:\n",
    "            #    return f.read()\n",
    "        return None\n",
    "\n",
    "    def write_calibration_cache(self, cache: bytes) -> None:\n",
    "        \"\"\"Write the calibration cache.\n",
    "\n",
    "        Args:\n",
    "            cache (bytes): The calibration cache.\n",
    "        \"\"\"\n",
    "        return  # for now\n",
    "        Path(self.cache_file).write_bytes(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6k2njAel4z6"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tensorrt as trt\n",
    "\n",
    "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
    "TRT_LOGGER: trt.Logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "\n",
    "\n",
    "def build_engine_onnx(\n",
    "    model_file: str, trt_engine_path: str, precision: str\n",
    ") -> None | None:\n",
    "    \"\"\"Builds a TensorRT engine from an ONNX model file.\n",
    "\n",
    "    Args:\n",
    "        model_file (str): The path to the ONNX model file.\n",
    "        trt_engine_path (str): The path to save the TensorRT engine.\n",
    "        precision (str): The precision mode to use ('fp16', 'int8', 'mixed').\n",
    "\n",
    "    Returns:\n",
    "        Optional[None]: Returns None if the engine creation fails.\n",
    "    \"\"\"\n",
    "    seq_len: int = 2**12\n",
    "    max_batch_size: list[int] = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "    calibration_batch_size: int = 16\n",
    "    builder: trt.Builder = trt.Builder(TRT_LOGGER)\n",
    "    network: trt.INetworkDefinition = builder.create_network(0)\n",
    "    config: trt.IBuilderConfig = builder.create_builder_config()\n",
    "    parser: trt.OnnxParser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "\n",
    "    config.set_memory_pool_limit(\n",
    "        trt.MemoryPoolType.WORKSPACE, 8 * 1 << 30\n",
    "    )  # TODO: Constant\n",
    "\n",
    "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    if not parser.parse(Path(model_file).read_bytes()):\n",
    "        print(\"ERROR: Failed to parse the ONNX file.\")\n",
    "        for error in range(parser.num_errors):\n",
    "            print(parser.get_error(error))\n",
    "        return\n",
    "\n",
    "    for b in max_batch_size:\n",
    "        profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
    "        profile.set_shape(\"input\", [1, seq_len, 1], [b, seq_len, 1], [b, seq_len, 1])\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "    if precision in [\"fp16\", \"int8\", \"mixed\"]:\n",
    "        if not builder.platform_has_fast_fp16:\n",
    "            print(\"FP16 is not supported natively on this platform/device\")\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "    if precision in [\"int8\", \"mixed\"]:\n",
    "        if not builder.platform_has_fast_int8:\n",
    "            print(\"INT8 is not supported natively on this platform/device\")\n",
    "        config.set_flag(trt.BuilderFlag.INT8)\n",
    "        # config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
    "\n",
    "        calib = MNISTEntropyCalibrator(\n",
    "            \"\", cache_file=\"cache.file\", batch_size=calibration_batch_size\n",
    "        )\n",
    "        config.int8_calibrator = calib\n",
    "\n",
    "        calib_profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
    "        calib_profile.set_shape(\n",
    "            \"input\",\n",
    "            [calibration_batch_size, seq_len, 1],\n",
    "            [calibration_batch_size, seq_len, 1],\n",
    "            [calibration_batch_size, seq_len, 1],\n",
    "        )\n",
    "        config.set_calibration_profile(calib_profile)\n",
    "        config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
    "\n",
    "        print(\"int 8 model\")\n",
    "\n",
    "    engine_bytes: bytes | None = builder.build_serialized_network(network, config)\n",
    "\n",
    "    if engine_bytes is None:\n",
    "        print(\"Failed to create the TensorRT engine\")\n",
    "        return\n",
    "    trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "    # Save the engine to a file\n",
    "    Path(trt_engine_path).write_bytes(engine_bytes)\n",
    "\n",
    "    print(f\"TensorRT engine saved to {trt_engine_path}\")\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "precision: str = \"int8\"\n",
    "onnx_path: str = \"dtmf_classifier.onnx\"\n",
    "trt_path: str = \"dtmf_classifier_\" + precision + \"_\" + get_gpu_type() + \".trt\"\n",
    "build_engine_onnx(onnx_path, trt_path, precision=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VY4AP6jrmJKg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def print_dbg(*x: Any) -> None:\n",
    "    \"\"\"Print debug information if DEBUG is set to True.\n",
    "\n",
    "    Args:\n",
    "        *x (Any): The information to print.\n",
    "    \"\"\"\n",
    "    if DEBUG:\n",
    "        print(x)\n",
    "\n",
    "\n",
    "class TensorRTInfer:\n",
    "    # TODO: This code still has a memory leak. The memory allocated by\n",
    "    # cudaMalloc has to be released!\n",
    "    \"\"\"Implements inference for the TensorRT engine.\"\"\"\n",
    "\n",
    "    def __init__(self, engine_path: str) -> None:\n",
    "        \"\"\"Initialize the TensorRTInfer class.\n",
    "\n",
    "        Args:\n",
    "            engine_path (str): The path to the serialized engine to load from disk.\n",
    "        \"\"\"\n",
    "        # Load TRT engine\n",
    "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
    "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
    "        # with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
    "        #    assert runtime\n",
    "        #    self.engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        runtime = trt.Runtime(self.logger)\n",
    "        assert runtime\n",
    "        self.engine = runtime.deserialize_cuda_engine(Path(engine_path).read_bytes())\n",
    "\n",
    "        assert self.engine\n",
    "        self.context = self.engine.create_execution_context()\n",
    "        assert self.context\n",
    "\n",
    "        # Some Infos about the engine\n",
    "        print_dbg(\"num optimization profiles:\", self.engine.num_optimization_profiles)\n",
    "        print_dbg(\"num io tensors:\", self.engine.num_io_tensors)\n",
    "\n",
    "        # Create CUDA stream for asynchronous tasks\n",
    "        _, self.stream = cudart.cudaStreamCreate()\n",
    "\n",
    "        # Setup I/O bindings\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        self.allocations = []\n",
    "        for prof_idx in range(self.engine.num_optimization_profiles):\n",
    "            for i in range(self.engine.num_io_tensors):\n",
    "                name = self.engine.get_tensor_name(i)\n",
    "                is_input = False\n",
    "                if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
    "                    is_input = True\n",
    "                dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))\n",
    "                shape = self.engine.get_tensor_shape(name)\n",
    "                if is_input and shape[0] < 0:\n",
    "                    assert self.engine.num_optimization_profiles > 1\n",
    "                    profile_shape = self.engine.get_tensor_profile_shape(name, prof_idx)\n",
    "                    print_dbg(\"profile_shape\", name, profile_shape)\n",
    "                    assert len(profile_shape) == 3  # min,opt,max\n",
    "\n",
    "                    # Set the *max* profile as binding shape\n",
    "                    self.switch_profile(prof_idx)\n",
    "                    self.context.set_input_shape(name, profile_shape[2])\n",
    "                    shape = self.context.get_tensor_shape(name)\n",
    "\n",
    "                if not is_input:\n",
    "                    shape = self.context.get_tensor_shape(name)\n",
    "                    print_dbg(\"shape for output:\", name, shape)\n",
    "\n",
    "                if is_input:\n",
    "                    self.batch_size = shape[0]\n",
    "                size = dtype.itemsize\n",
    "                for s in shape:\n",
    "                    size *= s\n",
    "                allocation = cuda_call(cudart.cudaMalloc(size))\n",
    "                host_allocation = None if is_input else np.zeros(shape, dtype)\n",
    "                binding = {\n",
    "                    \"index\": i,\n",
    "                    \"name\": name,\n",
    "                    \"dtype\": dtype,\n",
    "                    \"shape\": list(shape),\n",
    "                    \"allocation\": allocation,\n",
    "                    \"host_allocation\": host_allocation,\n",
    "                }\n",
    "                self.allocations.append(allocation)\n",
    "                if is_input:\n",
    "                    self.inputs.append(binding)\n",
    "                else:\n",
    "                    self.outputs.append(binding)\n",
    "                print_dbg(\n",
    "                    \"{} '{}' with shape {} and dtype {}\".format(\n",
    "                        \"Input\" if is_input else \"Output\",\n",
    "                        binding[\"name\"],\n",
    "                        binding[\"shape\"],\n",
    "                        binding[\"dtype\"],\n",
    "                    )\n",
    "                )\n",
    "            print_dbg()\n",
    "\n",
    "        assert self.batch_size > 0\n",
    "        assert len(self.inputs) > 0\n",
    "        assert len(self.outputs) > 0\n",
    "        assert len(self.allocations) > 0\n",
    "\n",
    "    def input_spec(self) -> tuple[list[int], np.dtype]:\n",
    "        \"\"\"Get the specs for the input tensor of the network. Useful to prepare memory allocations.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], np.dtype]: Two items, the shape of the input tensor and its (numpy) datatype.\n",
    "        \"\"\"\n",
    "        # TODO: Index 0 is wrong\n",
    "        return self.inputs[0][\"shape\"], self.inputs[0][\"dtype\"]\n",
    "\n",
    "    def output_spec(self) -> list[tuple[list[int], np.dtype]]:\n",
    "        \"\"\"Get the specs for the output tensors of the network. Useful to prepare memory allocations.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[List[int], np.dtype]]: A list with two items per element, the shape and (numpy) datatype of each output tensor.\n",
    "        \"\"\"\n",
    "        specs = []\n",
    "        for o in self.outputs:\n",
    "            specs.append((o[\"shape\"], o[\"dtype\"]))\n",
    "        return specs\n",
    "\n",
    "    def switch_profile(self, idx: int) -> None:\n",
    "        \"\"\"Switch to a different optimization profile.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the optimization profile to switch to.\n",
    "        \"\"\"\n",
    "        self.context.set_optimization_profile_async(\n",
    "            idx, self.stream\n",
    "        )  # Switch to profile 1 (index 1)\n",
    "\n",
    "    def infer(self, batch: np.ndarray) -> list[np.ndarray]:\n",
    "        \"\"\"Execute inference on a batch of images.\n",
    "\n",
    "        Args:\n",
    "            batch (np.ndarray): A numpy array holding the image batch.\n",
    "\n",
    "        Returns:\n",
    "            List[np.ndarray]: A list of outputs as numpy arrays.\n",
    "        \"\"\"\n",
    "        # If the optimization profile does not match, change it here:\n",
    "        # In our setup the opt. profiles are selected in a way that the\n",
    "        # optimal batch sizes are powers of 2. In practice, one would not do\n",
    "        # it in this way:\n",
    "        expected_profile = int(np.log2(batch.shape[0]))\n",
    "        if self.context.active_optimization_profile != expected_profile:\n",
    "            print(\"Changing to profile\", expected_profile)\n",
    "            self.switch_profile(expected_profile)\n",
    "\n",
    "        if self.context.get_tensor_shape(\"input\") != batch.shape:\n",
    "            print(\"Changing batch size for inference!\")\n",
    "\n",
    "            # Adapt the input shape:\n",
    "            self.context.set_input_shape(\"input\", batch.shape)\n",
    "        print_dbg(\n",
    "            \"self.engine.get_tensor_shape(input)\", self.engine.get_tensor_shape(\"input\")\n",
    "        )\n",
    "        print_dbg(\n",
    "            \"self.context.get_tensor_shape(input)\",\n",
    "            self.context.get_tensor_shape(\"input\"),\n",
    "        )\n",
    "        print_dbg(\n",
    "            \"self.context.get_tensor_shape(output)\",\n",
    "            self.context.get_tensor_shape(\"output\"),\n",
    "        )\n",
    "        print_dbg()\n",
    "\n",
    "        o_idx = self.context.active_optimization_profile\n",
    "        print_dbg(\"Active output index (opt. profile)\", o_idx)\n",
    "\n",
    "        # Copy I/O and Execute\n",
    "        memcpy_host_to_device(self.inputs[o_idx][\"allocation\"], batch)\n",
    "\n",
    "        self.context.execute_v2(self.allocations)\n",
    "        memcpy_device_to_host(\n",
    "            self.outputs[o_idx][\"host_allocation\"], self.outputs[o_idx][\"allocation\"]\n",
    "        )\n",
    "\n",
    "        return [self.outputs[o_idx][\"host_allocation\"]]\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Main function to run the TensorRT inference.\"\"\"\n",
    "    seq_len = 2**12\n",
    "    trt_infer = TensorRTInfer(trt_path)\n",
    "\n",
    "    print(\"Starting inference\")\n",
    "    if False:\n",
    "        spec = trt_infer.input_spec()\n",
    "        print(\"spec\", spec)\n",
    "        # batch = my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
    "        X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=seq_len)\n",
    "        o = trt_infer.infer(X.astype(np.float32))[0][: X.shape[0]]\n",
    "        print(\"o.shape\", o.shape)\n",
    "\n",
    "        thresholded = (o > 0.5).astype(int)\n",
    "        print((thresholded == Y).sum() / Y.size)\n",
    "        for iidx in range(X.shape[0]):\n",
    "            predicted_key_sequence = dtmf_gen.decode_prediction(o[iidx])\n",
    "            original_key_sequence = dtmf_gen.decode_prediction(Y[iidx])\n",
    "            if predicted_key_sequence != original_key_sequence:\n",
    "                print(\"predicted_key_sequence\", predicted_key_sequence)\n",
    "                print(\"original_key_sequence\", original_key_sequence)\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        print(\"No input provided, running in benchmark mode\")\n",
    "        trt_infer.switch_profile(1)\n",
    "        spec = trt_infer.input_spec()\n",
    "        # TODO:\n",
    "        spec = (1, 4096, 1), np.float32\n",
    "\n",
    "        rng = np.random.default_rng()\n",
    "        batch = rng.random(spec[0]).astype(spec[1])\n",
    "        # batch = np.random.rand(*spec[0]).astype(spec[1])\n",
    "\n",
    "        print(\"batch.shape\", batch.shape)\n",
    "        print(\"batch.dtype\", batch.dtype)\n",
    "        print(\"min/max/mean\", batch.min(), batch.max(), batch.mean())\n",
    "        iterations = 100\n",
    "        times = []\n",
    "        for i in range(20):  # GPU warmup iterations\n",
    "            trt_infer.infer(batch)\n",
    "        for i in range(iterations):\n",
    "            start = time.time()\n",
    "            o = trt_infer.infer(batch)\n",
    "            # print(\"o.shape\", o[0].shape)\n",
    "            times.append(time.time() - start)\n",
    "            print(f\"Iteration {i + 1} / {iterations}\", end=\"\\r\")\n",
    "        print(\"Benchmark results include time for H2D and D2H memory copies\")\n",
    "        print(f\"Average Latency: {1000 * np.average(times):.3f} ms\")\n",
    "        print(f\"Average Throughput: {trt_infer.batch_size / np.average(times):.1f} ips\")\n",
    "\n",
    "    print()\n",
    "    print(\"Finished Processing\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN2XVzIyy_Ww"
   },
   "source": [
    "## Erneutes Training des Keras Modells (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Shl0yW5zcdri"
   },
   "outputs": [],
   "source": [
    "from techdays25.dtmf_generation import DtmfGenerator\n",
    "from techdays25.dtmf_models import build_dtmf_classifier_model\n",
    "\n",
    "dtmf_gen = DtmfGenerator(\n",
    "    dur_key=(0.05, 0.1),\n",
    "    dur_pause=(0.01, 0.1),\n",
    "    noise_factor=(10.0, 50.0),\n",
    "    noise_freq_range=(0.0, 20000.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iN_hSCvRHtgy"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
    "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
    "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AWzMtPVQkgb"
   },
   "outputs": [],
   "source": [
    "# from collections.abc import Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XX1JtkVWTrI5"
   },
   "outputs": [],
   "source": [
    "model = build_dtmf_classifier_model((None, 1), dtmf_gen.get_num_keys() + 1)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")  # multi-label\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcganU0yPkdG"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=64, epochs=50, validation_data=(X_val, Y_val))\n",
    "model.save(\"dtmf_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNrpNO97eX3Y"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"dtmf_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoeSluZ-MoYQ"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "idx = 9\n",
    "\n",
    "# TODO: Duplicate Code below:\n",
    "pred = model.predict(X_val[idx : idx + 1])\n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(X_val[idx, :, 0])\n",
    "\n",
    "for key_idx in range(pred.shape[-1] - 1):  # last index represents pauses\n",
    "    plt.plot(\n",
    "        pred[0, :, key_idx],\n",
    "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
    "        color=colors[key_idx],\n",
    "    )\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
    "plt.show()\n",
    "\n",
    "wavfile.write(\n",
    "    \"val.wav\",\n",
    "    dtmf_gen.get_sample_rate(),\n",
    "    (X_val[idx] * np.iinfo(np.int32).max).flatten().astype(np.int32),\n",
    ")\n",
    "IPython.display.Audio(\"val.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SozwcF8LNNIZ"
   },
   "outputs": [],
   "source": [
    "# Compute Accuracy\n",
    "pred = model.predict(X_val)\n",
    "thresholded = (pred > 0.5).astype(int)\n",
    "\n",
    "(thresholded == Y_val).sum() / Y_val.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgfqAPHRf7OJ"
   },
   "source": [
    "# TRTExec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dNOfG_zsJAx"
   },
   "outputs": [],
   "source": [
    "!uname -a\n",
    "!cat /etc/os-release\n",
    "!ls -l /usr/local\n",
    "!nvcc --version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKxcfRC-l55h"
   },
   "source": [
    "# Experiments with different Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbQfmvwtIUei"
   },
   "outputs": [],
   "source": [
    "# Import tensorrt_libs\n",
    "\n",
    "# Import ONNX dependencies\n",
    "from onnxruntime.quantization import (\n",
    "    CalibrationDataReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4y0ndHlTcqzX"
   },
   "source": [
    "# Further Experiments with Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlBaeR_oBUS7"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.float_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frFXsleBYGPT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def float_to_binary_fp32(num: float) -> str:\n",
    "    \"\"\"Converts a built-in floating point number (64-bit) to its FP32 binary representation.\n",
    "\n",
    "    Args:\n",
    "        num (float): The floating point number to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the binary format of the floating point number.\n",
    "    \"\"\"\n",
    "    print(\"fp32:\", num)\n",
    "    return \"\".join(f\"{c:0>8b}\" for c in struct.pack(\"!f\", num))\n",
    "\n",
    "\n",
    "def float_to_binary_fp16(num: float) -> str:\n",
    "    \"\"\"Converts a builtin-in floating point number to a 16-bit floating point number and returns its binary representation.\n",
    "\n",
    "    Args:\n",
    "        num (float): The floating point number to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the binary format of the 16-bit floating point number.\n",
    "    \"\"\"\n",
    "    # Convert the number to a float16\n",
    "    float16_num = np.float16(num)\n",
    "\n",
    "    print(\"fp16:\", float16_num)\n",
    "\n",
    "    # Convert the float16 to bytes\n",
    "    float16_bytes = float16_num.tobytes()\n",
    "\n",
    "    # Convert the bytes to a binary string (big endian notation)\n",
    "    return \"\".join(f\"{byte:08b}\" for byte in reversed(float16_bytes))\n",
    "\n",
    "\n",
    "def float_to_binary_bf16(num: float) -> str:\n",
    "    \"\"\"Converts a floating point number to bfloat16  and returns its binary representation.\n",
    "\n",
    "    Args:\n",
    "        num (float): The floating point number to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the binary format of the bfloat16 floating point number.\n",
    "    \"\"\"\n",
    "    # Create a tensor with the given number\n",
    "    a = torch.Tensor([num])\n",
    "\n",
    "    # Convert the tensor to bfloat16\n",
    "    bf = a.bfloat16()\n",
    "\n",
    "    print(\"bf16\", bf)\n",
    "\n",
    "    # Convert the bfloat16 tensor to bytes\n",
    "    bf_bytes = bytes(bf.untyped_storage())\n",
    "\n",
    "    # Convert the bytes to a binary string (big endian notation)\n",
    "    return \"\".join(f\"{byte:08b}\" for byte in reversed(bf_bytes))\n",
    "\n",
    "\n",
    "def float_to_binary_fp8_e4m3(num: float) -> str:\n",
    "    \"\"\"Converts a  floating point number to float8 (e4m3) and returns its binary representation.\n",
    "\n",
    "    Args:\n",
    "        num (float): The floating point number to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the binary format of the float8 (e4m3) floating point number.\n",
    "    \"\"\"\n",
    "    # Create a tensor with the given number\n",
    "    a = torch.Tensor([num])\n",
    "\n",
    "    # Convert the tensor to float8 (e4m3)\n",
    "    bf = a.to(torch.float8_e4m3fn)\n",
    "\n",
    "    print(\"fp8_e4m3\", bf)\n",
    "\n",
    "    # Convert the float8 tensor to bytes\n",
    "    bf_bytes = bytes(bf.untyped_storage())\n",
    "\n",
    "    # Convert the bytes to a binary string\n",
    "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
    "\n",
    "\n",
    "def float_to_binary_fp8_e5m2(num: float) -> str:\n",
    "    \"\"\"Converts a floating point number to float8 (e5m2)  and returns its binary representation.\n",
    "\n",
    "    Args:\n",
    "        num (float): The floating point number to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the binary format of the float8 (e5m2) floating point number.\n",
    "    \"\"\"\n",
    "    # Create a tensor with the given number\n",
    "    a = torch.Tensor([num])\n",
    "\n",
    "    # Convert the tensor to float8 (e5m2)\n",
    "    bf = a.to(torch.float8_e5m2)\n",
    "\n",
    "    print(\"fp8_e5m2\", bf)\n",
    "\n",
    "    # Convert the float8 tensor to bytes\n",
    "    bf_bytes = bytes(bf.untyped_storage())\n",
    "\n",
    "    # Convert the bytes to a binary string\n",
    "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
    "\n",
    "\n",
    "def float_to_binary_int(num: float, bit_length: int = 8) -> str:\n",
    "    \"\"\"Converts a floating point number to its binary representation as an integer.\n",
    "\n",
    "    Args:\n",
    "        num (float): The floating point number to convert.\n",
    "        bit_length (int, optional): The bit length of the binary representation. Defaults to 8.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the binary format of the integer part of the floating point number.\n",
    "    \"\"\"\n",
    "    return np.binary_repr(round(num), width=bit_length)\n",
    "\n",
    "\n",
    "num = -8.875074538462327 - 2**-7 - 2**-8\n",
    "float_to_binary_fp32(num)\n",
    "# float_to_binary_fp16(num)\n",
    "# float_to_binary_bf16(num)\n",
    "# float_to_binary_fp8_e4m3(num)\n",
    "# float_to_binary_fp8_e5m2(num)\n",
    "# float_to_binary_int(num, bit_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_f2kRTHj4Qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ubud1lCaBUS8"
   },
   "outputs": [],
   "source": [
    "-num - 2**3 - 2**-1 - 2**-2 - 2**-3 - 2**-7 - 2**-8\n",
    "\n",
    "\n",
    "(int(\"1111011100011101\", base=2) - 2**16) / 2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-X1F7z9BUS8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s = \"1100100001111100\"\n",
    "b = int(s, base=2).to_bytes(2, \"little\")\n",
    "print(b)\n",
    "c = np.frombuffer(b, dtype=np.float16, count=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGjV-2lyBUS9"
   },
   "outputs": [],
   "source": [
    "# Binary string\n",
    "binary_string = \"11000001000011111000101100101011\"\n",
    "\n",
    "# Convert the binary string to an integer\n",
    "binary_int = int(binary_string, 2)\n",
    "\n",
    "# Convert the integer to bytes (4 bytes for float32)\n",
    "binary_bytes = binary_int.to_bytes(4, byteorder=\"big\")\n",
    "\n",
    "# Unpack the bytes to a float\n",
    "float_value = struct.unpack(\">f\", binary_bytes)[0]\n",
    "\n",
    "print(float_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeF16bolNFX1"
   },
   "source": [
    "# Analyze Model in Frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtRh4Dp-TUbs"
   },
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def multiple_formatter(\n",
    "    denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
    ") -> Callable[[float, int], str]:\n",
    "    \"\"\"Creates a formatter function for matplotlib that formats axis labels as multiples of a given number.\n",
    "\n",
    "    Args:\n",
    "        denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
    "        number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
    "        latex (str, optional): The LaTeX string to use for the base number.\n",
    "\n",
    "    Returns:\n",
    "        Callable[[float, int], str]: A function that formats a given value as a LaTeX fraction of the base number.\n",
    "    \"\"\"\n",
    "\n",
    "    def gcd(a: int, b: int) -> int:\n",
    "        \"\"\"Computes the greatest common divisor of two integers.\n",
    "\n",
    "        Args:\n",
    "            a (int): The first integer.\n",
    "            b (int): The second integer.\n",
    "\n",
    "        Returns:\n",
    "            int: The greatest common divisor of a and b.\n",
    "        \"\"\"\n",
    "        while b:\n",
    "            a, b = b, a % b\n",
    "        return a\n",
    "\n",
    "    def _multiple_formatter(x: float, pos: int) -> str:\n",
    "        \"\"\"Formats a given value as a LaTeX fraction of the base number.\n",
    "\n",
    "        Args:\n",
    "            x (float): The value to format.\n",
    "            pos (int): The position (not used in this implementation).\n",
    "\n",
    "        Returns:\n",
    "            str: The formatted string.\n",
    "        \"\"\"\n",
    "        den = denominator\n",
    "        num = np.int64(np.rint(den * x / number))\n",
    "        com = gcd(num, den)\n",
    "        (num, den) = (int(num / com), int(den / com))\n",
    "        if den == 1:\n",
    "            if num == 0:\n",
    "                return r\"$0$\"\n",
    "            if num == 1:\n",
    "                return rf\"${latex}$\"\n",
    "            if num == -1:\n",
    "                return rf\"$-{latex}$\"\n",
    "            return rf\"${num}{latex}$\"\n",
    "        if num == 1:\n",
    "            return rf\"$\\frac{{{latex}}}{{{den}}}$\"\n",
    "        if num == -1:\n",
    "            return rf\"$\\frac{{-{latex}}}{{{den}}}$\"\n",
    "        return rf\"$\\frac{{{num}{latex}}}{{{den}}}$\"\n",
    "\n",
    "    return _multiple_formatter\n",
    "\n",
    "\n",
    "class Multiple:\n",
    "    \"\"\"A class to create locators and formatters for matplotlib axes based on multiples of a given number.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
    "    ):\n",
    "        \"\"\"Initializes the Multiple class with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
    "            number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
    "            latex (str, optional): The LaTeX string to use for the base number.\n",
    "        \"\"\"\n",
    "        self.denominator = denominator\n",
    "        self.number = number\n",
    "        self.latex = latex\n",
    "\n",
    "    def locator(self) -> plt.MultipleLocator:\n",
    "        \"\"\"Creates a locator for matplotlib axes based on multiples of the base number.\n",
    "\n",
    "        Returns:\n",
    "            plt.MultipleLocator: A locator for matplotlib axes.\n",
    "        \"\"\"\n",
    "        return plt.MultipleLocator(self.number / self.denominator)\n",
    "\n",
    "    def formatter(self) -> plt.FuncFormatter:\n",
    "        \"\"\"Creates a formatter for matplotlib axes that formats labels as multiples of the base number.\n",
    "\n",
    "        Returns:\n",
    "            plt.FuncFormatter: A formatter for matplotlib axes.\n",
    "        \"\"\"\n",
    "        return plt.FuncFormatter(\n",
    "            multiple_formatter(self.denominator, self.number, self.latex)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3us2xVYGRQS6"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Copyright (c) 2011 Christopher Felton\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Lesser General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU Lesser General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU Lesser General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "#\n",
    "\n",
    "# The following is derived from the slides presented by\n",
    "# Alexander Kain for CS506/606 \"Special Topics: Speech Signal Processing\"\n",
    "# CSLU / OHSU, Spring Term 2011.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import patches\n",
    "\n",
    "\n",
    "def zplane(b, a, filename=None):\n",
    "    \"\"\"Will probably be removed soon.\n",
    "\n",
    "    Args:\n",
    "        b (_type_): _description_\n",
    "        a (_type_): _description_\n",
    "        filename (_type_, optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # get a figure/plot\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    # create the unit circle\n",
    "    uc = patches.Circle((0, 0), radius=1, fill=False, color=\"black\", ls=\"dashed\")\n",
    "    ax.add_patch(uc)\n",
    "\n",
    "    # The coefficients are less than 1, normalize the coeficients\n",
    "    if np.max(b) > 1:\n",
    "        kn = np.max(b)\n",
    "        b = b / float(kn)\n",
    "    else:\n",
    "        kn = 1\n",
    "\n",
    "    if np.max(a) > 1:\n",
    "        kd = np.max(a)\n",
    "        a = a / float(kd)\n",
    "    else:\n",
    "        kd = 1\n",
    "\n",
    "    # Get the poles and zeros\n",
    "    # p = np.roots(a)\n",
    "    # z = np.roots(b)\n",
    "    # k = kn/float(kd)\n",
    "    # Markus:\n",
    "    z, p, k = signal.tf2zpk(b, a)\n",
    "\n",
    "    # Plot the zeros and set marker properties\n",
    "    t1 = plt.plot(z.real, z.imag, \"go\", ms=10)\n",
    "    plt.setp(\n",
    "        t1,\n",
    "        markersize=10.0,\n",
    "        markeredgewidth=1.0,\n",
    "        markeredgecolor=\"k\",\n",
    "        markerfacecolor=\"g\",\n",
    "    )\n",
    "\n",
    "    # Plot the poles and set marker properties\n",
    "    t2 = plt.plot(p.real, p.imag, \"rx\", ms=10)\n",
    "    plt.setp(\n",
    "        t2,\n",
    "        markersize=12.0,\n",
    "        markeredgewidth=3.0,\n",
    "        markeredgecolor=\"r\",\n",
    "        markerfacecolor=\"r\",\n",
    "    )\n",
    "\n",
    "    ax.spines[\"left\"].set_position(\"center\")\n",
    "    ax.spines[\"bottom\"].set_position(\"center\")\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    # set the ticks\n",
    "    r = 1.5\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.axis([-r, r, -r, r])\n",
    "    ticks = [-1, -0.5, 0.5, 1]\n",
    "    plt.xticks(ticks)\n",
    "    plt.yticks(ticks)\n",
    "\n",
    "    if filename is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "    return z, p, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXofb-I-NH8R"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ze0NbFHqNO-K"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVexf_PdNVDg"
   },
   "outputs": [],
   "source": [
    "# Assuming 'model' is your Keras model and 'n' is the index of the layer you are interested in\n",
    "n = 0  # Example: Get the weights and name of the 3rd layer (indexing starts from 0)\n",
    "\n",
    "# Access the n-th layer\n",
    "nth_layer = model.layers[n]\n",
    "\n",
    "# Get the weights of the n-th layer\n",
    "weights = nth_layer.get_weights()\n",
    "\n",
    "# Get the name of the n-th layer\n",
    "layer_name = nth_layer.name\n",
    "\n",
    "# Print the name and weights of the n-th layer\n",
    "print(f\"Name der {n + 1}. Schicht (Index {n}): {layer_name}\")\n",
    "# print(f\"Gewichte der {n+1}. Schicht (Index {n}):\\n\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejseu_jkNlci"
   },
   "outputs": [],
   "source": [
    "weights[0].shape  # (kernel_size, channels, num_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ay9hPpIUPf-M"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "fig = plt.figure(figsize=(10, 2 * 6))\n",
    "\n",
    "for z in range(8):\n",
    "    dil_rate = 1\n",
    "    b = weights[0][:, 0, 2 * z]  # (kernel_size, channels, num_filters)\n",
    "    w, h = signal.freqz(b[::-1])\n",
    "    if dil_rate > 1:\n",
    "        m = b.shape\n",
    "        out = np.zeros((dil_rate) * m[0], dtype=b.dtype)\n",
    "        out[::dil_rate] = b\n",
    "        b = out[: -dil_rate + 1]\n",
    "        w, h = signal.freqz(b[::-1])\n",
    "\n",
    "    ax1 = fig.add_subplot(421 + z)\n",
    "\n",
    "    ax1.set_title(\"q=\" + str(dil_rate))\n",
    "\n",
    "    # plt.plot(w, 20 * np.log10(abs(h)), 'b')\n",
    "    plt.plot(w, abs(h), \"b\")\n",
    "    if z % 2 == 0:\n",
    "        plt.ylabel(\"Amplitude [dB]\", color=\"b\")\n",
    "    if z // 2 == 1:\n",
    "        plt.xlabel(r\"$\\hat\\omega$ [rad]\")  # Frequency [rad/sample]\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    angles = np.unwrap(np.angle(h))\n",
    "    # angles = angles % (2 * np.pi) - np.pi\n",
    "    plt.plot(w, angles, \"g\")\n",
    "    if z % 2 == 1:\n",
    "        plt.ylabel(\"Angle [rad]\", color=\"g\")\n",
    "    plt.grid()\n",
    "    # plt.axis('tight')\n",
    "\n",
    "    ax1.xaxis.grid(True)\n",
    "    ax1.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n",
    "    ax1.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 10))\n",
    "    ax1.xaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
    "\n",
    "    ax2.yaxis.grid(True)\n",
    "    ax2.yaxis.set_major_locator(plt.MultipleLocator(dil_rate * np.pi))\n",
    "    # ax2.yaxis.set_minor_locator(plt.MultipleLocator(2*np.pi))\n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
    "\n",
    "plt.tight_layout(pad=0.5)\n",
    "# plt.savefig(\"pdf/example-frequency-response-ecg1.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zg3V72mRHeN"
   },
   "outputs": [],
   "source": [
    "zplane(b=b, a=np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FNI7hwmWHzP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def zplane(b, a=np.array([1])):\n",
    "    \"\"\"Plot the complex z-plane given a transfer function.\"\"\"\n",
    "    # Create a unit circle\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "    unit_circle = plt.Circle((0, 0), 1, color=\"gray\", fill=False, linestyle=\"dotted\")\n",
    "    ax.add_artist(unit_circle)\n",
    "\n",
    "    # Plot zeros and poles\n",
    "    zeros = np.roots(b)\n",
    "    poles = np.roots(a)\n",
    "    plt.scatter(\n",
    "        np.real(zeros),\n",
    "        np.imag(zeros),\n",
    "        s=50,\n",
    "        marker=\"o\",\n",
    "        facecolors=\"none\",\n",
    "        edgecolors=\"b\",\n",
    "        label=\"Zeros\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        np.real(poles), np.imag(poles), s=50, marker=\"x\", color=\"r\", label=\"Poles\"\n",
    "    )\n",
    "\n",
    "    # Set plot limits and labels\n",
    "    plt.xlim(-1.5, 1.5)\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    plt.axhline(0, color=\"black\", lw=1)\n",
    "    plt.axvline(0, color=\"black\", lw=1)\n",
    "    plt.xlabel(\"Real Part\")\n",
    "    plt.ylabel(\"Imaginary Part\")\n",
    "    plt.title(\"Z-Plane Diagram\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example: Design a low-pass FIR filter using the window method\n",
    "# numtaps = 21  # Number of filter coefficients (taps)\n",
    "# cutoff = 0.3  # Normalized cutoff frequency (0 to 1, where 1 corresponds to Nyquist frequency)\n",
    "# b = firwin(numtaps, cutoff)\n",
    "\n",
    "# Plot the z-plane diagram for the FIR filter\n",
    "zplane(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlaYfNloX8Gr"
   },
   "outputs": [],
   "source": [
    "from scipy.signal import tf2zpk\n",
    "\n",
    "tf2zpk([3, 0, 0], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZVoVdBPNsXy"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(None, 3)),\n",
    "    layers.Conv1D(\n",
    "        32,\n",
    "        kernel_size=15,\n",
    "        activation=\"relu\",\n",
    "        padding=\"same\",\n",
    "    ),\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
