{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusThill/techdays25/blob/feature-lab2-initial-draft/notebooks/lab2-model-quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWrVTJSVVy4"
      },
      "source": [
        "# üöÄ Lab 2: Effiziente Quantisierung tiefer neuronaler Netze\n",
        "- Dieses Jupyter Notebook **ben√∂tigt eine GPU Laufzeit**. Falls nicht bereits voreingestellt, kann daher der Laufzeittyp im Men√º unter \"Laufzeit\" > \"Laufzeittyp √§ndern\" > \"Hardwarebeschleuniger\" > **\"T4 GPU\"** ge√§ndert werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2hhcmOjXQXB"
      },
      "source": [
        "Strukturierung:\n",
        "- Teil 1: Darstellung numerischer Datentypen\n",
        "- Teil 2:\n",
        "  - Quantisierung des einfachen Modells aus Lab 1\n",
        "  - Diverse Betrachtungen auf dem quantisierten Modell (Genauigkeit, etc.)\n",
        "  - Gotchas (Optional): Overflow/Underflow am Beispiel eines Average Pooling layers\n",
        "  - Subnormal Numbers\n",
        "  - ...\n",
        "- Teil 3: Quantisierung eines DTMF Klassifikationsmodells\n",
        "  - Illustration: Erzeugung einer DTMF W√§hlsequenz und Abspielen derselben\n",
        "  - Laden eines vortrainierten DTMF-Klassifikationsmodells (ConvNet; Keras oder PyTorch)\n",
        "  - Konvertierung nach ONNX\n",
        "  - Quantisierung nach FP16\n",
        "  - Messung der Inferenzzeiten (auch f√ºr verschiedene Batch-Sizes) und vergleich von FP32, FP16-Modell\n",
        "  - Vergleich der Genauigkeit von FP16 und FP32 Modell (wie √§ndert sich die Fehlerrate)\n",
        "  - Optional: Konvertierung nach FP8 und Wiederholung der obigen Schritte\n",
        "  - Optional: Profiling der ONNX Modelle. Wo liegen die \"Hotspots\" des Modells?\n",
        "  - Optional: Trainieren des Modells auf de\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHjiyBN9VVy4"
      },
      "source": [
        "# Vorbereitungen: Installation der n√∂tigen Abh√§ngigkeiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zRp0QsBVVy5"
      },
      "outputs": [],
      "source": [
        "# Remove the `%%capture`, if you have the impression that something is going wrong during the setup\n",
        "# %%capture\n",
        "!pip install \"techdays25[lab2] @ git+https://github.com/MarkusThill/techdays25.git@feature-lab2-initial-draft\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PetUdSKZVVy5"
      },
      "source": [
        "**WICHTIG: Nach der Installation der Abh√§ngigkeiten (siehe oben) muss die Google Colab Laufzeit neugestartet werden! Im Anschluss kann mit der Ausf√ºhrung der n√§chsten Zellen fortgefahren werden werden.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/MarkusThill/techdays25.git\"\n",
        "!cd techdays25 && git checkout feature-lab2-initial-draft"
      ],
      "metadata": {
        "id": "TvMZAZUyiYx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf2wjy7rVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Colab-spezifische Konfigurationen {display-mode: \"form\"}\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "\n",
        "    output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPuTmcJKVVy5"
      },
      "source": [
        "# üìò Einleitung\n",
        "- DTMF\n",
        "- Quanstisierungsans√§tze\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-emxsEEVVy5"
      },
      "source": [
        "# üìñ Teil 1: Darstellung numerischer Datentypen\n",
        "- Zweierkomplementdarstellung\n",
        "- IEEE-754 Standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0MW1AnSVVy5"
      },
      "source": [
        "### Ganzahldarstellungen/Zweierkomplementdarstellung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfRcqICXVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 8-Bit Integer Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Initialize 8 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"40px\")\n",
        "    )\n",
        "    for _ in range(8)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Hex representation (2 hex digits for 8 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>{bit_string}</code><br>\n",
        "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
        "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
        "            Hexadecimal: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.HBox(bit_toggles))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDlSxZqOVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Grundlegendes Setzen von Bits: Setze das 3. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
        "Erwartete Antwort: 4\n",
        "\n",
        "- Setzen mehrerer Bits: Setze das 1., 3. und 5. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
        "Erwartete Antwort: 21\n",
        "\n",
        "- Was ist die gr√∂√ütm√∂gliche bzw. kleinstm√∂gliche Zahl die mit 8 Bit dargestellt werden k√∂nnen? Antwort: -128, +127\n",
        "  - Was w√§re die Antwort, wenn wir statt 8-bit Integer, nun 32-bit Integer haben?\n",
        "\n",
        "- Signed vs. Unsigned Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -128, Unsigned: 128\n",
        "\n",
        "- Was charakterisiert eine negative Zahl in der Zweierkomplementdarstellung (unsigned integer) im Allgmeinen? Antwort: Zumindest das vorderste Bit ist gesetzt.\n",
        "\n",
        "- Wie negiere ich eine Zahl (z.B. 32 -> -32 bzw. -71 -> 71)? Antwort: Invertieren alle Bits und Addition  von 1\n",
        "\n",
        "- Angenommen ich habe -33 als 8-bit Zahl vorliegen. Wie w√ºrde ich daraus eine 32-bit unsigned Integer Zahl machen? Antwort: Einfach noch drei Bytes voranh√§ngen in denen alle Bits gesetzt sind.\n",
        "\n",
        "- Kombinieren von Bits: Setze das 2., 4. und 6. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: 42, Unsigned: 42\n",
        "\n",
        "- Negative Zahlen in der Signed-Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) und das 1. Bit (niederwertigstes Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -127, Unsigned: 129\n",
        "\n",
        "- Maximale und minimale Werte: Was ist der maximale Wert, den man mit einer 8-Bit unsigned Zahl darstellen kann? Was ist der minimale Wert, den man mit einer 8-Bit signed Zahl darstellen kann?\n",
        "Erwartete Antwort: Maximale unsigned: 255, Minimale signed: -128\n",
        "\n",
        "- Bitmuster und Werte: Setze die Bits, um die Bin√§rzahl 10101010 zu bilden. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -86, Unsigned: 170\n",
        "\n",
        "- Alle Bits gesetzt: Setze alle Bits einer 8-Bit-Zahl auf 1. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -1, Unsigned: 255\n",
        "\n",
        "\n",
        "- Verst√§ndnis von √úberlauf: Was passiert, wenn du 1 zum maximalen Wert einer 8-Bit unsigned Zahl hinzuf√ºgst? Was passiert bei einer 8-Bit signed Zahl?\n",
        "Erwartete Antwort: Bei unsigned wird es auf 0 zur√ºckgesetzt. Bei signed verursacht es einen √úberlauf und wird auf den minimalen Wert (-128) zur√ºckgesetzt.\n",
        "Zweierkomplement:\n",
        "\n",
        "- Erkl√§re, wie die Zweierkomplement-Darstellung f√ºr negative Zahlen in einer 8-Bit signed Zahl funktioniert.\n",
        "Erwartete Antwort: Im Zweierkomplement ist das h√∂chstwertige Bit (MSB) das Vorzeichenbit. Um das Zweierkomplement einer Zahl zu finden, invertiere alle Bits und addiere 1 zum niederwertigsten Bit (LSB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q1kp8MaVVy6"
      },
      "source": [
        "### Fixkommadarstellungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCrHNptuVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit Festkomma-Zahlen (engl.: fixpoint binary representations) {display-mode: \"form\"}\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Initialize 16 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, integer part, and fractional part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 7\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "# def twos_complement(bits):\n",
        "#    \"\"\"Convert list of bits to signed integer using two's complement.\"\"\"\n",
        "#    if bits[0] == 0:\n",
        "#        return int(\"\".join(str(b) for b in bits), 2)\n",
        "#\n",
        "#    # If MSB is 1, it's negative\n",
        "#    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "#    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "#    return -incremented\n",
        "\n",
        "\n",
        "def fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to a fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = twos_complement(integer_part)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Fixed-point value\n",
        "    fixed_point_decimal = fixed_point_value(bit_values)\n",
        "\n",
        "    # Hex representation (4 hex digits for 16 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:8]}</span>.\n",
        "                <span style=\"color: blue;\">{bit_string[8:]}</span>\n",
        "            </code><br>\n",
        "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
        "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
        "            Fixed-Point Decimal: <b>{fixed_point_decimal}</b><br>\n",
        "            Hexadecimal: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN_oFcfjVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmRekLfxVVy6"
      },
      "source": [
        "### Flie√ükommadarstellungen nach IEEE-754\n",
        "- TODO: Subnormal Numbers\n",
        "- Webseite mit noch mehr Darstellungen: https://evanw.github.io/float-toy/\n",
        "- Verschiedene FP8-Darstellungen: https://asawicki.info/articles/fp8_tables.php\n",
        "- https://onnx.ai/onnx/technical/float8.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8LgC7KNVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit (FP16) Flie√ükomma-Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import struct\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, exponent, and mantissa\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 5\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show FP16 value and components\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def bits_to_float16(bits: list[int]) -> np.float16:\n",
        "    \"\"\"Convert list of bits to FP16 float value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        np.float16: The FP16 float value of the binary number.\n",
        "    \"\"\"\n",
        "    bit_string = \"\".join(str(b) for b in bits)\n",
        "    # Convert binary string to integer\n",
        "    int_value = int(bit_string, 2)\n",
        "    # Pack as unsigned 16-bit int, then unpack as float16 using numpy\n",
        "    packed = struct.pack(\"<H\", int_value)  # Big endian 16-bit unsigned int\n",
        "    return np.frombuffer(packed, dtype=np.float16)[0]\n",
        "\n",
        "\n",
        "def update_display(*args):\n",
        "    \"\"\"Update the display with the current binary, FP16 float value, and its components.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Extract components\n",
        "    sign = bit_values[0]\n",
        "    exponent_bits = bit_values[1:6]\n",
        "    mantissa_bits = bit_values[6:]\n",
        "\n",
        "    exponent = int(\"\".join(str(b) for b in exponent_bits), 2)\n",
        "    exponent_unbiased = exponent - 15  # Bias = 15\n",
        "\n",
        "    mantissa_raw = \"\".join(str(b) for b in mantissa_bits)\n",
        "    (\n",
        "        1 + sum(int(b) * 2 ** (-i) for i, b in enumerate(mantissa_bits, start=1))\n",
        "        if exponent != 0\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "    # Convert to float16 value\n",
        "    fp16_value = bits_to_float16(bit_values)\n",
        "\n",
        "    # Clear previous output and display new info\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:6]}</span>\n",
        "                <span style=\"color: blue;\">{bit_string[6:]}</span>\n",
        "            </code><br>\n",
        "            Sign (1 bit): <b>{sign}</b> ({\"-\" if sign else \"+\"})<br>\n",
        "            Exponent (5 bits): <b>{\"\".join(str(b) for b in exponent_bits)} (biased: {exponent}, unbiased: {exponent_unbiased})</b><br>\n",
        "            Mantissa (10 bits): <b>{mantissa_raw}</b><br>\n",
        "            <hr>\n",
        "            <b>FP16 Value:</b> {fp16_value}\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize output\n",
        "update_display()  # 0 01111 0000000001 ^=^ 1.00097656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBCmHSNeVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Gibt es einen Unterschied zwischen +0.0 und -0.0?\n",
        "- Wie stelle ich `+Inf` bzw. `-Inf` dar?\n",
        "- Wie stelle ich `NaN` dar?\n",
        "- Was ergibt der Vergleich `float(\"nan\") != float(\"nan\")`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7youIav3VVy7"
      },
      "source": [
        "# üî¢Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
        "- Gotchas: zu gro√üe, kleine inputs, numerische Abweichungen. Ggfs.: Sehr kleines Gewicht, sehr gro√üer Input.\n",
        "- Abweichungen bestimmen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KX9mB2kgqHH"
      },
      "outputs": [],
      "source": [
        "# TODO: Move to\n",
        "# Load necessary libs\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import onnx\n",
        "import pandas as pd\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "from techdays25.onnx_utils import (\n",
        "    OnnxModel,\n",
        "    benchmark_models_on_batch_size,\n",
        "    plot_benchmark_results,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ls-fTM1gqHH"
      },
      "source": [
        "## Quantisiere ONNX Modell nach FP16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbYQ_9fjMCUD"
      },
      "outputs": [],
      "source": [
        "# Specify, which model to use:\n",
        "onnx_model_path = Path(\"techdays25/assets/lab1/pytorch_regression.onnx\")\n",
        "\n",
        "# Load the previously saved FP32 ONNX model\n",
        "regression_model_fp32 = onnx.load(onnx_model_path)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    regression_model_fp32,  # path to the onnx model\n",
        "    min_positive_val=1e-7,  # Constant values will be clipped to these bounds\n",
        "    max_finite_val=1e4,  # same as above\n",
        "    keep_io_types=True,  # If set to false, the IO types will change to FP16\n",
        "    disable_shape_infer=False,  # Skips running onnx shape/type inference\n",
        "    op_block_list=None,  # A list of OPs which shall not be quantized\n",
        "    node_block_list=None,  # A list of nodes which shall not be converted\n",
        ")\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_fp16_path = onnx_model_path.stem + \"_fp16\" + onnx_model_path.suffix\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_fp16_path)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_fp16_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbOmu6lDgqHI"
      },
      "source": [
        "## Quantisiere Modell nach INT8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cemKbQh6gqHI"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process\n",
        "\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = np.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8,\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_77SjqWgqHI"
      },
      "source": [
        "## Netron Visualisierung der ONNX Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPJlTiVRgqHI"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "# Change model path accordingly:\n",
        "onnx_utils.netron_visualize(\"pytorch_regression_int8.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ZYUTq7gqHI"
      },
      "source": [
        "## Vergleich der quantisierten Modellvarianten mit urspr√ºnglichem Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX1nKqsDgqHI"
      },
      "outputs": [],
      "source": [
        "reg_model_fp32_cpu = OnnxModel(onnx_model_path, provider=\"CPUExecutionProvider\")\n",
        "reg_model_fp16_cpu = OnnxModel(onnx_model_fp16_path, provider=\"CPUExecutionProvider\")\n",
        "reg_model_int8_cpu = OnnxModel(onnx_model_path_int8, provider=\"CPUExecutionProvider\")\n",
        "\n",
        "reg_model_fp32_gpu = OnnxModel(onnx_model_path, provider=\"CUDAExecutionProvider\")\n",
        "reg_model_fp16_gpu = OnnxModel(onnx_model_fp16_path, provider=\"CUDAExecutionProvider\")\n",
        "reg_model_int8_gpu = OnnxModel(onnx_model_path_int8, provider=\"CUDAExecutionProvider\")\n",
        "\n",
        "print(\"\\nSpezifikation des FP16 Modells:\")\n",
        "print(reg_model_fp16_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGYkUWNzMJGz"
      },
      "outputs": [],
      "source": [
        "# Create some random data and compare the results of the FP16 and FP32 models\n",
        "u_range = (-10, 10)  # set range for which input values shall be generated\n",
        "\n",
        "models = {\n",
        "    \"FP32/CPU\": reg_model_fp32_cpu,  # first model is the reference\n",
        "    \"FP16/CPU\": reg_model_fp16_cpu,\n",
        "    #\"INT8/CPU\": reg_model_int8_cpu,\n",
        "    # \"FP32/GPU\": reg_model_fp32_gpu,\n",
        "    \"FP16/GPU\": reg_model_fp16_gpu,\n",
        "    \"INT8/GPU\": reg_model_int8_gpu,\n",
        "}\n",
        "\n",
        "uu = np.linspace(*u_range, 15).reshape(-1, 1).astype(np.float32)\n",
        "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
        "\n",
        "# Extract the first key-value pair (this is the reference)\n",
        "first_key = next(iter(ii_predictions))\n",
        "first_value = ii_predictions[first_key]\n",
        "ii_diffs = {\n",
        "    \"Œî\" + k: first_value - v for k, v in ii_predictions.items() if k != first_key\n",
        "}\n",
        "\n",
        "df_data = {\"Input [U/V]\": uu.flatten()}\n",
        "\n",
        "df_data.update(ii_predictions)\n",
        "df_data.update(ii_diffs)\n",
        "\n",
        "pd.DataFrame(df_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzNNq4CUgqHI"
      },
      "source": [
        "## Fragen:\n",
        "- Wie verhalten sich die Modellausgaben/Differenzen der beiden obigen Modelle f√ºr unterschiedliche Bereiche, die in `u_range` spezifiziert werden, z.B. f√ºr `u_range=(0,100)` oder `u_range=(-1000, 1000)`?\n",
        "- Wie lassen sich m√∂gliche Abweichungen erkl√§ren?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRlxbLaqgqHI"
      },
      "outputs": [],
      "source": [
        "# systematically evaluate the model differences for a larger range\n",
        "uu = np.linspace(-20, 20, 100000).reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
        "# Extract the first key-value pair (this is the reference)\n",
        "ref_key = next(iter(ii_predictions))\n",
        "ref_value = ii_predictions[ref_key]\n",
        "ii_diffs = {k: ref_value - v for k, v in ii_predictions.items() if k != ref_key}\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "# plt.plot(uu, ii_fp32_ - ii_fp16_)\n",
        "for k, v in ii_diffs.items():\n",
        "    plt.plot(uu, v, label=k)\n",
        "\n",
        "# plt.yscale(\"symlog\", linthresh=.0001)\n",
        "plt.grid(which=\"both\")\n",
        "plt.xlabel(\"U [V]\")\n",
        "plt.ylabel(r\"$\\hat{I}_{FP32} - \\hat{I}_{FP16}$ [mA]\")\n",
        "plt.legend()\n",
        "plt.title(f\"Abweichungen diverser ONNX Modelle zur Referenz {first_key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJnVIlNxgqHJ"
      },
      "outputs": [],
      "source": [
        "batch_sizes = [2**i for i in range(20, 25)]\n",
        "model_dict = {\n",
        "    #\"ONNX Regression Model (FP32/CPU)\": reg_model_fp32_cpu.predict,\n",
        "    #\"ONNX Regression Model (FP16/CPU)\": reg_model_fp16_cpu.predict,\n",
        "    #\"ONNX Regression Model (INT8/CPU)\": reg_model_int8_cpu.predict,\n",
        "    \"ONNX Regression Model (FP32/GPU)\": reg_model_fp32_gpu.predict,\n",
        "    \"ONNX Regression Model (FP16/GPU)\": reg_model_fp16_gpu.predict,\n",
        "    \"ONNX Regression Model (INT8/GPU)\": reg_model_int8_gpu.predict,\n",
        "}\n",
        "\n",
        "benchmark_results = benchmark_models_on_batch_size(\n",
        "    model_dict=model_dict,\n",
        "    input_shape=(1,),\n",
        "    batch_sizes=batch_sizes,\n",
        "    n_runs=100,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg8OpUBIgqHJ"
      },
      "outputs": [],
      "source": [
        "plot_benchmark_results(results=benchmark_results, title=\"\", xscale=\"log\", yscale=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fd481-eMB-R"
      },
      "source": [
        "# üï∏ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
        "\n",
        "In diesem Teil werden wir uns damit befassen, welche Probleme bei der Modellquantisierung auftreten k√∂nnen und dies anhand eines Beispiels illustrieren. Folgende Schritte werden durchgef√ºhrt:\n",
        "- Erstellen eines benutzerdefinierten Modells in Keras zur Mittelwertbildung √ºber entlang der Zeitachse.\n",
        "- Konvertieren des Keras-Modells in das ONNX-Format.\n",
        "- Quantisieren des ONNX-Modells von FP32 auf FP16.\n",
        "- Generierung von 3-dimensionalen Zeitreihendaten f√ºr die Modellinferenz.\n",
        "- Modellinferenz mit dem Keras-Modell.\n",
        "- Modellinferenz mit den FP32/FP16 ONNX-Modellen:\n",
        "  - Laden und Ausf√ºhren von ONNX-Modellen mit der ONNX Runtime.\n",
        "  - Vergleich der Ausgaben von FP32- und FP16-ONNX-Modellen.\n",
        "- Diskussion der Beobachtungen und m√∂glicher L√∂sungen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pncih_L8dWVa"
      },
      "source": [
        "## Modelldefinition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya6rTWHfamy3"
      },
      "source": [
        "Unser Modell unten nimmt einen 3-dimensionalen Eingabetensor mit den Dimensionen (Batch-Gr√∂√üe, Sequenzl√§nge, Merkmalsanzahl) entgegen. In unserem Beispiel hat der Eingabetensor die Form (2, 10000, 3), was bedeutet, dass wir zwei Batch-Elemente haben, jedes mit einer Sequenzl√§nge von 10000 und 3 Merkmalen pro Zeitschritt.\n",
        "\n",
        "Nach der Verarbeitung durch das Modell wird die Zeitdimension reduziert, und die Ausgabe hat die Form (Batch-Gr√∂√üe, Merkmalsanzahl). F√ºr unser Beispiel ergibt sich eine Ausgabe mit der Form (2, 3). Die Ausgabe repr√§sentiert den Durchschnitt der Merkmale √ºber die gesamte Sequenzl√§nge f√ºr jedes Batch-Element.\n",
        "\n",
        "**Beispiel**\n",
        "\n",
        "Eingabetensor (2 x 4 x 3):\n",
        "```\n",
        "[\n",
        "    [3, 4, 5],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "  ],\n",
        "  [\n",
        "    [2, 4, 6],\n",
        "    [8, 10, 12],\n",
        "    [14, 16, 18],\n",
        "    [20, 22, 24]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "Ausgabetensor (2 x 3):\n",
        "```\n",
        "[\n",
        "  [ 6,  7,  8],\n",
        "  [11, 13, 15]\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBhX8Vul3feC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Layer\n",
        "\n",
        "\n",
        "class SumLayer(Layer):\n",
        "    \"\"\"Custom Layer to sum over time dimension of a tensor.\"\"\"\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"Reduce (sum) the input tensor along the time axis (axis=1).\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): The input tensor of shape (batch_size, sequence_length, feature_dim).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The reduced tensor of shape (batch_size, feature_dim).\n",
        "        \"\"\"\n",
        "        return tf.reduce_sum(inputs, axis=1)\n",
        "\n",
        "\n",
        "# Custom Layer: Division by sequence length\n",
        "class DivisionLayer(Layer):\n",
        "    \"\"\"Divide a tensor by the length of the given sequence.\"\"\"\n",
        "\n",
        "    def call(self, inputs: tuple[tf.Tensor, tf.Tensor]) -> tf.Tensor:\n",
        "        \"\"\"Divide the summed tensor by the sequence length to get the average.\n",
        "\n",
        "        Args:\n",
        "            inputs (Tuple[tf.Tensor, tf.Tensor]): A tuple containing the summed tensor and the original input tensor.\n",
        "                - tensor_x (tf.Tensor): The summed tensor of shape (batch_size, feature_dim).\n",
        "                - original_input (tf.Tensor): The original input tensor of shape (batch_size, sequence_length, feature_dim).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The averaged tensor of shape (batch_size, feature_dim).\n",
        "        \"\"\"\n",
        "        tensor_x, original_input = inputs\n",
        "        seq_length = tf.shape(original_input)[\n",
        "            1\n",
        "        ]  # Get the dynamic sequence length (length of the time dimension)\n",
        "        return tensor_x / tf.cast(seq_length, dtype=tensor_x.dtype)\n",
        "\n",
        "\n",
        "# Define model with separate Sum and Division layers\n",
        "def global_average_pooling_1d() -> Model:\n",
        "    \"\"\"Define a Keras model with separate Sum and Division layers for global average pooling.\n",
        "\n",
        "    Returns:\n",
        "        Model: A Keras model that performs global average pooling over the time dimension.\n",
        "    \"\"\"\n",
        "    inputs = Input(\n",
        "        shape=(None, 3), name=\"input\"\n",
        "    )  # Define the input layer with shape (sequence_length=None, feature_dim=3)\n",
        "    sum_x = SumLayer(name=\"sum\")(inputs)  # Apply the SumLayer to the inputs\n",
        "    output = DivisionLayer(name=\"divide\")([\n",
        "        sum_x,\n",
        "        inputs,\n",
        "    ])  # Apply the DivisionLayer to the summed tensor and the original inputs\n",
        "    return Model(\n",
        "        inputs, output, name=\"GlobalAveragePooling1D\"\n",
        "    )  # Create the Keras model with the specified input and output\n",
        "\n",
        "\n",
        "# Create the model\n",
        "model = global_average_pooling_1d()\n",
        "\n",
        "# Print model summary to see the architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_5U6zHgR-_"
      },
      "source": [
        "## Modellkonvertierung nach ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-9pMzIv6oUY"
      },
      "outputs": [],
      "source": [
        "# Convert our GlobalAveragePooling1D Model to ONNX format\n",
        "import onnx  # ONNX library for handling ONNX models\n",
        "import tf2onnx  # TensorFlow to ONNX conversion library\n",
        "from onnxconverter_common import float16  # Utility for FP16 conversion\n",
        "\n",
        "# Define the path where the FP32 ONNX model will be saved\n",
        "onnx_model_path_fp32 = \"gap1d_model_fp32.onnx\"\n",
        "\n",
        "# Convert the Keras model to ONNX format with FP32 precision\n",
        "# Define the input specification for the model conversion\n",
        "spec = (tf.TensorSpec((None, None, 3), tf.float32, name=\"input\"),)\n",
        "# Convert the Keras model to ONNX using tf2onnx\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=18)\n",
        "\n",
        "# Save the converted FP32 ONNX model to the specified path\n",
        "onnx.save(onnx_model, onnx_model_path_fp32)\n",
        "print(f\"ONNX model (FP32) saved to {onnx_model_path_fp32}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdLdCuQBgaLi"
      },
      "source": [
        "## Quantisierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8A1tP9V679a"
      },
      "outputs": [],
      "source": [
        "# Now quantize the ONNX model to FP16 and save it\n",
        "\n",
        "# Load the previously saved FP32 ONNX model\n",
        "onnx_model_fp32 = onnx.load(onnx_model_path_fp32)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(onnx_model_fp32, keep_io_types=True)\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_path_fp16 = \"gap1d_model_fp16.onnx\"\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_path_fp16)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_path_fp16}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7m2fr58kMm"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"gap1d_model_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R_B8RE7ggas"
      },
      "source": [
        "## Datengenerierung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PORbJXNx4yav"
      },
      "outputs": [],
      "source": [
        "# First create some data and put it through the Keras model\n",
        "import matplotlib.pyplot as plt  # Library for plotting\n",
        "import numpy as np  # Library for numerical operations\n",
        "\n",
        "# Create a random input tensor with a batch size of 2\n",
        "# Generate a sequence of numbers from 0 to 9999 and reshape it to (1, 10000, 1)\n",
        "tt = np.arange(10_000).reshape(1, -1, 1)\n",
        "\n",
        "# Create an offset array and reverse it\n",
        "off = (np.array(np.arange(6)).astype(np.float32) + 4)[::-1]\n",
        "\n",
        "# Generate a 3-dimensional time series data using a sine function with the offset\n",
        "xx = 0.4 * np.sin(4 * np.pi * 1e-5 * off**2 * tt) + off\n",
        "\n",
        "# Reshape the data to have dimensions (sequence_length, batch_size, feature_dim)\n",
        "xx = xx.reshape(-1, 2, 3)\n",
        "\n",
        "# Swap the axes to get the shape (batch_size, sequence_length, feature_dim)\n",
        "xx = np.swapaxes(xx, 0, 1)\n",
        "\n",
        "# Convert the data to float32 type\n",
        "x_input = xx.astype(np.float32)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensions of the input tensor:\", x_input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGQTVao-GYZM"
      },
      "outputs": [],
      "source": [
        "# Plot the generated time series data\n",
        "import matplotlib.pyplot as plt  # Library for plotting (re-imported for completeness)\n",
        "\n",
        "# Create a new figure with a specified size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the first batch (b$_1$) of the time series data\n",
        "plt.plot(xx[0, :, :], label=\"b$_1$\")\n",
        "\n",
        "# Plot the second batch (b$_2$) of the time series data\n",
        "plt.plot(xx[1, :, :], label=\"b$_2$\")\n",
        "\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"Index\")\n",
        "\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"Amplitude\")\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Ein Batch bestehend aus jeweils zwei 3-dimensionalen Zeitreihen\")\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(1.1, 0.6), ncol=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRHQY_j_gzEj"
      },
      "source": [
        "## Inferenz mit dem Keras Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9EP5mXQ-Ln2"
      },
      "outputs": [],
      "source": [
        "# Put the data through the Keras model\n",
        "\n",
        "# Use the Keras model to make predictions on the input data\n",
        "y_output_keras = model.predict(x_input)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensionen des Eingabetensors:\", x_input.shape)  # Erwartete Form: (2, 10000, 3)\n",
        "\n",
        "# Print the dimensions of the Keras model output\n",
        "print(\n",
        "    \"Dimensionen der Keras-Modellausgabe:\", y_output_keras.shape\n",
        ")  # Erwartete Form: (2, 3) -> Zeitdimension reduziert!\n",
        "\n",
        "# Print the output of the Keras model\n",
        "print(\"Keras-Modellausgabe:\\n\", y_output_keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq_N1o4Sg7p9"
      },
      "source": [
        "## Inferenz mit den FP32/FP16 ONNX Modellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8LdB2clSPgQ"
      },
      "outputs": [],
      "source": [
        "# Run the FP32 ONNX model\n",
        "# run_onnx_model(onnx_model_path=\"gap1d_model_fp32.onnx\", x_input=x_input)\n",
        "OnnxModel(onnx_model_path=\"gap1d_model_fp32.onnx\").predict(x_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8wCn4znSZ_s"
      },
      "outputs": [],
      "source": [
        "# Run the FP16 ONNX model\n",
        "# run_onnx_model(onnx_model_path=\"gap1d_model_fp16.onnx\", x_input=x_input)\n",
        "OnnxModel(onnx_model_path=\"gap1d_model_fp16.onnx\").predict(x_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsQD-7RzO2Ao"
      },
      "source": [
        "## Fragen / Diskussion\n",
        "- Welche Ergebnisse erwarten wir? Stimmen die Ergebnisse mit den Erwartungen √ºberein?\n",
        "- Was f√§llt bei der Ausgabe des quantisierten FP16 Modells auf?\n",
        "  - Wie k√∂nnte man sich dieses Ergebnis erkl√§ren?\n",
        "  - L√§sst sich das Problem ggfs. vermeiden?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5i-XeVZVVy7"
      },
      "source": [
        "# üìû Teil 4: Quantisierung eines DTMF Klassifikationsmodells\n",
        "\n",
        "## TODO: Profiling in ONNX/TRT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG6JRjlfVVy7"
      },
      "source": [
        "## Einf√ºhrung: Generierung und Dekodierung/Klassifizierung von DTMF (dual-tone multi-frequency) Signalen <a class=\"anchor\" id=\"part0\"></a>\n",
        "\n",
        "\n",
        "Das Dualton-Mehrfrequenzwahlverfahren (DTMF) ist ein Signalisierungssystem f√ºr das W√§hlen eines Telefons, das in den fr√ºhen 1960er Jahren von Western Electric entwickelt und sp√§ter von Bell System kommerziell an Telefonkunden geliefert wurde.\n",
        "Wenn eine Taste auf dem Telefon gedr√ºckt wird, werden zwei harmonische Tonsignale erzeugt, und die Superposition/√úberlagerung beider Signale wird verwendet, um die entsprechende Telefontaste zu charakterisieren. Wenn zum Beispiel die Taste ‚Äû5‚Äú gedr√ºckt wird, entsteht ein Dualtontonsignal, das sich aus den Frequenzen 770 Hz und 1336 Hz zusammensetzt. Die beiden Frequenzen, die jede Taste beschreiben, sind in der folgenden Tabelle aufgef√ºhrt:\n",
        "\n",
        "|   | 1209Hz  | 1336 Hz  | 1477 Hz   | 1633 Hz  |\n",
        "|---|:---:|:---:|:---:|:---:|\n",
        "| **697 Hz**  |  1 | 2  | 3  | A  |\n",
        "| **770 Hz**  |  4 | 5  | 6  | B  |\n",
        "| **852 Hz**  |  7 | 8  | 9  | C  |\n",
        "| **941 Hz**  |  * | 0  | #  | D  |\n",
        "\n",
        "In diesem Beispiel werden wir uns ansehen, wie man solche DTMF-W√§hlsequenzen generiert, sie in einer Audiodatei speichert und das Audiosignal mit einem einfachen KI-Modell wieder dekodiert.\n",
        "\n",
        "Wir werden die folgenden Schritte durchf√ºhren, um ein DTMF-Signal zu erzeugen und mit einem Klassifikationsmodell zu dekodieren:\n",
        "1. Erzeugung des Signals und der Audiodatei mit `scipy` und `numpy`. Wir speichern die erzeugte Audiodatei in einer `.wav` Datei, die in diesem Notebook oder in deinem lokalen Audioplayer abgespielt werden kann\n",
        "2. Wir entwerfen eine einfaches KI-Modell ... TODO\n",
        "3. Extraktion der gew√§hlten Tastenfolge aus der `.wav`-Datei unter Verwendung des KI-Modells\n",
        "4. Quantisierung & Export des Modells nach ONNX im FP32 und FP16 Format. Quantisierung nach INT8 und Export nach TensorRT.\n",
        "5. Laufzeituntersuchungen f√ºr FP32/FP16/INT8, unterschiedliche Batch-Gr√∂√üen und Signall√§ngen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXOs32MVVy7"
      },
      "outputs": [],
      "source": [
        "# Trainiere Modell\n",
        "# Konvertiere Modell nach ONNX (einmal FP32, einmal FP16)\n",
        "# Untersuche Laufzeitunterschiede (auch nach batchsize)\n",
        "# Untersuche Abweichungen. Wie √§ndert sich die Fehlerrate des Modells f√ºr FP32/Fp16?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51a6fcd-760a-4926-8d68-7f75eddb906a"
      },
      "source": [
        "## Signal- und Audiodatei-Generierung <a class=\"anchor\" id=\"part1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9360855-39ba-450f-975b-ebd7f48a5521"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# from collections.abc import Callable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kR8O3oWRKR"
      },
      "outputs": [],
      "source": [
        "# @title Tastenfeld-Widget f√ºr Generierung der W√§hlsequenz' {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize a text widget to display the dial sequence\n",
        "dial_sequence = widgets.Text(\n",
        "    value=\"\",\n",
        "    placeholder=\"Dial sequence will appear here...\",\n",
        "    description=\"\",\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width=\"300px\"),\n",
        ")\n",
        "\n",
        "\n",
        "# Function to handle button clicks\n",
        "def on_button_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    dial_sequence.value += b.description\n",
        "\n",
        "\n",
        "# Create buttons for the phone dialer\n",
        "buttons = []\n",
        "for row in [\n",
        "    [\"1\", \"2\", \"3\", \"A\"],\n",
        "    [\"4\", \"5\", \"6\", \"B\"],\n",
        "    [\"7\", \"8\", \"9\", \"C\"],\n",
        "    [\"*\", \"0\", \"#\", \"D\"],\n",
        "]:\n",
        "    button_row = []\n",
        "    for label in row:\n",
        "        button = widgets.Button(\n",
        "            description=label, layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        "        )\n",
        "        button.on_click(on_button_click)\n",
        "        button_row.append(button)\n",
        "    buttons.append(widgets.HBox(button_row))\n",
        "\n",
        "# Create a clear button\n",
        "clear_button = widgets.Button(\n",
        "    description=\"Clear\", layout=widgets.Layout(width=\"158px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "back_button = widgets.Button(\n",
        "    description=\"‚¨Ö\", layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "\n",
        "def on_clear_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = \"\"\n",
        "\n",
        "\n",
        "def on_back_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = dial_sequence.value[:-1]\n",
        "\n",
        "\n",
        "clear_button.on_click(on_clear_click)\n",
        "\n",
        "\n",
        "back_button.on_click(on_back_click)\n",
        "\n",
        "# Display the dialer\n",
        "display(dial_sequence)\n",
        "for button_row in buttons:\n",
        "    display(button_row)\n",
        "display(widgets.HBox([clear_button, back_button]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V728NfPmsAQr"
      },
      "outputs": [],
      "source": [
        "print(\"Gew√§hlte Sequenz:\", dial_sequence.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8i2MsZF3o0g"
      },
      "source": [
        "### Generierung des W√§hl-Audiosignals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAyM34wYqx_A"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.2, 0.3),\n",
        "    dur_pause=(0.01, 0.1),\n",
        "    noise_factor=(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62132ef1-c61f-4653-9f6c-a4d9f892781e"
      },
      "outputs": [],
      "source": [
        "# Either use the dialed sequence from above:\n",
        "my_dialed_sequence_keys = dial_sequence.value\n",
        "\n",
        "# ... or generate a random sequence:\n",
        "# my_dialed_sequence_keys = \"\".join([random.choice(\"1234567890ABCD*#\") for i in range(10)])\n",
        "\n",
        "# ... or use a simple sequence for debugging purposes\n",
        "# my_dialed_sequence_keys = \"1234567890ABCD*#\" # for debug purposes...\n",
        "\n",
        "# ... or use a slightly longer sequence (which also contains all symbols)\n",
        "# my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "if not my_dialed_sequence_keys:\n",
        "    my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "\n",
        "# Try changing the following arguments: dur_key=0.05, dur_pause=0.02\n",
        "my_dialed_sequence_signal = dtmf_gen.get_tone_sequence(my_dialed_sequence_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-9x6ncx3wiD"
      },
      "source": [
        "### Visualisierung des Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aarMEIq3vS0m"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Das vollst√§ndige gew√§hlte Signal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWiuyJ_7BUS6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal[: 10**4])\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Die ersten 10000 Datenpunkte des gew√§hlten Signals\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJe9QX8Ee9aA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "quant = np.quantile(my_dialed_sequence_signal, 0.99)\n",
        "start_index = np.where(my_dialed_sequence_signal > quant)[0][10]\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Weiterer Zoom-In\")\n",
        "plt.xlim(start_index, start_index + 1.5 * 10**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42af11c2-3c15-4a57-afa8-f62b8e82925d"
      },
      "outputs": [],
      "source": [
        "# Now let us listen to the generated WAV file\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "wav_file_name = \"my_dtmf_file.wav\"\n",
        "\n",
        "wavfile.write(\n",
        "    wav_file_name,\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (my_dialed_sequence_signal * np.iinfo(np.int32).max).astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(wav_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51a52767-7e0e-444f-8028-f5a52fce4820"
      },
      "outputs": [],
      "source": [
        "print(\"Dialed sequence: \", my_dialed_sequence_keys)\n",
        "print(\"Used symbols: \", len(set(my_dialed_sequence_keys)))\n",
        "print(\"Total length of signal:\", my_dialed_sequence_signal.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b763fef4-360e-4a01-910b-add573007fd3"
      },
      "source": [
        "### Signal-Spektrogramm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7827a985-0dd0-40c0-993c-e002523ef0e9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "Pxx, freqs, bins, im = plt.specgram(\n",
        "    my_dialed_sequence_signal, NFFT=1024, Fs=dtmf_gen.get_sample_rate()\n",
        ")\n",
        "plt.ylim(0, 2000)\n",
        "plt.xlabel(\"t [s]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "plt.title(\"Spektrogramm des generierten Telefonw√§hlsignals\")\n",
        "plt.show(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aio7fvyo4ZUy"
      },
      "source": [
        "## Experimente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHys5X74cRB"
      },
      "source": [
        "### Laden des vortrainierten Keras Modells\n",
        "\n",
        "TODO: Einf√ºhrung: Was ist die Eingabe/Ausgabe des Modells\n",
        "Was ist das f√ºr ein Modell, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4Tks3yH0ipe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "keras_model = tf.keras.models.load_model(\"dtmf_classifier.keras\")\n",
        "keras_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesc3J6SUBOv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "keras_pred = keras_model.predict(my_dialed_sequence_signal.reshape(1, -1, 1))\n",
        "end = time.time()\n",
        "\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "\n",
        "for key_idx in range(keras_pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        keras_pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
        "plt.title(f\"Tats√§chliche Wahlsequenz: {' '.join(list(my_dialed_sequence_keys))}\")\n",
        "plt.show()\n",
        "print(\"Inferenz-Dauer:\", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_zpgnG6CviY"
      },
      "outputs": [],
      "source": [
        "predicted_key_sequence = dtmf_gen.decode_prediction(keras_pred)\n",
        "print(\"Prognostizierte W√§hlsequenz:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlich gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-97qYaeo4k86"
      },
      "source": [
        "### Konvertierung des Keras Modells nach ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0niGbjMEhna"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "\n",
        "# Diese Zelle k√∂nnte einen Fehler werfen.\n",
        "# Dennoch sollte das ONNX Modell korrekt exportiert werden\n",
        "keras_model.output_names = [\"output\"]\n",
        "\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, 2**12, 1], tf.float32, name=\"input\")\n",
        "]  # TODO: time axis fixed or dynamic?\n",
        "# Use from_function for tf functions\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(keras_model, input_signature, opset=18)\n",
        "onnx.save(onnx_model, \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-CLAhtx4tTw"
      },
      "source": [
        "### Optimierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5PAAutNg2bE"
      },
      "outputs": [],
      "source": [
        "import onnxsim\n",
        "\n",
        "model_path = \"dtmf_classifier.onnx\"\n",
        "simplified_model_path = \"dtmf_classifier.onnx\"\n",
        "onnx_model = onnx.load(model_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_simp, check = onnxsim.simplify(onnx_model)\n",
        "assert check, \"Simplified ONNX model could not be validated\"\n",
        "onnx.save(onnx_model_simp, simplified_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9OUrzZa-bgt"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0s4ULT84ynC"
      },
      "source": [
        "### Quantisierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOwr_prgiN4"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "onnx_model = onnx.load(\"dtmf_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    onnx_model,\n",
        "    min_positive_val=1e-7,\n",
        "    max_finite_val=1e4,\n",
        "    keep_io_types=True,\n",
        "    disable_shape_infer=False,\n",
        "    op_block_list=None,\n",
        "    node_block_list=None,\n",
        ")\n",
        "onnx.save(onnx_model_fp16, \"dtmf_classifier_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGuwxgoDkgGv"
      },
      "source": [
        "### TensorRT Tests\n",
        "\n",
        "TODO: Move below code to .py files and import!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a3of1tuYcNrC"
      },
      "outputs": [],
      "source": [
        "def get_gpu_type() -> str:\n",
        "    \"\"\"Get the type of GPU available on the system.\n",
        "\n",
        "    This function checks if a CUDA-capable GPU is available using PyTorch.\n",
        "    If a GPU is available, it returns the name of the GPU in lowercase with spaces replaced by underscores.\n",
        "    If no GPU is available, it returns 'cpu'.\n",
        "\n",
        "    Returns:\n",
        "        str: The type of GPU available or 'cpu' if no GPU is available.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        return \"cpu\"\n",
        "    return \"_\".join(torch.cuda.get_device_name(0).lower().split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fSJVcrVW6gPw"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.2, 0.3),\n",
        "    dur_pause=(0.01, 0.1),\n",
        "    noise_factor=(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l5sW5xE4y3Yf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "from cuda import cuda, cudart\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def check_cuda_err(err: cuda.CUresult | cudart.cudaError_t) -> None:\n",
        "    \"\"\"Check for CUDA errors and raise an exception if an error is found.\n",
        "\n",
        "    Args:\n",
        "        err (Union[cuda.CUresult, cudart.cudaError_t]): The CUDA error code.\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: If a CUDA error is detected.\n",
        "    \"\"\"\n",
        "    if isinstance(err, cuda.CUresult) and err != cuda.CUresult.CUDA_SUCCESS:\n",
        "        raise RuntimeError(f\"Cuda Error: {err}\")\n",
        "    if isinstance(err, cudart.cudaError_t):\n",
        "        if err != cudart.cudaError_t.cudaSuccess:\n",
        "            raise RuntimeError(f\"Cuda Runtime Error: {err}\")\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown error type: {err}\")\n",
        "\n",
        "\n",
        "def cuda_call(call: Any) -> Any:\n",
        "    \"\"\"Make a CUDA call and check for errors.\n",
        "\n",
        "    Args:\n",
        "        call (Any): The CUDA call to make.\n",
        "\n",
        "    Returns:\n",
        "        Any: The result of the CUDA call.\n",
        "    \"\"\"\n",
        "    err, res = call[0], call[1:]\n",
        "    check_cuda_err(err)\n",
        "    if len(res) == 1:\n",
        "        res = res[0]\n",
        "    return res\n",
        "\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_host_to_device(device_ptr: int, host_arr: np.ndarray) -> None:\n",
        "    \"\"\"Copy data from host to device.\n",
        "\n",
        "    Args:\n",
        "        device_ptr (int): The device pointer.\n",
        "        host_arr (np.ndarray): The host array.\n",
        "    \"\"\"\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(\n",
        "        cudart.cudaMemcpy(\n",
        "            device_ptr, host_arr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_device_to_host(host_arr: np.ndarray, device_ptr: int) -> None:\n",
        "    \"\"\"Copy data from device to host.\n",
        "\n",
        "    Args:\n",
        "        host_arr (np.ndarray): The host array.\n",
        "        device_ptr (int): The device pointer.\n",
        "    \"\"\"\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(\n",
        "        cudart.cudaMemcpy(\n",
        "            host_arr, device_ptr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "class MNISTEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    \"\"\"INT8 calibrator for our DTMF classifier model.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, training_data: str, cache_file: str, batch_size: int = 16\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the MNISTEntropyCalibrator.\n",
        "\n",
        "        Args:\n",
        "            training_data (str): The path to the training data.\n",
        "            cache_file (str): The path to the cache file.\n",
        "            batch_size (int, optional): The batch size. Defaults to 16.\n",
        "        \"\"\"\n",
        "        # Whenever you specify a custom constructor for a TensorRT class,\n",
        "        # you MUST call the constructor of the parent explicitly.\n",
        "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
        "\n",
        "        self.cache_file = cache_file\n",
        "\n",
        "        # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n",
        "        # self.data = 2 * np.random.rand(32*batch_size, 2**12, 1).astype(np.float32) - 1.0\n",
        "        # self.data = training_data\n",
        "        self.data = dtmf_gen.generate_dataset(\n",
        "            n_samples=32 * batch_size, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        # print(self.data.dtype)\n",
        "        # self.data = self.data.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "        self.current_index = 0\n",
        "\n",
        "        # Allocate enough memory for a whole batch.\n",
        "        # self.device_input = cuda.mem_alloc(self.data[0].nbytes * self.batch_size)\n",
        "        n_bytes = self.data[0].nbytes * self.batch_size\n",
        "        # print(\"n_bytes\", n_bytes)\n",
        "        self.device_input = cuda_call(cudart.cudaMalloc(n_bytes))\n",
        "\n",
        "    def get_batch_size(self) -> int:\n",
        "        \"\"\"Get the batch size.\n",
        "\n",
        "        Returns:\n",
        "            int: The batch size.\n",
        "        \"\"\"\n",
        "        return self.batch_size\n",
        "\n",
        "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
        "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
        "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
        "    def get_batch(self, names: list[str]) -> list[int] | None:\n",
        "        \"\"\"Get a batch of data.\n",
        "\n",
        "        Args:\n",
        "            names (List[str]): The names of the engine bindings.\n",
        "\n",
        "        Returns:\n",
        "            Optional[List[int]]: The device input pointer, or None if there is no more data.\n",
        "        \"\"\"\n",
        "        # print(\"names:\", names)\n",
        "        if self.current_index + self.batch_size > self.data.shape[0]:\n",
        "            return None\n",
        "\n",
        "        current_batch = int(self.current_index / self.batch_size)\n",
        "        if current_batch % 10 == 0:\n",
        "            print(\n",
        "                f\"Calibrating batch {current_batch}, containing {self.batch_size} images\"\n",
        "            )\n",
        "\n",
        "        batch = self.data[\n",
        "            self.current_index : self.current_index + self.batch_size\n",
        "        ].ravel()\n",
        "        # cuda.memcpy_htod(self.device_input, batch)\n",
        "        # memcpy_host_to_device(self.device_input, batch)\n",
        "        memcpy_host_to_device(self.device_input, np.ascontiguousarray(batch))\n",
        "        self.current_index += self.batch_size\n",
        "        # print(\"Schalom!\")\n",
        "        return [int(self.device_input)]\n",
        "\n",
        "    def read_calibration_cache(self) -> bytes | None:\n",
        "        \"\"\"Read the calibration cache.\n",
        "\n",
        "        Returns:\n",
        "            Optional[bytes]: The calibration cache, or None if it does not exist.\n",
        "        \"\"\"\n",
        "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
        "        if Path.exists(self.cache_file):\n",
        "            return Path(self.cache_file).read_bytes()\n",
        "            # with open(self.cache_file, \"rb\") as f:\n",
        "            #    return f.read()\n",
        "        return None\n",
        "\n",
        "    def write_calibration_cache(self, cache: bytes) -> None:\n",
        "        \"\"\"Write the calibration cache.\n",
        "\n",
        "        Args:\n",
        "            cache (bytes): The calibration cache.\n",
        "        \"\"\"\n",
        "        return  # for now\n",
        "        Path(self.cache_file).write_bytes(cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6k2njAel4z6",
        "outputId": "2a2a67c1-d939-4891-e95c-d8943f5cb9f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e257e0ee0ada>:59: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
            "  config.int8_calibrator = calib\n",
            "<ipython-input-4-e257e0ee0ada>:68: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n",
            "  config.set_calibration_profile(calib_profile)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int 8 model\n",
            "Calibrating batch 0, containing 16 images\n",
            "Calibrating batch 10, containing 16 images\n",
            "Calibrating batch 20, containing 16 images\n",
            "Calibrating batch 30, containing 16 images\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import tensorrt as trt\n",
        "\n",
        "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
        "TRT_LOGGER: trt.Logger = trt.Logger(trt.Logger.VERBOSE)\n",
        "\n",
        "\n",
        "def build_engine_onnx(\n",
        "    model_file: str, trt_engine_path: str, precision: str\n",
        ") -> None:\n",
        "    \"\"\"Builds a TensorRT engine from an ONNX model file.\n",
        "\n",
        "    Args:\n",
        "        model_file (str): The path to the ONNX model file.\n",
        "        trt_engine_path (str): The path to save the TensorRT engine.\n",
        "        precision (str): The precision mode to use ('fp16', 'int8', 'mixed').\n",
        "\n",
        "    Returns:\n",
        "        Optional[None]: Returns None if the engine creation fails.\n",
        "    \"\"\"\n",
        "    seq_len: int = 2**12\n",
        "    max_batch_size: list[int] = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
        "    calibration_batch_size: int = 16\n",
        "    builder: trt.Builder = trt.Builder(TRT_LOGGER)\n",
        "    network: trt.INetworkDefinition = builder.create_network(0)\n",
        "    config: trt.IBuilderConfig = builder.create_builder_config()\n",
        "    parser: trt.OnnxParser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "    config.set_memory_pool_limit(\n",
        "        trt.MemoryPoolType.WORKSPACE, 8 * 1 << 30\n",
        "    )  # TODO: Constant\n",
        "\n",
        "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "    if not parser.parse(Path(model_file).read_bytes()):\n",
        "        print(\"ERROR: Failed to parse the ONNX file.\")\n",
        "        for error in range(parser.num_errors):\n",
        "            print(parser.get_error(error))\n",
        "        return\n",
        "\n",
        "    for b in max_batch_size:\n",
        "        profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
        "        profile.set_shape(\"input\", [b//2 + 1, seq_len, 1], [b, seq_len, 1], [b, seq_len, 1])\n",
        "        config.add_optimization_profile(profile)\n",
        "\n",
        "    if precision in [\"fp16\", \"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_fp16:\n",
        "            print(\"FP16 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.FP16)\n",
        "    if precision in [\"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_int8:\n",
        "            print(\"INT8 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.INT8)\n",
        "        # config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "\n",
        "        calib = MNISTEntropyCalibrator(\n",
        "            \"\", cache_file=\"cache.file\", batch_size=calibration_batch_size\n",
        "        )\n",
        "        config.int8_calibrator = calib\n",
        "\n",
        "        calib_profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
        "        calib_profile.set_shape(\n",
        "            \"input\",\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "        )\n",
        "        config.set_calibration_profile(calib_profile)\n",
        "        config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
        "\n",
        "        print(\"int 8 model\")\n",
        "\n",
        "    engine_bytes: bytes | None = builder.build_serialized_network(network, config)\n",
        "\n",
        "    if engine_bytes is None:\n",
        "        print(\"Failed to create the TensorRT engine\")\n",
        "        return\n",
        "    trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "    # Save the engine to a file\n",
        "    Path(trt_engine_path).write_bytes(engine_bytes)\n",
        "\n",
        "    print(f\"TensorRT engine saved to {trt_engine_path}\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "precision: str = \"int8\"\n",
        "onnx_path: str = \"dtmf_classifier.onnx\"\n",
        "trt_path: str = \"dtmf_classifier_\" + precision + \"_\" + get_gpu_type() + \".trt\"\n",
        "build_engine_onnx(onnx_path, trt_path, precision=precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VY4AP6jrmJKg",
        "outputId": "94976374-ad92-4e28-e7d3-3a087f5f8735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dtmf_classifier_int8_nvidia_l4.trt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ca7d28f74049>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0mtrt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dtmf_classifier_int8_nvidia_l4.trt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m \u001b[0mtrt_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorRTInfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0mtrt_infer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_profiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Use only for debugging/analysis purposes, since it slows down inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-ca7d28f74049>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, engine_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRuntime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize_cuda_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mread_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0mOpen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mclose\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \"\"\"\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dtmf_classifier_int8_nvidia_l4.trt'"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "\n",
        "DEBUG = False\n",
        "\n",
        "\n",
        "def print_dbg(*x: Any) -> None:\n",
        "    \"\"\"Print debug information if DEBUG is set to True.\n",
        "\n",
        "    Args:\n",
        "        *x (Any): The information to print.\n",
        "    \"\"\"\n",
        "    if DEBUG:\n",
        "        print(x)\n",
        "\n",
        "class CustomProfiler(trt.IProfiler):\n",
        "    \"\"\"Custom Profiler for logging layer-wise latency.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        trt.IProfiler.__init__(self)\n",
        "        self.layers = {}\n",
        "\n",
        "    def report_layer_time(self, layer_name, ms):\n",
        "        if layer_name not in self.layers:\n",
        "            self.layers[layer_name] = []\n",
        "\n",
        "        self.layers[layer_name].append(ms)\n",
        "\n",
        "class TensorRTInfer:\n",
        "    # TODO: This code still has a memory leak. The memory allocated by\n",
        "    # cudaMalloc has to be released!\n",
        "    \"\"\"Implements inference for the TensorRT engine.\"\"\"\n",
        "\n",
        "    def __init__(self, engine_path: str) -> None:\n",
        "        \"\"\"Initialize the TensorRTInfer class.\n",
        "\n",
        "        Args:\n",
        "            engine_path (str): The path to the serialized engine to load from disk.\n",
        "        \"\"\"\n",
        "        # Load TRT engine\n",
        "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
        "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
        "        # with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
        "        #    assert runtime\n",
        "        #    self.engine = runtime.deserialize_cuda_engine(f.read())\n",
        "        runtime = trt.Runtime(self.logger)\n",
        "        assert runtime\n",
        "        self.engine = runtime.deserialize_cuda_engine(Path(engine_path).read_bytes())\n",
        "\n",
        "        assert self.engine\n",
        "        self.context = self.engine.create_execution_context()\n",
        "        assert self.context\n",
        "\n",
        "        # Some Infos about the engine\n",
        "        print_dbg(\"num optimization profiles:\", self.engine.num_optimization_profiles)\n",
        "        print_dbg(\"num io tensors:\", self.engine.num_io_tensors)\n",
        "\n",
        "        # Create CUDA stream for asynchronous tasks\n",
        "        _, self.stream = cudart.cudaStreamCreate()\n",
        "\n",
        "        # Setup I/O bindings\n",
        "        self.inputs = []\n",
        "        self.outputs = []\n",
        "        self.allocations = []\n",
        "        for prof_idx in range(self.engine.num_optimization_profiles):\n",
        "            for i in range(self.engine.num_io_tensors):\n",
        "                name = self.engine.get_tensor_name(i)\n",
        "                is_input = False\n",
        "                if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
        "                    is_input = True\n",
        "                dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))\n",
        "                shape = self.engine.get_tensor_shape(name)\n",
        "                if is_input and shape[0] < 0:\n",
        "                    assert self.engine.num_optimization_profiles >= 1\n",
        "                    profile_shape = self.engine.get_tensor_profile_shape(name, prof_idx)\n",
        "                    print_dbg(\"profile_shape\", name, profile_shape)\n",
        "                    assert len(profile_shape) == 3  # min,opt,max\n",
        "\n",
        "                    # Set the *max* profile as binding shape\n",
        "                    self.switch_profile(prof_idx)\n",
        "                    self.context.set_input_shape(name, profile_shape[2])\n",
        "                    shape = self.context.get_tensor_shape(name)\n",
        "\n",
        "                if not is_input:\n",
        "                    shape = self.context.get_tensor_shape(name)\n",
        "                    print_dbg(\"shape for output:\", name, shape)\n",
        "\n",
        "                if is_input:\n",
        "                    self.batch_size = shape[0]\n",
        "                size = dtype.itemsize\n",
        "                for s in shape:\n",
        "                    size *= s\n",
        "                allocation = cuda_call(cudart.cudaMalloc(size))\n",
        "                host_allocation = None if is_input else np.zeros(shape, dtype)\n",
        "                binding = {\n",
        "                    \"index\": i,\n",
        "                    \"name\": name,\n",
        "                    \"dtype\": dtype,\n",
        "                    \"shape\": list(shape),\n",
        "                    \"allocation\": allocation,\n",
        "                    \"host_allocation\": host_allocation,\n",
        "                }\n",
        "                self.allocations.append(allocation)\n",
        "                if is_input:\n",
        "                    self.inputs.append(binding)\n",
        "                else:\n",
        "                    self.outputs.append(binding)\n",
        "                print_dbg(\n",
        "                    \"{} '{}' with shape {} and dtype {}\".format(\n",
        "                        \"Input\" if is_input else \"Output\",\n",
        "                        binding[\"name\"],\n",
        "                        binding[\"shape\"],\n",
        "                        binding[\"dtype\"],\n",
        "                    )\n",
        "                )\n",
        "            print_dbg()\n",
        "\n",
        "        assert self.batch_size > 0\n",
        "        assert len(self.inputs) > 0\n",
        "        assert len(self.outputs) > 0\n",
        "        assert len(self.allocations) > 0\n",
        "\n",
        "    def enable_profiling(self, profiler: trt.IProfiler = None) -> None:\n",
        "        \"\"\"Enable TensorRT profiling.#\n",
        "\n",
        "        TensorRT will report time spent on each layer in stdout for each forward run.\n",
        "        \"\"\"\n",
        "        if not self.context.profiler:\n",
        "            self.context.profiler = CustomProfiler() if profiler is None else profiler\n",
        "\n",
        "    def input_spec(self) -> tuple[list[int], np.dtype]:\n",
        "        \"\"\"Get the specs for the input tensor of the network. Useful to prepare memory allocations.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[List[int], np.dtype]: Two items, the shape of the input tensor and its (numpy) datatype.\n",
        "        \"\"\"\n",
        "        # TODO: Index 0 is wrong\n",
        "        return self.inputs[0][\"shape\"], self.inputs[0][\"dtype\"]\n",
        "\n",
        "    def output_spec(self) -> list[tuple[list[int], np.dtype]]:\n",
        "        \"\"\"Get the specs for the output tensors of the network. Useful to prepare memory allocations.\n",
        "\n",
        "        Returns:\n",
        "            List[Tuple[List[int], np.dtype]]: A list with two items per element, the shape and (numpy) datatype of each output tensor.\n",
        "        \"\"\"\n",
        "        specs = []\n",
        "        for o in self.outputs:\n",
        "            specs.append((o[\"shape\"], o[\"dtype\"]))\n",
        "        return specs\n",
        "\n",
        "    def switch_profile(self, idx: int) -> None:\n",
        "        \"\"\"Switch to a different optimization profile.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the optimization profile to switch to.\n",
        "        \"\"\"\n",
        "        self.context.set_optimization_profile_async(\n",
        "            idx, self.stream\n",
        "        )  # Switch to profile 1 (index 1)\n",
        "\n",
        "    def infer(self, batch: np.ndarray) -> list[np.ndarray]:\n",
        "        \"\"\"Execute inference on a batch of images.\n",
        "\n",
        "        Args:\n",
        "            batch (np.ndarray): A numpy array holding the image batch.\n",
        "\n",
        "        Returns:\n",
        "            List[np.ndarray]: A list of outputs as numpy arrays.\n",
        "        \"\"\"\n",
        "        # If the optimization profile does not match, change it here:\n",
        "        # In our setup the opt. profiles are selected in a way that the\n",
        "        # optimal batch sizes are powers of 2. In practice, one would not do\n",
        "        # it in this way:\n",
        "        # TODO: If the profile does not fit in the range, find the profile with\n",
        "        # the closest optimal settings...\n",
        "        expected_profile = int(np.log2(batch.shape[0]))\n",
        "        if self.context.active_optimization_profile != expected_profile:\n",
        "            print(\"Changing to profile\", expected_profile)\n",
        "            self.switch_profile(expected_profile)\n",
        "\n",
        "        if self.context.get_tensor_shape(\"input\") != batch.shape:\n",
        "            print(\"Changing batch size for inference!\")\n",
        "\n",
        "            # Adapt the input shape:\n",
        "            self.context.set_input_shape(\"input\", batch.shape)\n",
        "        print_dbg(\n",
        "            \"self.engine.get_tensor_shape(input)\", self.engine.get_tensor_shape(\"input\")\n",
        "        )\n",
        "        print_dbg(\n",
        "            \"self.context.get_tensor_shape(input)\",\n",
        "            self.context.get_tensor_shape(\"input\"),\n",
        "        )\n",
        "        print_dbg(\n",
        "            \"self.context.get_tensor_shape(output)\",\n",
        "            self.context.get_tensor_shape(\"output\"),\n",
        "        )\n",
        "        print_dbg()\n",
        "\n",
        "        o_idx = self.context.active_optimization_profile\n",
        "        print_dbg(\"Active output index (opt. profile)\", o_idx)\n",
        "\n",
        "        # Copy I/O and Execute\n",
        "        memcpy_host_to_device(self.inputs[o_idx][\"allocation\"], batch)\n",
        "\n",
        "        self.context.execute_v2(self.allocations)\n",
        "        memcpy_device_to_host(\n",
        "            self.outputs[o_idx][\"host_allocation\"], self.outputs[o_idx][\"allocation\"]\n",
        "        )\n",
        "\n",
        "        return [self.outputs[o_idx][\"host_allocation\"]]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Main function to run the TensorRT inference.\"\"\"\n",
        "trt_path = \"dtmf_classifier_int8_nvidia_l4.trt\"\n",
        "seq_len = 2**12\n",
        "trt_infer = TensorRTInfer(trt_path)\n",
        "trt_infer.enable_profiling() # Use only for debugging/analysis purposes, since it slows down inference\n",
        "\n",
        "print(\"Starting inference\")\n",
        "if False:\n",
        "    spec = trt_infer.input_spec()\n",
        "    print(\"spec\", spec)\n",
        "    # batch = my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        "    X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=seq_len)\n",
        "    o = trt_infer.infer(X.astype(np.float32))[0][: X.shape[0]]\n",
        "    print(\"o.shape\", o.shape)\n",
        "\n",
        "    thresholded = (o > 0.5).astype(int)\n",
        "    print((thresholded == Y).sum() / Y.size)\n",
        "    for iidx in range(X.shape[0]):\n",
        "        predicted_key_sequence = dtmf_gen.decode_prediction(o[iidx])\n",
        "        original_key_sequence = dtmf_gen.decode_prediction(Y[iidx])\n",
        "        if predicted_key_sequence != original_key_sequence:\n",
        "            print(\"predicted_key_sequence\", predicted_key_sequence)\n",
        "            print(\"original_key_sequence\", original_key_sequence)\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"No input provided, running in benchmark mode\")\n",
        "    trt_infer.switch_profile(0)\n",
        "    spec = trt_infer.input_spec()\n",
        "    # TODO:\n",
        "    spec = (1024, 4096, 1), np.float32\n",
        "\n",
        "    rng = np.random.default_rng()\n",
        "    batch = rng.random(spec[0]).astype(spec[1])\n",
        "    # batch = np.random.rand(*spec[0]).astype(spec[1])\n",
        "\n",
        "    print(\"batch.shape\", batch.shape)\n",
        "    print(\"batch.dtype\", batch.dtype)\n",
        "    print(\"min/max/mean\", batch.min(), batch.max(), batch.mean())\n",
        "    iterations = 100\n",
        "    times = []\n",
        "    for i in range(20):  # GPU warmup iterations\n",
        "        trt_infer.infer(batch)\n",
        "    for i in range(iterations):\n",
        "        start = time.time()\n",
        "        o = trt_infer.infer(batch)\n",
        "        # print(\"o.shape\", o[0].shape)\n",
        "        times.append(time.time() - start)\n",
        "        print(f\"Iteration {i + 1} / {iterations}\", end=\"\\r\")\n",
        "    print(\"Benchmark results include time for H2D and D2H memory copies\")\n",
        "    print(f\"Average Latency: {1000 * np.average(times):.3f} ms\")\n",
        "    print(f\"Average Throughput: {trt_infer.batch_size / np.average(times):.1f} ips\")\n",
        "\n",
        "print()\n",
        "print(\"Finished Processing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trt_path"
      ],
      "metadata": {
        "id": "NJxjPLRYoscs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_fp16 = pd.DataFrame([ (k, np.mean(v)) for k, v in trt_infer.context.profiler.layers.items()], columns=[\"Layer\", \"Time (ms)\"])"
      ],
      "metadata": {
        "id": "ZjSx_JaTn9Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_int8.set_index(\"Layer\").add_suffix(' int8'), df_fp16.set_index(\"Layer\").add_suffix(' fp16')], axis=1)"
      ],
      "metadata": {
        "id": "UPSFFqu8pFfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"diff\"] = df[\"Time (ms) fp16\"] - df[\"Time (ms) int8\"]"
      ],
      "metadata": {
        "id": "R461aK52qy2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)  # Display up to 50 columns\n",
        "df.sort_values(\"diff\", ascending=False)"
      ],
      "metadata": {
        "id": "eDZQHQaupi_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in trt_infer.context.profiler.layers.items():\n",
        "  print(k[-40:], np.sum(v))"
      ],
      "metadata": {
        "id": "JK_aoGgKZh69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trt_infer.profiler.report_layer_time(0)"
      ],
      "metadata": {
        "id": "tLg5ItFTYRCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laden der einzelnen Modelle f√ºr die Inferenz"
      ],
      "metadata": {
        "id": "ajTlV0ndF3j0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JYcDlVrLqWwx"
      },
      "outputs": [],
      "source": [
        "from techdays25.onnx_utils import (\n",
        "    OnnxModel,\n",
        "    benchmark_models_on_batch_size,\n",
        "    plot_benchmark_results,\n",
        ")\n",
        "\n",
        "# FP32 ONNX Model\n",
        "onnx_classifier = OnnxModel(\"dtmf_classifier.onnx\")\n",
        "\n",
        "# FP16 ONNX Model\n",
        "onnx_classifier_fp16 = OnnxModel(\"dtmf_classifier_fp16.onnx\")\n",
        "\n",
        "# FP32 TensorRT Model\n",
        "# tensorrt_classifier_fp32 = TensorRTInfer(\"dtmf_classifier_fp32_nvidia_l4.trt\")\n",
        "# tensorrt_classifier_fp16 = TensorRTInfer(\"dtmf_classifier_fp16_nvidia_l4.trt\")\n",
        "tensorrt_classifier_int8 = TensorRTInfer(f\"dtmf_classifier_int8_{get_gpu_type()}.trt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7H557RUJyEhf",
        "outputId": "0efdc829-b15b-44a8-8649-8cb51789c285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'my_dialed_sequence_signal' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-aa34dc4a117c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TODO: Time axis has to be dynamic!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m onnx_prediction = onnx_classifier.predict(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmy_dialed_sequence_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mpredicted_key_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtmf_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my_dialed_sequence_signal' is not defined"
          ]
        }
      ],
      "source": [
        "# TODO: Allow to select model here:\n",
        "# TODO: Time axis has to be dynamic!\n",
        "onnx_prediction = onnx_classifier.predict(\n",
        "    my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        ")\n",
        "predicted_key_sequence = dtmf_gen.decode_prediction(onnx_prediction)\n",
        "print(\"Predicted Sequence:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wZZNC80qUvnP"
      },
      "outputs": [],
      "source": [
        "# TODO: Validate ONNX models and Keras Model on Validation/Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns8srDuD5Ji1"
      },
      "source": [
        "### Peformanzmessung (Latenz) der individuellen Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0splX4gqHP",
        "outputId": "18240af4-4dd8-41e4-b8b8-3b1a648dd68a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX (FP32)\n",
            "  b=1....................................................................................................\n",
            "  b=2....................................................................................................\n",
            "  b=4....................................................................................................\n",
            "  b=8....................................................................................................\n",
            "  b=16....................................................................................................\n",
            "  b=32....................................................................................................\n",
            "  b=64....................................................................................................\n",
            "  b=128....................................................................................................\n",
            "  b=256....................................................................................................\n",
            "  b=512....................................................................................................\n",
            "  b=1024....................................................................................................\n",
            "ONNX (FP16)\n",
            "  b=1....................................................................................................\n",
            "  b=2....................................................................................................\n",
            "  b=4....................................................................................................\n",
            "  b=8....................................................................................................\n",
            "  b=16....................................................................................................\n",
            "  b=32....................................................................................................\n",
            "  b=64....................................................................................................\n",
            "  b=128....................................................................................................\n",
            "  b=256....................................................................................................\n",
            "  b=512....................................................................................................\n",
            "  b=1024....................................................................................................\n",
            "TRT (INT8)\n",
            "  b=1Changing to profile 0\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=2Changing to profile 1\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=4Changing to profile 2\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=8Changing to profile 3\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=16Changing to profile 4\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=32Changing to profile 5\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=64Changing to profile 6\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=128Changing to profile 7\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=256Changing to profile 8\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=512Changing to profile 9\n",
            "Changing batch size for inference!\n",
            "....................................................................................................\n",
            "  b=1024Changing to profile 10\n"
          ]
        }
      ],
      "source": [
        "n_runs = 100\n",
        "n_warmup = 20\n",
        "signal_length = 2**12\n",
        "batch_sizes = [2**i for i in range(11)]\n",
        "\n",
        "model_dict = {\n",
        "    # \"keras\": lambda x: model.predict(x, verbose=0),\n",
        "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    # \"TRT (FP32)\": tensorrt_classifier_fp32.infer,\n",
        "    # \"TRT (FP16)\": tensorrt_classifier_fp16.infer,\n",
        "    \"TRT (INT8)\": tensorrt_classifier_int8.infer,\n",
        "}\n",
        "\n",
        "dtmf_benchmark_results = benchmark_models_on_batch_size(\n",
        "    model_dict=model_dict,\n",
        "    input_shape=(signal_length, 1),\n",
        "    batch_sizes=batch_sizes,\n",
        "    n_runs=n_runs,\n",
        "    n_warmup=n_warmup,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uzxwUrIdqNFN",
        "outputId": "33025195-46dc-4fe6-bef1-2a3a74500ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_benchmark_results(results=dtmf_benchmark_results, title=\"Inferenzzeiten von DTMF-Klassifikationsmodellen\", xscale=\"log\", yscale=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtmf_benchmark_results['ONNX (FP16)'][1024].mean() - dtmf_benchmark_results['TRT (INT8)'][1024].mean()"
      ],
      "metadata": {
        "id": "jUxCMkL1K2OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb6KDq61AI_G"
      },
      "outputs": [],
      "source": [
        "# import onnx\n",
        "# Load the ONNX model\n",
        "# model_path = \"dtmf_classifier.onnx\"\n",
        "# model = onnx.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Genauigkeit der einzelnen Modelle"
      ],
      "metadata": {
        "id": "d7bQfXSiN86q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN2XVzIyy_Ww"
      },
      "source": [
        "## Reproduktion des Modells/Erneutes Training des Keras Modells (Optional)\n",
        "\n",
        "TODO: Hinweis, dass Sitzung neugesrartet werden sollte\n",
        "- Hilfreich mit fast perfekten Signalen zu starten (kein Rauschen)\n",
        "- Dann sukzessive das Rauschen hochdrehen, um das Modell robuster zu machen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AWzMtPVQkgb"
      },
      "outputs": [],
      "source": [
        "# from collections.abc import Callable\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shl0yW5zcdri"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.05, 0.1),\n",
        "    dur_pause=(0.01, 0.05),\n",
        "    noise_factor=(20.0,60.0),#(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO add use_bias=False to Conv1D layers\n",
        "\n",
        "# This model can be used as a basis to analyze it in the frequency domain.\n",
        "# It appears to show some interesting insights in the frequency domain.\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Concatenate, Activation\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (None, 1)  # Example: sequence length is variable, and there are 3 features per time step\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "# Learn a filter for the input:\n",
        "conv_layer_input = Conv1D(filters=1, kernel_size=32, padding='same', activation='linear', name=f'input_filter')(inputs)\n",
        "\n",
        "# Do some downsampling first\n",
        "avg_pooled = layers.AveragePooling1D(padding=\"same\", pool_size=2)(conv_layer_input)\n",
        "avg_pooled_1 = layers.AveragePooling1D(padding=\"same\", pool_size=2)(avg_pooled)\n",
        "\n",
        "# Define 8 different Conv1D layers\n",
        "conv_layers = []\n",
        "for i in range(4):\n",
        "    conv_layer = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_1_{i+1}')(avg_pooled_1)\n",
        "\n",
        "    max_pooled_layer =  layers.AveragePooling1D(padding=\"same\", pool_size=2)(conv_layer)\n",
        "    conv_layer_1 = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_2_{i+1}')(max_pooled_layer)\n",
        "\n",
        "    max_pooled_layer_2 = layers.MaxPooling1D(padding=\"same\")(conv_layer_1)\n",
        "    conv_layer_2 = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_3_{i+1}')(max_pooled_layer_2)\n",
        "    upsamp_layer = layers.UpSampling1D(size=16)(conv_layer_2)\n",
        "\n",
        "    conv_layers.append(upsamp_layer)\n",
        "\n",
        "# Concatenate the outputs of the 8 Conv1D layers\n",
        "concatenated = Concatenate(name=\"concat\")(conv_layers)\n",
        "\n",
        "# Final 1x1 Conv1D layer with softmax activation\n",
        "output = Conv1D(filters=dtmf_gen.get_num_keys() + 1, kernel_size=1, activation='softmax', name=\"final_conv\")(concatenated)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=output, name=\"MultiConv1DModel\")\n",
        "\n",
        "# Create an additional model to output the concatenated layer\n",
        "intermediate_model = Model(inputs=inputs, outputs=concatenated, name=\"IntermediateModel\")\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "tjb5kdPBgrrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (None, 1)\n",
        "num_classes = dtmf_gen.get_num_keys() + 1\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        # roughly, some temporal autoencoder structure\n",
        "        layers.Conv1D(32,kernel_size=32, activation=\"relu\",padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        #layers.UpSampling1D(size=2),\n",
        "        layers.Conv1DTranspose(32, kernel_size=32,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=32,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=32,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=32,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=32, activation=\"relu\", padding=\"same\"),\n",
        "\n",
        "        # roughly, some temporal autoencoder structure\n",
        "        layers.Conv1D(32,kernel_size=16, activation=\"relu\",padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling1D(padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=16,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=16,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=16,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv1DTranspose(32, kernel_size=16,strides=2, padding=\"same\"),\n",
        "        layers.Conv1D(32, kernel_size=16, activation=\"relu\", padding=\"same\"),\n",
        "\n",
        "        # Final layer\n",
        "        layers.Conv1D(num_classes, kernel_size=1, activation=\"softmax\"),\n",
        "    ])"
      ],
      "metadata": {
        "id": "y-kWNpC8LTlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_hSCvRHtgy"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=2*1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=2*64, t_length=2**16)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Sch√∂ner\n",
        "from matplotlib import pyplot as plt\n",
        "idx = 7\n",
        "plt.plot(X_train[idx,:,0])"
      ],
      "metadata": {
        "id": "BVDa0gpfMRmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Sch√∂ner\n",
        "from matplotlib import pyplot as plt\n",
        "idx = 2\n",
        "plt.plot(X_val[idx,:,0])"
      ],
      "metadata": {
        "id": "lxswHcK4M-AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Plot the model graph and save to a temporary file\n",
        "#plot_model(model, to_file='model_plot.png', show_shapes=False, show_layer_names=True, dpi=300)\n",
        "\n",
        "# Display the plot inline\n",
        "#display(Image('model_plot.png'))"
      ],
      "metadata": {
        "id": "1i9AFr9Hmy0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX1JtkVWTrI5"
      },
      "outputs": [],
      "source": [
        "#model = build_dtmf_classifier_model((None, 1), dtmf_gen.get_num_keys() + 1)\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")  # multi-label\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcganU0yPkdG"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=20, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"dtmf_classifier.keras\")"
      ],
      "metadata": {
        "id": "lKhU_0SSM5xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrpNO97eX3Y"
      },
      "outputs": [],
      "source": [
        "# load again to make sure...\n",
        "model = tf.keras.models.load_model(\"dtmf_classifier.keras\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoeSluZ-MoYQ"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "idx = 9\n",
        "\n",
        "# TODO: Duplicate Code below:\n",
        "pred = model.predict(X_val[idx : idx + 1])\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(X_val[idx, :, 0])\n",
        "\n",
        "for key_idx in range(pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
        "plt.show()\n",
        "\n",
        "wavfile.write(\n",
        "    \"val.wav\",\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (X_val[idx] * np.iinfo(np.int32).max).flatten().astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(\"val.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SozwcF8LNNIZ"
      },
      "outputs": [],
      "source": [
        "# Compute Accuracy\n",
        "pred = model.predict(X_val)\n",
        "thresholded = (pred > 0.5).astype(int)\n",
        "\n",
        "(thresholded == Y_val).sum() / Y_val.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgfqAPHRf7OJ"
      },
      "source": [
        "# TRTExec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dNOfG_zsJAx"
      },
      "outputs": [],
      "source": [
        "!uname -a\n",
        "!cat /etc/os-release\n",
        "!ls -l /usr/local\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKxcfRC-l55h"
      },
      "source": [
        "# Experiments with different Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbQfmvwtIUei"
      },
      "outputs": [],
      "source": [
        "# Import tensorrt_libs\n",
        "\n",
        "# Import ONNX dependencies\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y0ndHlTcqzX"
      },
      "source": [
        "# Further Experiments with Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlBaeR_oBUS7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.float_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frFXsleBYGPT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def float_to_binary_fp32(num: float) -> str:\n",
        "    \"\"\"Converts a built-in floating point number (64-bit) to its FP32 binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the floating point number.\n",
        "    \"\"\"\n",
        "    print(\"fp32:\", num)\n",
        "    return \"\".join(f\"{c:0>8b}\" for c in struct.pack(\"!f\", num))\n",
        "\n",
        "\n",
        "def float_to_binary_fp16(num: float) -> str:\n",
        "    \"\"\"Converts a builtin-in floating point number to a 16-bit floating point number and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the 16-bit floating point number.\n",
        "    \"\"\"\n",
        "    # Convert the number to a float16\n",
        "    float16_num = np.float16(num)\n",
        "\n",
        "    print(\"fp16:\", float16_num)\n",
        "\n",
        "    # Convert the float16 to bytes\n",
        "    float16_bytes = float16_num.tobytes()\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(float16_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_bf16(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to bfloat16  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the bfloat16 floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to bfloat16\n",
        "    bf = a.bfloat16()\n",
        "\n",
        "    print(\"bf16\", bf)\n",
        "\n",
        "    # Convert the bfloat16 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(bf_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e4m3(num: float) -> str:\n",
        "    \"\"\"Converts a  floating point number to float8 (e4m3) and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e4m3) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e4m3)\n",
        "    bf = a.to(torch.float8_e4m3fn)\n",
        "\n",
        "    print(\"fp8_e4m3\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e5m2(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to float8 (e5m2)  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e5m2) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e5m2)\n",
        "    bf = a.to(torch.float8_e5m2)\n",
        "\n",
        "    print(\"fp8_e5m2\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_int(num: float, bit_length: int = 8) -> str:\n",
        "    \"\"\"Converts a floating point number to its binary representation as an integer.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "        bit_length (int, optional): The bit length of the binary representation. Defaults to 8.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the integer part of the floating point number.\n",
        "    \"\"\"\n",
        "    return np.binary_repr(round(num), width=bit_length)\n",
        "\n",
        "\n",
        "num = -8.875074538462327 - 2**-7 - 2**-8\n",
        "float_to_binary_fp32(num)\n",
        "# float_to_binary_fp16(num)\n",
        "# float_to_binary_bf16(num)\n",
        "# float_to_binary_fp8_e4m3(num)\n",
        "# float_to_binary_fp8_e5m2(num)\n",
        "# float_to_binary_int(num, bit_length=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_f2kRTHj4Qd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubud1lCaBUS8"
      },
      "outputs": [],
      "source": [
        "-num - 2**3 - 2**-1 - 2**-2 - 2**-3 - 2**-7 - 2**-8\n",
        "\n",
        "\n",
        "(int(\"1111011100011101\", base=2) - 2**16) / 2**8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-X1F7z9BUS8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "s = \"1100100001111100\"\n",
        "b = int(s, base=2).to_bytes(2, \"little\")\n",
        "print(b)\n",
        "c = np.frombuffer(b, dtype=np.float16, count=1)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjV-2lyBUS9"
      },
      "outputs": [],
      "source": [
        "# Binary string\n",
        "binary_string = \"11000001000011111000101100101011\"\n",
        "\n",
        "# Convert the binary string to an integer\n",
        "binary_int = int(binary_string, 2)\n",
        "\n",
        "# Convert the integer to bytes (4 bytes for float32)\n",
        "binary_bytes = binary_int.to_bytes(4, byteorder=\"big\")\n",
        "\n",
        "# Unpack the bytes to a float\n",
        "float_value = struct.unpack(\">f\", binary_bytes)[0]\n",
        "\n",
        "print(float_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeF16bolNFX1"
      },
      "source": [
        "# Analyze Model in Frequency domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtRh4Dp-TUbs"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Callable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def multiple_formatter(\n",
        "    denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
        ") -> Callable[[float, int], str]:\n",
        "    \"\"\"Creates a formatter function for matplotlib that formats axis labels as multiples of a given number.\n",
        "\n",
        "    Args:\n",
        "        denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
        "        number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
        "        latex (str, optional): The LaTeX string to use for the base number.\n",
        "\n",
        "    Returns:\n",
        "        Callable[[float, int], str]: A function that formats a given value as a LaTeX fraction of the base number.\n",
        "    \"\"\"\n",
        "\n",
        "    def gcd(a: int, b: int) -> int:\n",
        "        \"\"\"Computes the greatest common divisor of two integers.\n",
        "\n",
        "        Args:\n",
        "            a (int): The first integer.\n",
        "            b (int): The second integer.\n",
        "\n",
        "        Returns:\n",
        "            int: The greatest common divisor of a and b.\n",
        "        \"\"\"\n",
        "        while b:\n",
        "            a, b = b, a % b\n",
        "        return a\n",
        "\n",
        "    def _multiple_formatter(x: float, pos: int) -> str:\n",
        "        \"\"\"Formats a given value as a LaTeX fraction of the base number.\n",
        "\n",
        "        Args:\n",
        "            x (float): The value to format.\n",
        "            pos (int): The position (not used in this implementation).\n",
        "\n",
        "        Returns:\n",
        "            str: The formatted string.\n",
        "        \"\"\"\n",
        "        den = denominator\n",
        "        num = np.int64(np.rint(den * x / number))\n",
        "        com = gcd(num, den)\n",
        "        (num, den) = (int(num / com), int(den / com))\n",
        "        if den == 1:\n",
        "            if num == 0:\n",
        "                return r\"$0$\"\n",
        "            if num == 1:\n",
        "                return rf\"${latex}$\"\n",
        "            if num == -1:\n",
        "                return rf\"$-{latex}$\"\n",
        "            return rf\"${num}{latex}$\"\n",
        "        if num == 1:\n",
        "            return rf\"$\\frac{{{latex}}}{{{den}}}$\"\n",
        "        if num == -1:\n",
        "            return rf\"$\\frac{{-{latex}}}{{{den}}}$\"\n",
        "        return rf\"$\\frac{{{num}{latex}}}{{{den}}}$\"\n",
        "\n",
        "    return _multiple_formatter\n",
        "\n",
        "\n",
        "class Multiple:\n",
        "    \"\"\"A class to create locators and formatters for matplotlib axes based on multiples of a given number.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
        "    ):\n",
        "        \"\"\"Initializes the Multiple class with the given parameters.\n",
        "\n",
        "        Args:\n",
        "            denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
        "            number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
        "            latex (str, optional): The LaTeX string to use for the base number.\n",
        "        \"\"\"\n",
        "        self.denominator = denominator\n",
        "        self.number = number\n",
        "        self.latex = latex\n",
        "\n",
        "    def locator(self) -> plt.MultipleLocator:\n",
        "        \"\"\"Creates a locator for matplotlib axes based on multiples of the base number.\n",
        "\n",
        "        Returns:\n",
        "            plt.MultipleLocator: A locator for matplotlib axes.\n",
        "        \"\"\"\n",
        "        return plt.MultipleLocator(self.number / self.denominator)\n",
        "\n",
        "    def formatter(self) -> plt.FuncFormatter:\n",
        "        \"\"\"Creates a formatter for matplotlib axes that formats labels as multiples of the base number.\n",
        "\n",
        "        Returns:\n",
        "            plt.FuncFormatter: A formatter for matplotlib axes.\n",
        "        \"\"\"\n",
        "        return plt.FuncFormatter(\n",
        "            multiple_formatter(self.denominator, self.number, self.latex)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3us2xVYGRQS6"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Copyright (c) 2011 Christopher Felton\n",
        "#\n",
        "# This program is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "#\n",
        "# This program is distributed in the hope that it will be useful,\n",
        "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "# GNU Lesser General Public License for more details.\n",
        "#\n",
        "# You should have received a copy of the GNU Lesser General Public License\n",
        "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
        "#\n",
        "\n",
        "# The following is derived from the slides presented by\n",
        "# Alexander Kain for CS506/606 \"Special Topics: Speech Signal Processing\"\n",
        "# CSLU / OHSU, Spring Term 2011.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import patches\n",
        "\n",
        "\n",
        "def zplane(b, a, filename=None):\n",
        "    \"\"\"Will probably be removed soon.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "        a (_type_): _description_\n",
        "        filename (_type_, optional): _description_. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "    # get a figure/plot\n",
        "    ax = plt.subplot(111)\n",
        "\n",
        "    # create the unit circle\n",
        "    uc = patches.Circle((0, 0), radius=1, fill=False, color=\"black\", ls=\"dashed\")\n",
        "    ax.add_patch(uc)\n",
        "\n",
        "    # The coefficients are less than 1, normalize the coeficients\n",
        "    if np.max(b) > 1:\n",
        "        kn = np.max(b)\n",
        "        b = b / float(kn)\n",
        "    else:\n",
        "        kn = 1\n",
        "\n",
        "    if np.max(a) > 1:\n",
        "        kd = np.max(a)\n",
        "        a = a / float(kd)\n",
        "    else:\n",
        "        kd = 1\n",
        "\n",
        "    # Get the poles and zeros\n",
        "    # p = np.roots(a)\n",
        "    # z = np.roots(b)\n",
        "    # k = kn/float(kd)\n",
        "    # Markus:\n",
        "    z, p, k = signal.tf2zpk(b, a)\n",
        "\n",
        "    # Plot the zeros and set marker properties\n",
        "    t1 = plt.plot(z.real, z.imag, \"go\", ms=10)\n",
        "    plt.setp(\n",
        "        t1,\n",
        "        markersize=10.0,\n",
        "        markeredgewidth=1.0,\n",
        "        markeredgecolor=\"k\",\n",
        "        markerfacecolor=\"g\",\n",
        "    )\n",
        "\n",
        "    # Plot the poles and set marker properties\n",
        "    t2 = plt.plot(p.real, p.imag, \"rx\", ms=10)\n",
        "    plt.setp(\n",
        "        t2,\n",
        "        markersize=12.0,\n",
        "        markeredgewidth=3.0,\n",
        "        markeredgecolor=\"r\",\n",
        "        markerfacecolor=\"r\",\n",
        "    )\n",
        "\n",
        "    ax.spines[\"left\"].set_position(\"center\")\n",
        "    ax.spines[\"bottom\"].set_position(\"center\")\n",
        "    ax.spines[\"right\"].set_visible(False)\n",
        "    ax.spines[\"top\"].set_visible(False)\n",
        "\n",
        "    # set the ticks\n",
        "    r = 1.5\n",
        "    plt.axis(\"scaled\")\n",
        "    plt.axis([-r, r, -r, r])\n",
        "    ticks = [-1, -0.5, 0.5, 1]\n",
        "    plt.xticks(ticks)\n",
        "    plt.yticks(ticks)\n",
        "\n",
        "    if filename is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(filename)\n",
        "\n",
        "    return z, p, k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXofb-I-NH8R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze0NbFHqNO-K"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"dtmf_classifier.keras\")\n",
        "\n",
        "# Recreate the intermediate model\n",
        "intermediate_output = loaded_model.get_layer('concat').output\n",
        "recreated_intermediate_model = Model(inputs=loaded_model.input, outputs=intermediate_output, name=\"RecreatedIntermediateModel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVexf_PdNVDg"
      },
      "outputs": [],
      "source": [
        "# Assuming 'model' is your Keras model and 'n' is the index of the layer you are interested in\n",
        "n = 14  # Example: Get the weights and name of the 3rd layer (indexing starts from 0)\n",
        "\n",
        "# Access the n-th layer\n",
        "nth_layer = model.layers[n]\n",
        "\n",
        "# Get the weights of the n-th layer\n",
        "weights = nth_layer.get_weights()\n",
        "\n",
        "# Get the name of the n-th layer\n",
        "layer_name = nth_layer.name\n",
        "\n",
        "# Print the name and weights of the n-th layer\n",
        "print(f\"Name der {n + 1}. Schicht (Index {n}): {layer_name}\")\n",
        "# print(f\"Gewichte der {n+1}. Schicht (Index {n}):\\n\", weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejseu_jkNlci"
      },
      "outputs": [],
      "source": [
        "weights[0].shape  # (kernel_size, input_channels, num_filters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = [8*2.0 * np.pi * f / dtmf_gen.get_sample_rate() for f in dtmf_gen.FREQS]\n",
        "frequencies"
      ],
      "metadata": {
        "id": "RCvM88wLWa3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay9hPpIUPf-M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "fig = plt.figure(figsize=(10, 2 * 6))\n",
        "\n",
        "for z in range(1):\n",
        "    dil_rate = 1\n",
        "    b = weights[0][:, 0, z]  # (kernel_size, channels, num_filters)\n",
        "    w, h = signal.freqz(b[::-1])\n",
        "    if dil_rate > 1:\n",
        "        m = b.shape\n",
        "        out = np.zeros((dil_rate) * m[0], dtype=b.dtype)\n",
        "        out[::dil_rate] = b\n",
        "        b = out[: -dil_rate + 1]\n",
        "        w, h = signal.freqz(b[::-1])\n",
        "\n",
        "    ax1 = fig.add_subplot(421 + z)\n",
        "\n",
        "    ax1.set_title(\"q=\" + str(dil_rate))\n",
        "\n",
        "    # plt.plot(w, 20 * np.log10(abs(h)), 'b')\n",
        "    plt.plot(w, abs(h), \"b\")\n",
        "    if z % 2 == 0:\n",
        "        plt.ylabel(\"Amplitude [dB]\", color=\"b\")\n",
        "    if z // 2 == 1:\n",
        "        plt.xlabel(r\"$\\hat\\omega$ [rad]\")  # Frequency [rad/sample]\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    angles = np.unwrap(np.angle(h))\n",
        "    # angles = angles % (2 * np.pi) - np.pi\n",
        "    plt.plot(w, angles, \"g\")\n",
        "    if z % 2 == 1:\n",
        "        plt.ylabel(\"Angle [rad]\", color=\"g\")\n",
        "    plt.grid()\n",
        "    # plt.axis('tight')\n",
        "\n",
        "    ax1.xaxis.grid(True)\n",
        "    ax1.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n",
        "    ax1.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 10))\n",
        "    ax1.xaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
        "\n",
        "    ax2.yaxis.grid(True)\n",
        "    ax2.yaxis.set_major_locator(plt.MultipleLocator(dil_rate * np.pi))\n",
        "    # ax2.yaxis.set_minor_locator(plt.MultipleLocator(2*np.pi))\n",
        "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
        "\n",
        "    # Plot vertical lines at specified frequencies\n",
        "    if frequencies:\n",
        "        for freq in frequencies:\n",
        "            ax1.axvline(x=freq, color='r', linestyle='--')\n",
        "\n",
        "plt.tight_layout(pad=0.5)\n",
        "# plt.savefig(\"pdf/example-frequency-response-ecg1.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zg3V72mRHeN"
      },
      "outputs": [],
      "source": [
        "zplane(b=b, a=np.array([1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FNI7hwmWHzP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def zplane(b, a=np.array([1])):\n",
        "    \"\"\"Plot the complex z-plane given a transfer function.\"\"\"\n",
        "    # Create a unit circle\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    ax = plt.subplot(1, 1, 1)\n",
        "    unit_circle = plt.Circle((0, 0), 1, color=\"gray\", fill=False, linestyle=\"dotted\")\n",
        "    ax.add_artist(unit_circle)\n",
        "\n",
        "    # Plot zeros and poles\n",
        "    zeros = np.roots(b)\n",
        "    poles = np.roots(a)\n",
        "    plt.scatter(\n",
        "        np.real(zeros),\n",
        "        np.imag(zeros),\n",
        "        s=50,\n",
        "        marker=\"o\",\n",
        "        facecolors=\"none\",\n",
        "        edgecolors=\"b\",\n",
        "        label=\"Zeros\",\n",
        "    )\n",
        "    plt.scatter(\n",
        "        np.real(poles), np.imag(poles), s=50, marker=\"x\", color=\"r\", label=\"Poles\"\n",
        "    )\n",
        "\n",
        "    # Set plot limits and labels\n",
        "    plt.xlim(-1.5, 1.5)\n",
        "    plt.ylim(-1.5, 1.5)\n",
        "    plt.axhline(0, color=\"black\", lw=1)\n",
        "    plt.axvline(0, color=\"black\", lw=1)\n",
        "    plt.xlabel(\"Real Part\")\n",
        "    plt.ylabel(\"Imaginary Part\")\n",
        "    plt.title(\"Z-Plane Diagram\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example: Design a low-pass FIR filter using the window method\n",
        "# numtaps = 21  # Number of filter coefficients (taps)\n",
        "# cutoff = 0.3  # Normalized cutoff frequency (0 to 1, where 1 corresponds to Nyquist frequency)\n",
        "# b = firwin(numtaps, cutoff)\n",
        "\n",
        "# Plot the z-plane diagram for the FIR filter\n",
        "zplane(b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import chirp\n",
        "\n",
        "# Define parameters\n",
        "dur = 2.0  # Duration of the chirp signal in seconds\n",
        "sample_rate = 44100  # Sampling rate in Hz\n",
        "f1 = 0  # Start frequency of the chirp in Hz\n",
        "f2 = 2000  # End frequency of the chirp in Hz\n",
        "\n",
        "f_interest = [697, 770, 852, 941, 1209, 1336, 1477, 1633]\n",
        "\n",
        "# Generate the time vector\n",
        "tt = np.arange(0.0, dur, 1 / sample_rate)\n",
        "\n",
        "# Generate the chirp signal\n",
        "chirp_signal = chirp(tt, f0=f1, f1=f2, t1=dur, method='linear')\n",
        "\n",
        "# Calculate the time points for the frequencies of interest\n",
        "t_interest = [(f - f1) / (f2 - f1) * dur for f in f_interest]\n",
        "\n",
        "# Plot the chirp signal\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.plot(tt, chirp_signal, label='Chirp Signal')\n",
        "\n",
        "# Add markers for the frequencies of interest\n",
        "for f, t in zip(f_interest, t_interest):\n",
        "    plt.axvline(x=t, color='r', linestyle='--', alpha=0.5)\n",
        "    plt.text(t, 0, f'{f} Hz', rotation=90, verticalalignment='bottom', color='r')\n",
        "\n",
        "plt.title(f'Chirp Signal from {f1} Hz to {f2} Hz')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XLsaVUMcP9Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = intermediate_model.predict(chirp_signal.reshape(1, -1, 1))\n",
        "result.shape"
      ],
      "metadata": {
        "id": "UbbzOWRPOjz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate example data (896x8)\n",
        "# In practice, you would load your actual data here\n",
        "data = result.squeeze()\n",
        "\n",
        "# Create a figure with 8 subplots arranged vertically\n",
        "fig, axes = plt.subplots(4, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "# Plot each time series in its respective subplot\n",
        "for i in range(4):\n",
        "    ax_data = data[:len(tt), i]\n",
        "    axes[i].plot(tt, ax_data, alpha=0.8)\n",
        "    #axes[i].set_title(f'Time Series {i+1}')\n",
        "    axes[i].grid(True)\n",
        "\n",
        "    # Add markers for the frequencies of interest\n",
        "    for f, t in zip(f_interest, t_interest):\n",
        "        axes[i].axvline(x=t, color='r', linestyle='--', alpha=0.5)\n",
        "        axes[i].text(t*1.01, min(ax_data), f'{f} Hz', rotation=90, verticalalignment='bottom', color='r')\n",
        "\n",
        "# Set common labels\n",
        "fig.text(0.5, 0.04, 'Time', ha='center')\n",
        "fig.text(0.04, 0.5, 'Amplitude', va='center', rotation='vertical')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout(rect=[0.03, 0.03, 1, 0.97])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7aHPwaGFN7Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtmf_gen.FREQS"
      ],
      "metadata": {
        "id": "hw0kueXVOc0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEgSKqSPParf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}