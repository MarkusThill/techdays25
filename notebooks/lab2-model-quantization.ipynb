{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusThill/techdays25/blob/feature-lab2-initial-draft/notebooks/lab2-model-quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWrVTJSVVy4"
      },
      "source": [
        "# üöÄ Lab 2: Effiziente Quantisierung tiefer neuronaler Netze\n",
        "- Dieses Jupyter Notebook **ben√∂tigt eine GPU Laufzeit**. Falls nicht bereits voreingestellt, kann daher der Laufzeittyp im Men√º unter \"Laufzeit\" > \"Laufzeittyp √§ndern\" > \"Hardwarebeschleuniger\" > **\"T4 GPU\"** ge√§ndert werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2hhcmOjXQXB"
      },
      "source": [
        "Strukturierung:\n",
        "- Teil 1: Darstellung numerischer Datentypen\n",
        "- Teil 2:\n",
        "  - Quantisierung des einfachen Modells aus Lab 1\n",
        "  - Diverse Betrachtungen auf dem quantisierten Modell (Genauigkeit, etc.)\n",
        "  - Gotchas (Optional): Overflow/Underflow am Beispiel eines Average Pooling layers\n",
        "  - Subnormal Numbers\n",
        "  - ...\n",
        "- Teil 3: Quantisierung eines DTMF Klassifikationsmodells\n",
        "  - Illustration: Erzeugung einer DTMF W√§hlsequenz und Abspielen derselben\n",
        "  - Laden eines vortrainierten DTMF-Klassifikationsmodells (ConvNet; Keras oder PyTorch)\n",
        "  - Konvertierung nach ONNX\n",
        "  - Quantisierung nach FP16\n",
        "  - Messung der Inferenzzeiten (auch f√ºr verschiedene Batch-Sizes) und vergleich von FP32, FP16-Modell\n",
        "  - Vergleich der Genauigkeit von FP16 und FP32 Modell (wie √§ndert sich die Fehlerrate)\n",
        "  - Optional: Konvertierung nach FP8 und Wiederholung der obigen Schritte\n",
        "  - Optional: Profiling der ONNX Modelle. Wo liegen die \"Hotspots\" des Modells?\n",
        "  - Optional: Trainieren des Modells auf de\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHjiyBN9VVy4"
      },
      "source": [
        "# Vorbereitungen: Installation der n√∂tigen Abh√§ngigkeiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zRp0QsBVVy5"
      },
      "outputs": [],
      "source": [
        "# Remove the `%%capture`, if you have the impression that something is going wrong during the setup\n",
        "# %%capture\n",
        "!pip install \"techdays25[lab2] @ git+https://github.com/MarkusThill/techdays25.git@feature-lab2-initial-draft\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PetUdSKZVVy5"
      },
      "source": [
        "**WICHTIG: Nach der Installation der Abh√§ngigkeiten (siehe oben) muss die Google Colab Laufzeit neugestartet werden! Im Anschluss kann mit der Ausf√ºhrung der n√§chsten Zellen fortgefahren werden werden.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf2wjy7rVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Colab-spezifische Konfigurationen {display-mode: \"form\"}\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "\n",
        "    output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPuTmcJKVVy5"
      },
      "source": [
        "# üìò Einleitung\n",
        "- DTMF\n",
        "- Quanstisierungsans√§tze\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-emxsEEVVy5"
      },
      "source": [
        "# üìñ Teil 1: Darstellung numerischer Datentypen\n",
        "- Zweierkomplementdarstellung\n",
        "- IEEE-754 Standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0MW1AnSVVy5"
      },
      "source": [
        "### Ganzahldarstellungen/Zweierkomplementdarstellung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfRcqICXVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 8-Bit Integer Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Initialize 8 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"40px\")\n",
        "    )\n",
        "    for _ in range(8)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Hex representation (2 hex digits for 8 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>{bit_string}</code><br>\n",
        "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
        "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
        "            Hexadecimal: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.HBox(bit_toggles))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDlSxZqOVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Grundlegendes Setzen von Bits: Setze das 3. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
        "Erwartete Antwort: 4\n",
        "\n",
        "- Setzen mehrerer Bits: Setze das 1., 3. und 5. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was ist die dezimale Darstellung dieser Zahl im unsigned Format?\n",
        "Erwartete Antwort: 21\n",
        "\n",
        "- Was ist die gr√∂√ütm√∂gliche bzw. kleinstm√∂gliche Zahl die mit 8 Bit dargestellt werden k√∂nnen? Antwort: -128, +127\n",
        "  - Was w√§re die Antwort, wenn wir statt 8-bit Integer, nun 32-bit Integer haben?\n",
        "\n",
        "- Signed vs. Unsigned Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -128, Unsigned: 128\n",
        "\n",
        "- Was charakterisiert eine negative Zahl in der Zweierkomplementdarstellung (unsigned integer) im Allgmeinen? Antwort: Zumindest das vorderste Bit ist gesetzt.\n",
        "\n",
        "- Wie negiere ich eine Zahl (z.B. 32 -> -32 bzw. -71 -> 71)? Antwort: Invertieren alle Bits und Addition  von 1\n",
        "\n",
        "- Angenommen ich habe -33 als 8-bit Zahl vorliegen. Wie w√ºrde ich daraus eine 32-bit unsigned Integer Zahl machen? Antwort: Einfach noch drei Bytes voranh√§ngen in denen alle Bits gesetzt sind.\n",
        "\n",
        "- Kombinieren von Bits: Setze das 2., 4. und 6. Bit (von rechts) einer 8-Bit-Zahl auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: 42, Unsigned: 42\n",
        "\n",
        "- Negative Zahlen in der Signed-Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) und das 1. Bit (niederwertigstes Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -127, Unsigned: 129\n",
        "\n",
        "- Maximale und minimale Werte: Was ist der maximale Wert, den man mit einer 8-Bit unsigned Zahl darstellen kann? Was ist der minimale Wert, den man mit einer 8-Bit signed Zahl darstellen kann?\n",
        "Erwartete Antwort: Maximale unsigned: 255, Minimale signed: -128\n",
        "\n",
        "- Bitmuster und Werte: Setze die Bits, um die Bin√§rzahl 10101010 zu bilden. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -86, Unsigned: 170\n",
        "\n",
        "- Alle Bits gesetzt: Setze alle Bits einer 8-Bit-Zahl auf 1. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "Erwartete Antwort: Signed: -1, Unsigned: 255\n",
        "\n",
        "\n",
        "- Verst√§ndnis von √úberlauf: Was passiert, wenn du 1 zum maximalen Wert einer 8-Bit unsigned Zahl hinzuf√ºgst? Was passiert bei einer 8-Bit signed Zahl?\n",
        "Erwartete Antwort: Bei unsigned wird es auf 0 zur√ºckgesetzt. Bei signed verursacht es einen √úberlauf und wird auf den minimalen Wert (-128) zur√ºckgesetzt.\n",
        "Zweierkomplement:\n",
        "\n",
        "- Erkl√§re, wie die Zweierkomplement-Darstellung f√ºr negative Zahlen in einer 8-Bit signed Zahl funktioniert.\n",
        "Erwartete Antwort: Im Zweierkomplement ist das h√∂chstwertige Bit (MSB) das Vorzeichenbit. Um das Zweierkomplement einer Zahl zu finden, invertiere alle Bits und addiere 1 zum niederwertigsten Bit (LSB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q1kp8MaVVy6"
      },
      "source": [
        "### Fixkommadarstellungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCrHNptuVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit Festkomma-Zahlen (engl.: fixpoint binary representations) {display-mode: \"form\"}\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Initialize 16 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, integer part, and fractional part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 7\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "# def twos_complement(bits):\n",
        "#    \"\"\"Convert list of bits to signed integer using two's complement.\"\"\"\n",
        "#    if bits[0] == 0:\n",
        "#        return int(\"\".join(str(b) for b in bits), 2)\n",
        "#\n",
        "#    # If MSB is 1, it's negative\n",
        "#    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "#    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "#    return -incremented\n",
        "\n",
        "\n",
        "def fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to a fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = twos_complement(integer_part)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Fixed-point value\n",
        "    fixed_point_decimal = fixed_point_value(bit_values)\n",
        "\n",
        "    # Hex representation (4 hex digits for 16 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:8]}</span>.\n",
        "                <span style=\"color: blue;\">{bit_string[8:]}</span>\n",
        "            </code><br>\n",
        "            Unsigned Decimal: <b>{unsigned_decimal}</b><br>\n",
        "            Signed Decimal (Two's Complement): <b>{signed_decimal}</b><br>\n",
        "            Fixed-Point Decimal: <b>{fixed_point_decimal}</b><br>\n",
        "            Hexadecimal: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN_oFcfjVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmRekLfxVVy6"
      },
      "source": [
        "### Flie√ükommadarstellungen nach IEEE-754\n",
        "- TODO: Subnormal Numbers\n",
        "- Webseite mit noch mehr Darstellungen: https://evanw.github.io/float-toy/\n",
        "- Verschiedene FP8-Darstellungen: https://asawicki.info/articles/fp8_tables.php\n",
        "- https://onnx.ai/onnx/technical/float8.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8LgC7KNVVy6"
      },
      "outputs": [],
      "source": [
        "## @title Darstellung von 16-Bit (FP16) Flie√ükomma-Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import struct\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, exponent, and mantissa\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 5\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show FP16 value and components\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def bits_to_float16(bits: list[int]) -> np.float16:\n",
        "    \"\"\"Convert list of bits to FP16 float value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        np.float16: The FP16 float value of the binary number.\n",
        "    \"\"\"\n",
        "    bit_string = \"\".join(str(b) for b in bits)\n",
        "    # Convert binary string to integer\n",
        "    int_value = int(bit_string, 2)\n",
        "    # Pack as unsigned 16-bit int, then unpack as float16 using numpy\n",
        "    packed = struct.pack(\"<H\", int_value)  # Big endian 16-bit unsigned int\n",
        "    return np.frombuffer(packed, dtype=np.float16)[0]\n",
        "\n",
        "\n",
        "def update_display(*args):\n",
        "    \"\"\"Update the display with the current binary, FP16 float value, and its components.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Extract components\n",
        "    sign = bit_values[0]\n",
        "    exponent_bits = bit_values[1:6]\n",
        "    mantissa_bits = bit_values[6:]\n",
        "\n",
        "    exponent = int(\"\".join(str(b) for b in exponent_bits), 2)\n",
        "    exponent_unbiased = exponent - 15  # Bias = 15\n",
        "\n",
        "    mantissa_raw = \"\".join(str(b) for b in mantissa_bits)\n",
        "    (\n",
        "        1 + sum(int(b) * 2 ** (-i) for i, b in enumerate(mantissa_bits, start=1))\n",
        "        if exponent != 0\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "    # Convert to float16 value\n",
        "    fp16_value = bits_to_float16(bit_values)\n",
        "\n",
        "    # Clear previous output and display new info\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Binary: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:6]}</span>\n",
        "                <span style=\"color: blue;\">{bit_string[6:]}</span>\n",
        "            </code><br>\n",
        "            Sign (1 bit): <b>{sign}</b> ({\"-\" if sign else \"+\"})<br>\n",
        "            Exponent (5 bits): <b>{\"\".join(str(b) for b in exponent_bits)} (biased: {exponent}, unbiased: {exponent_unbiased})</b><br>\n",
        "            Mantissa (10 bits): <b>{mantissa_raw}</b><br>\n",
        "            <hr>\n",
        "            <b>FP16 Value:</b> {fp16_value}\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize output\n",
        "update_display()  # 0 01111 0000000001 ^=^ 1.00097656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBCmHSNeVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Gibt es einen Unterschied zwischen +0.0 und -0.0?\n",
        "- Wie stelle ich `+Inf` bzw. `-Inf` dar?\n",
        "- Wie stelle ich `NaN` dar?\n",
        "- Was ergibt der Vergleich `float(\"nan\") != float(\"nan\")`?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqJpD_KdjXoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7youIav3VVy7"
      },
      "source": [
        "# üî¢Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
        "- Gotchas: zu gro√üe, kleine inputs, numerische Abweichungen. Ggfs.: Sehr kleines Gewicht, sehr gro√üer Input.\n",
        "- Abweichungen bestimmen"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbYQ_9fjMCUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eGYkUWNzMJGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fd481-eMB-R"
      },
      "source": [
        "# üï∏ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
        "\n",
        "In diesem Teil werden wir uns damit befassen, welche Probleme bei der Modellquantisierung auftreten k√∂nnen und dies anhand eines Beispiels illustrieren. Folgende Schritte werden durchgef√ºhrt:\n",
        "- Erstellen eines benutzerdefinierten Modells in Keras zur Mittelwertbildung √ºber entlang der Zeitachse.\n",
        "- Konvertieren des Keras-Modells in das ONNX-Format.\n",
        "- Quantisieren des ONNX-Modells von FP32 auf FP16.\n",
        "- Generierung von 3-dimensionalen Zeitreihendaten f√ºr die Modellinferenz.\n",
        "- Modellinferenz mit dem Keras-Modell.\n",
        "- Modellinferenz mit den FP32/FP16 ONNX-Modellen:\n",
        "  - Laden und Ausf√ºhren von ONNX-Modellen mit der ONNX Runtime.\n",
        "  - Vergleich der Ausgaben von FP32- und FP16-ONNX-Modellen.\n",
        "- Diskussion der Beobachtungen und m√∂glicher L√∂sungen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8ni09r-3eyW"
      },
      "outputs": [],
      "source": [
        "!pip install tf2onnx onnx onnxconverter-common onnxruntime-gpu # TODO: Add to Deps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelldefinition"
      ],
      "metadata": {
        "id": "pncih_L8dWVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unser Modell unten nimmt einen 3-dimensionalen Eingabetensor mit den Dimensionen (Batch-Gr√∂√üe, Sequenzl√§nge, Merkmalsanzahl) entgegen. In unserem Beispiel hat der Eingabetensor die Form (2, 10000, 3), was bedeutet, dass wir zwei Batch-Elemente haben, jedes mit einer Sequenzl√§nge von 10000 und 3 Merkmalen pro Zeitschritt.\n",
        "\n",
        "Nach der Verarbeitung durch das Modell wird die Zeitdimension reduziert, und die Ausgabe hat die Form (Batch-Gr√∂√üe, Merkmalsanzahl). F√ºr unser Beispiel ergibt sich eine Ausgabe mit der Form (2, 3). Die Ausgabe repr√§sentiert den Durchschnitt der Merkmale √ºber die gesamte Sequenzl√§nge f√ºr jedes Batch-Element.\n",
        "\n",
        "**Beispiel**\n",
        "\n",
        "Eingabetensor (2 x 4 x 3):\n",
        "```\n",
        "[\n",
        "    [3, 4, 5],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "  ],\n",
        "  [\n",
        "    [2, 4, 6],\n",
        "    [8, 10, 12],\n",
        "    [14, 16, 18],\n",
        "    [20, 22, 24]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "Ausgabetensor (2 x 3):\n",
        "```\n",
        "[\n",
        "  [ 6,  7,  8],\n",
        "  [11, 13, 15]\n",
        "]\n",
        "```\n"
      ],
      "metadata": {
        "id": "Ya6rTWHfamy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBhX8Vul3feC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Layer\n",
        "\n",
        "# Custom Layer: Sum over time dimension\n",
        "class SumLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        # Reduce (sum) the input tensor along the time axis (axis=1)\n",
        "        return tf.reduce_sum(inputs, axis=1)\n",
        "\n",
        "# Custom Layer: Division by sequence length\n",
        "class DivisionLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        tensor_x, original_input = inputs  # Extract both tensors: the summed tensor and the original input tensor\n",
        "        seq_length = tf.shape(original_input)[1]  # Get the dynamic sequence length (length of the time dimension)\n",
        "        # Divide the summed tensor by the sequence length to get the average\n",
        "        return tensor_x / tf.cast(seq_length, dtype=tensor_x.dtype)\n",
        "\n",
        "# Define model with separate Sum and Division layers\n",
        "def GlobalAveragePooling1D():\n",
        "    # Define the input layer with shape (sequence_length=None, feature_dim=3)\n",
        "    inputs = Input(shape=(None, 3), name=\"input\")\n",
        "    # Apply the SumLayer to the inputs\n",
        "    sum_x = SumLayer(name=\"sum\")(inputs)\n",
        "    # Apply the DivisionLayer to the summed tensor and the original inputs\n",
        "    output = DivisionLayer(name=\"divide\")([sum_x, inputs])\n",
        "    # Create the Keras model with the specified input and output\n",
        "    model = keras.Model(inputs, output, name=\"GlobalAveragePooling1D\")\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = GlobalAveragePooling1D()\n",
        "\n",
        "# Print model summary to see the architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modellkonvertierung nach ONNX"
      ],
      "metadata": {
        "id": "G8_5U6zHgR-_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-9pMzIv6oUY"
      },
      "outputs": [],
      "source": [
        "# Convert our GlobalAveragePooling1D Model to ONNX format\n",
        "import tf2onnx  # TensorFlow to ONNX conversion library\n",
        "import onnx  # ONNX library for handling ONNX models\n",
        "import tensorflow as tf  # TensorFlow library\n",
        "from onnxconverter_common import float16  # Utility for FP16 conversion\n",
        "\n",
        "# Define the path where the FP32 ONNX model will be saved\n",
        "onnx_model_path_fp32 = \"gap1d_model_fp32.onnx\"\n",
        "\n",
        "# Convert the Keras model to ONNX format with FP32 precision\n",
        "# Define the input specification for the model conversion\n",
        "spec = (tf.TensorSpec((None, None, 3), tf.float32, name=\"input\"),)\n",
        "# Convert the Keras model to ONNX using tf2onnx\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=18)\n",
        "\n",
        "# Save the converted FP32 ONNX model to the specified path\n",
        "onnx.save(onnx_model, onnx_model_path_fp32)\n",
        "print(f\"ONNX model (FP32) saved to {onnx_model_path_fp32}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantisierung des ONNX Modells"
      ],
      "metadata": {
        "id": "pdLdCuQBgaLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8A1tP9V679a"
      },
      "outputs": [],
      "source": [
        "# Now quantize the ONNX model to FP16 and save it\n",
        "\n",
        "# Load the previously saved FP32 ONNX model\n",
        "onnx_model_fp32 = onnx.load(onnx_model_path_fp32)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(onnx_model_fp32, keep_io_types=True)\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_path_fp16 = \"gap1d_model_fp16.onnx\"\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_path_fp16)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_path_fp16}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7m2fr58kMm"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"gap1d_model_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datengenerierung"
      ],
      "metadata": {
        "id": "6R_B8RE7ggas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PORbJXNx4yav"
      },
      "outputs": [],
      "source": [
        "# First create some data and put it through the Keras model\n",
        "import numpy as np  # Library for numerical operations\n",
        "import matplotlib.pyplot as plt  # Library for plotting\n",
        "\n",
        "# Create a random input tensor with a batch size of 2\n",
        "# Generate a sequence of numbers from 0 to 9999 and reshape it to (1, 10000, 1)\n",
        "tt = np.arange(10_000).reshape(1, -1, 1)\n",
        "\n",
        "# Create an offset array and reverse it\n",
        "off = (np.array(np.arange(6)).astype(np.float32) + 4)[::-1]\n",
        "\n",
        "# Generate a 3-dimensional time series data using a sine function with the offset\n",
        "xx = 0.4 * np.sin(4 * np.pi * 1e-5 * off**2 * tt) + off\n",
        "\n",
        "# Reshape the data to have dimensions (sequence_length, batch_size, feature_dim)\n",
        "xx = xx.reshape(-1, 2, 3)\n",
        "\n",
        "# Swap the axes to get the shape (batch_size, sequence_length, feature_dim)\n",
        "xx = np.swapaxes(xx, 0, 1)\n",
        "\n",
        "# Convert the data to float32 type\n",
        "x_input = xx.astype(np.float32)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensions of the input tensor:\", x_input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the generated time series data\n",
        "import matplotlib.pyplot as plt  # Library for plotting (re-imported for completeness)\n",
        "\n",
        "# Create a new figure with a specified size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the first batch (b$_1$) of the time series data\n",
        "plt.plot(xx[0, :, :], label=\"b$_1$\")\n",
        "\n",
        "# Plot the second batch (b$_2$) of the time series data\n",
        "plt.plot(xx[1, :, :], label=\"b$_2$\")\n",
        "\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"Index\")\n",
        "\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"Amplitude\")\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Ein Batch bestehend aus jeweils zwei 3-dimensionalen Zeitreihen\")\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(1.1, 0.6), ncol=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gGQTVao-GYZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferenz mit dem Keras Modell"
      ],
      "metadata": {
        "id": "HRHQY_j_gzEj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9EP5mXQ-Ln2"
      },
      "outputs": [],
      "source": [
        "# Put the data through the Keras model\n",
        "\n",
        "# Use the Keras model to make predictions on the input data\n",
        "y_output_keras = model.predict(x_input)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensionen des Eingabetensors:\", x_input.shape)  # Erwartete Form: (2, 10000, 3)\n",
        "\n",
        "# Print the dimensions of the Keras model output\n",
        "print(\"Dimensionen der Keras-Modellausgabe:\", y_output_keras.shape)  # Erwartete Form: (2, 3) -> Zeitdimension reduziert!\n",
        "\n",
        "# Print the output of the Keras model\n",
        "print(\"Keras-Modellausgabe:\\n\", y_output_keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferenz mit den FP32/FP16 ONNX Modellen"
      ],
      "metadata": {
        "id": "tq_N1o4Sg7p9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGonsmsm6oXu"
      },
      "outputs": [],
      "source": [
        "# Run the ONNX models\n",
        "import onnxruntime as ort  # Bibliothek zum Ausf√ºhren von ONNX-Modellen\n",
        "import numpy as np  # Bibliothek f√ºr numerische Operationen (nochmals importiert f√ºr Vollst√§ndigkeit)\n",
        "\n",
        "# Funktion zum Laden und Ausf√ºhren eines ONNX-Modells mit CUDA Execution Provider\n",
        "def run_onnx_model(onnx_model_path, x_input):\n",
        "    # Erstellen einer Inferenzsitzung f√ºr das ONNX-Modell mit dem CUDA Execution Provider\n",
        "    session = ort.InferenceSession(\n",
        "        onnx_model_path,\n",
        "        providers=[\"CUDAExecutionProvider\"]\n",
        "    )\n",
        "\n",
        "    # Abrufen des Namens, der Form und des Datentyps des Modelleingangs\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    input_shape = session.get_inputs()[0].shape\n",
        "    input_dtype = session.get_inputs()[0].type\n",
        "\n",
        "    # Ausgabe der Modelleingabedetails\n",
        "    print(f\"Name des Modellinputs: {input_name}\")\n",
        "    print(f\"Dimension des Modellinputs: {input_shape}\")\n",
        "    print(f\"Typ des Modellinputs: {input_dtype}\")\n",
        "\n",
        "    # Inferenz durchf√ºhren: Die gleichen Daten durch das ONNX-Modell laufen lassen\n",
        "    outputs = session.run(None, {input_name: x_input})\n",
        "\n",
        "    # Ausgabe der Ausgabedetails\n",
        "    print(f\"Dimension der Ausgabe: {outputs[0].shape}\")\n",
        "    print(f\"\\nAusgabe:\\n{outputs[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the FP32 ONNX model\n",
        "run_onnx_model(onnx_model_path = \"gap1d_model_fp32.onnx\", x_input=x_input)"
      ],
      "metadata": {
        "id": "h8LdB2clSPgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the FP16 ONNX model\n",
        "run_onnx_model(onnx_model_path = \"gap1d_model_fp16.onnx\", x_input=x_input)"
      ],
      "metadata": {
        "id": "a8wCn4znSZ_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fragen / Diskussion\n",
        "- Welche Ergebnisse erwarten wir? Stimmen die Ergebnisse mit den Erwartungen √ºberein?\n",
        "- Was f√§llt bei der Ausgabe des quantisierten FP16 Modells auf?\n",
        "  - Wie k√∂nnte man sich dieses Ergebnis erkl√§ren?\n",
        "  - L√§sst sich das Problem ggfs. vermeiden?\n"
      ],
      "metadata": {
        "id": "hsQD-7RzO2Ao"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5i-XeVZVVy7"
      },
      "source": [
        "# üìû Teil 4: Quantisierung eines DTMF Klassifikationsmodells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG6JRjlfVVy7"
      },
      "source": [
        "## Einf√ºhrung: Generierung und Dekodierung/Klassifizierung von DTMF (dual-tone multi-frequency) Signalen <a class=\"anchor\" id=\"part0\"></a>\n",
        "\n",
        "\n",
        "Das Dualton-Mehrfrequenzwahlverfahren (DTMF) ist ein Signalisierungssystem f√ºr das W√§hlen eines Telefons, das in den fr√ºhen 1960er Jahren von Western Electric entwickelt und sp√§ter von Bell System kommerziell an Telefonkunden geliefert wurde.\n",
        "Wenn eine Taste auf dem Telefon gedr√ºckt wird, werden zwei harmonische Tonsignale erzeugt, und die Superposition/√úberlagerung beider Signale wird verwendet, um die entsprechende Telefontaste zu charakterisieren. Wenn zum Beispiel die Taste ‚Äû5‚Äú gedr√ºckt wird, entsteht ein Dualtontonsignal, das sich aus den Frequenzen 770 Hz und 1336 Hz zusammensetzt. Die beiden Frequenzen, die jede Taste beschreiben, sind in der folgenden Tabelle aufgef√ºhrt:\n",
        "\n",
        "|   | 1209Hz  | 1336 Hz  | 1477 Hz   | 1633 Hz  |\n",
        "|---|:---:|:---:|:---:|:---:|\n",
        "| **697 Hz**  |  1 | 2  | 3  | A  |\n",
        "| **770 Hz**  |  4 | 5  | 6  | B  |\n",
        "| **852 Hz**  |  7 | 8  | 9  | C  |\n",
        "| **941 Hz**  |  * | 0  | #  | D  |\n",
        "\n",
        "In diesem Beispiel werden wir uns ansehen, wie man solche DTMF-W√§hlsequenzen generiert, sie in einer Audiodatei speichert und das Audiosignal mit einem einfachen KI-Modell wieder dekodiert.\n",
        "\n",
        "Wir werden die folgenden Schritte durchf√ºhren, um ein DTMF-Signal zu erzeugen und mit einem Klassifikationsmodell zu dekodieren:\n",
        "1. Erzeugung des Signals und der Audiodatei mit `scipy` und `numpy`. Wir speichern die erzeugte Audiodatei in einer `.wav` Datei, die in diesem Notebook oder in deinem lokalen Audioplayer abgespielt werden kann\n",
        "2. Wir entwerfen eine einfaches KI-Modell ... TODO\n",
        "3. Extraktion der gew√§hlten Tastenfolge aus der `.wav`-Datei unter Verwendung des KI-Modells\n",
        "4. Quantisierung & Export des Modells nach ONNX im FP32 und FP16 Format. Quantisierung nach INT8 und Export nach TensorRT.\n",
        "5. Laufzeituntersuchungen f√ºr FP32/FP16/INT8, unterschiedliche Batch-Gr√∂√üen und Signall√§ngen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXOs32MVVy7"
      },
      "outputs": [],
      "source": [
        "# Trainiere Modell\n",
        "# Konvertiere Modell nach ONNX (einmal FP32, einmal FP16)\n",
        "# Untersuche Laufzeitunterschiede (auch nach batchsize)\n",
        "# Untersuche Abweichungen. Wie √§ndert sich die Fehlerrate des Modells f√ºr FP32/Fp16?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51a6fcd-760a-4926-8d68-7f75eddb906a"
      },
      "source": [
        "## Signal- und Audiodatei-Generierung <a class=\"anchor\" id=\"part1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9360855-39ba-450f-975b-ebd7f48a5521"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# from collections.abc import Callable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kR8O3oWRKR"
      },
      "outputs": [],
      "source": [
        "## @title Tastenfeld-Widget f√ºr Generierung der W√§hlsequenz' {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize a text widget to display the dial sequence\n",
        "dial_sequence = widgets.Text(\n",
        "    value=\"\",\n",
        "    placeholder=\"Dial sequence will appear here...\",\n",
        "    description=\"\",\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width=\"300px\"),\n",
        ")\n",
        "\n",
        "\n",
        "# Function to handle button clicks\n",
        "def on_button_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    dial_sequence.value += b.description\n",
        "\n",
        "\n",
        "# Create buttons for the phone dialer\n",
        "buttons = []\n",
        "for row in [[\"1\", \"2\", \"3\", \"A\"], [\"4\", \"5\", \"6\", \"B\"], [\"7\", \"8\", \"9\", \"C\"], [\"*\", \"0\", \"#\", \"D\"]]:\n",
        "    button_row = []\n",
        "    for label in row:\n",
        "        button = widgets.Button(\n",
        "            description=label, layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        "        )\n",
        "        button.on_click(on_button_click)\n",
        "        button_row.append(button)\n",
        "    buttons.append(widgets.HBox(button_row))\n",
        "\n",
        "# Create a clear button\n",
        "clear_button = widgets.Button(\n",
        "    description=\"Clear\", layout=widgets.Layout(width=\"158px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "back_button = widgets.Button(\n",
        "    description=\"‚¨Ö\", layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "\n",
        "def on_clear_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = \"\"\n",
        "\n",
        "def on_back_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = dial_sequence.value[:-1]\n",
        "\n",
        "\n",
        "clear_button.on_click(on_clear_click)\n",
        "\n",
        "\n",
        "back_button.on_click(on_back_click)\n",
        "\n",
        "# Display the dialer\n",
        "display(dial_sequence)\n",
        "for button_row in buttons:\n",
        "    display(button_row)\n",
        "display(widgets.HBox([clear_button, back_button]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Gew√§hlte Sequenz:\", dial_sequence.value)"
      ],
      "metadata": {
        "id": "V728NfPmsAQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generierung des W√§hl-Audiosignals"
      ],
      "metadata": {
        "id": "D8i2MsZF3o0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAyM34wYqx_A"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.2, 0.3),\n",
        "    dur_pause=(0.01, 0.1),\n",
        "    noise_factor=(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62132ef1-c61f-4653-9f6c-a4d9f892781e"
      },
      "outputs": [],
      "source": [
        "# Either use the dialed sequence from above:\n",
        "my_dialed_sequence_keys = dial_sequence.value\n",
        "\n",
        "# ... or generate a random sequence:\n",
        "# my_dialed_sequence_keys = \"\".join([random.choice(\"1234567890ABCD*#\") for i in range(10)])\n",
        "\n",
        "# ... or use a simple sequence for debugging purposes\n",
        "# my_dialed_sequence_keys = \"1234567890ABCD*#\" # for debug purposes...\n",
        "\n",
        "# ... or use a slightly longer sequence (which also contains all symbols)\n",
        "# my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "if not my_dialed_sequence_keys:\n",
        "    my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "\n",
        "# Try changing the following arguments: dur_key=0.05, dur_pause=0.02\n",
        "my_dialed_sequence_signal = dtmf_gen.get_tone_sequence(my_dialed_sequence_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisierung des Signals"
      ],
      "metadata": {
        "id": "y-9x6ncx3wiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Das vollst√§ndige gew√§hlte Signal\")"
      ],
      "metadata": {
        "id": "aarMEIq3vS0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWiuyJ_7BUS6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal[: 10**4])\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Die ersten 10000 Datenpunkte des gew√§hlten Signals\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJe9QX8Ee9aA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "quant = np.quantile(my_dialed_sequence_signal, 0.99)\n",
        "start_index = np.where(my_dialed_sequence_signal > quant)[0][10]\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Weiterer Zoom-In\")\n",
        "plt.xlim(start_index, start_index+1.5*10**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42af11c2-3c15-4a57-afa8-f62b8e82925d"
      },
      "outputs": [],
      "source": [
        "# Now let us listen to the generated WAV file\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "wav_file_name = \"my_dtmf_file.wav\"\n",
        "\n",
        "wavfile.write(\n",
        "    wav_file_name,\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (my_dialed_sequence_signal * np.iinfo(np.int32).max).astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(wav_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51a52767-7e0e-444f-8028-f5a52fce4820"
      },
      "outputs": [],
      "source": [
        "print(\"Dialed sequence: \", my_dialed_sequence_keys)\n",
        "print(\"Used symbols: \", len(set(my_dialed_sequence_keys)))\n",
        "print(\"Total length of signal:\", my_dialed_sequence_signal.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b763fef4-360e-4a01-910b-add573007fd3"
      },
      "source": [
        "### Signal-Spektrogramm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7827a985-0dd0-40c0-993c-e002523ef0e9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "Pxx, freqs, bins, im = plt.specgram(\n",
        "    my_dialed_sequence_signal, NFFT=1024, Fs=dtmf_gen.get_sample_rate()\n",
        ")\n",
        "plt.ylim(0, 2000)\n",
        "plt.xlabel(\"t [s]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "plt.title(\"Spektrogramm des generierten Telefonw√§hlsignals\")\n",
        "plt.show(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimente"
      ],
      "metadata": {
        "id": "Aio7fvyo4ZUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laden des vortrainierten Keras Modells"
      ],
      "metadata": {
        "id": "YtHys5X74cRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "keras_model = tf.keras.models.load_model(\"dtmf_classifier.keras\")"
      ],
      "metadata": {
        "id": "g4Tks3yH0ipe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesc3J6SUBOv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "start = time.time()\n",
        "keras_pred = keras_model.predict(my_dialed_sequence_signal.reshape(1, -1, 1))\n",
        "end = time.time()\n",
        "\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "\n",
        "for key_idx in range(keras_pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        keras_pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
        "plt.title(f\"Tats√§chliche Wahlsequenz: {' '.join(list(my_dialed_sequence_keys))}\")\n",
        "plt.show()\n",
        "print(\"Inferenz-Dauer:\", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_zpgnG6CviY"
      },
      "outputs": [],
      "source": [
        "predicted_key_sequence = dtmf_gen.decode_prediction(keras_pred)\n",
        "print(\"Prognostizierte W√§hlsequenz:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Konvertierung des Keras Modells nach ONNX"
      ],
      "metadata": {
        "id": "-97qYaeo4k86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0niGbjMEhna"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "\n",
        "# Diese Zelle k√∂nnte einen Fehler werfen.\n",
        "# Dennoch sollte das ONNX Modell korrekt exportiert werden\n",
        "keras_model.output_names = [\"output\"]\n",
        "\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, 2**12, 1], tf.float32, name=\"input\")\n",
        "]  # TODO: time axis fixed or dynamic?\n",
        "# Use from_function for tf functions\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(keras_model, input_signature, opset=18)\n",
        "onnx.save(onnx_model, \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-simplifier # TODO: Add to deps"
      ],
      "metadata": {
        "id": "Skoq4dR7koyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimierung des ONNX Modells"
      ],
      "metadata": {
        "id": "y-CLAhtx4tTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxsim\n",
        "\n",
        "model_path = \"dtmf_classifier.onnx\"\n",
        "simplified_model_path = \"dtmf_classifier.onnx\"\n",
        "onnx_model = onnx.load(model_path)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_simp, check = onnxsim.simplify(onnx_model)\n",
        "assert check, \"Simplified ONNX model could not be validated\"\n",
        "onnx.save(onnx_model_simp, simplified_model_path)"
      ],
      "metadata": {
        "id": "D5PAAutNg2bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9OUrzZa-bgt"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantisierung des ONNX Modells"
      ],
      "metadata": {
        "id": "W0s4ULT84ynC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOwr_prgiN4"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "onnx_model = onnx.load(\"dtmf_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    onnx_model,\n",
        "    min_positive_val=1e-7,\n",
        "    max_finite_val=1e4,\n",
        "    keep_io_types=True,\n",
        "    disable_shape_infer=False,\n",
        "    op_block_list=None,\n",
        "    node_block_list=None,\n",
        ")\n",
        "onnx.save(onnx_model_fp16, \"dtmf_classifier_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYcDlVrLqWwx"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_models import DtmfClassifierOnnx\n",
        "\n",
        "# Import tensorrt_libs\n",
        "import tensorrt_libs\n",
        "\n",
        "# FP32 ONNX Model\n",
        "onnx_classifier = DtmfClassifierOnnx(\"dtmf_classifier.onnx\")\n",
        "\n",
        "# FP16 ONNX Model\n",
        "onnx_classifier_fp16 = DtmfClassifierOnnx(\"dtmf_classifier_fp16.onnx\")\n",
        "\n",
        "# FP16 TensorRT Model\n",
        "trt_provider = (\n",
        "        \"TensorrtExecutionProvider\",\n",
        "        {\n",
        "            \"device_id\": 0,  # The device ID\n",
        "            'trt_max_workspace_size': 4e9, # Maximum workspace size for TensorRT engine (1e9 ‚âà 1GB)\n",
        "            \"trt_fp16_enable\": True,\n",
        "            \"trt_int8_enable\": False,\n",
        "            \"trt_int8_use_native_calibration_table\": False,\n",
        "            \"trt_engine_cache_enable\": False,\n",
        "            \"trt_engine_cache_path\": \"./trt_catch_dir\",\n",
        "            #\"trt_profile_opt_shapes\": \"input:32x4096x1\",\n",
        "            #\"trt_profile_min_shapes\": \"input:1x4096x1\",\n",
        "            #\"trt_profile_max_shapes\": \"input:32x4096x1\",\n",
        "        },\n",
        "    )\n",
        "#tensorrt_classifier_fp16 = DtmfClassifierOnnx(\"dtmf_classifier.onnx\", provider=trt_provider)\n",
        "\n",
        "#tensorrt_classifier_fp32 = TensorRTInfer(\"dtmf_classifier_fp32_nvidia_l4.trt\")\n",
        "#tensorrt_classifier_fp16 = TensorRTInfer(\"dtmf_classifier_fp16_nvidia_l4.trt\")\n",
        "tensorrt_classifier_int8 = TensorRTInfer(\"dtmf_classifier_int8_nvidia_a100-sxm4-40gb.trt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H557RUJyEhf"
      },
      "outputs": [],
      "source": [
        "# TODO: Allow to select model here:\n",
        "onnx_prediction = onnx_classifier.predict(\n",
        "    my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        ")\n",
        "predicted_key_sequence = dtmf_gen.decode_prediction(onnx_prediction)\n",
        "print(\"Predicted Sequence:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZZNC80qUvnP"
      },
      "outputs": [],
      "source": [
        "# TODO: Validate ONNX models and Keras Model on Validation/Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Peformanzmessung (Latenz) der individuellen Modelle"
      ],
      "metadata": {
        "id": "Ns8srDuD5Ji1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_rvzFHFjpZy"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_models import measure_latency\n",
        "import pandas as pd\n",
        "\n",
        "n_runs = 100\n",
        "n_warmup = 20\n",
        "signal_length = 2**12\n",
        "batch_sizes = [2**i for i in range(11)]\n",
        "# model_dict = {\"keras\": lambda x: sum(np.median(x) for i in range(10)),\n",
        "#         \"onnx\": lambda x: sum(np.median(x) for i in range(5))}\n",
        "model_dict = {\n",
        "    #\"keras\": lambda x: model.predict(x, verbose=0),\n",
        "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    #\"TRT (FP32)\": tensorrt_classifier_fp32.infer,\n",
        "    #\"TRT (FP16)\": tensorrt_classifier_fp16.infer,\n",
        "    \"TRT (INT8)\": tensorrt_classifier_int8.infer,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, f_predict in model_dict.items():\n",
        "    print(model_name)\n",
        "    timings = {}\n",
        "    for batch_size in batch_sizes:\n",
        "        tensor_shape = (batch_size, signal_length, 1)\n",
        "        batch_timings = measure_latency(\n",
        "            f_predict, tensor_shape=tensor_shape, n_runs=n_runs, n_warmup=n_warmup\n",
        "        )\n",
        "        timings[batch_size] = batch_timings\n",
        "\n",
        "    df = pd.DataFrame(timings)\n",
        "    results[model_name] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzxwUrIdqNFN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "cmap = plt.get_cmap(\"tab10\")\n",
        "colors = [cmap(i) for i in range(len(results))]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "for (model_name, df), color in zip(results.items(), colors):\n",
        "    # Convert columns to integers for sorting\n",
        "    df.columns = df.columns.astype(int)\n",
        "    df = df[sorted(df.columns)]\n",
        "\n",
        "    # Compute medians and standard deviations\n",
        "    medians = df.median()\n",
        "    stds = df.std()\n",
        "\n",
        "    # X-axis values (sorted batch sizes)\n",
        "    x = medians.index\n",
        "\n",
        "    # Plot with connected points and error bars\n",
        "\n",
        "    plt.errorbar(\n",
        "        x,\n",
        "        medians,\n",
        "        yerr=stds,\n",
        "        fmt=\"-o\",\n",
        "        capsize=5,\n",
        "        color=color,\n",
        "        ecolor=color,\n",
        "        elinewidth=2,\n",
        "        markerfacecolor=\"white\",\n",
        "        label=model_name,\n",
        "    )\n",
        "\n",
        "# Make it pretty\n",
        "plt.xlabel(\"Batch-Gr√∂√üe\")\n",
        "plt.ylabel(\"Latenz [s]\")\n",
        "plt.title(\"TODO\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6, which=\"both\")\n",
        "# plt.xticks(x)\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.xscale(\"log\")\n",
        "#plt.yscale(\"log\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb6KDq61AI_G"
      },
      "outputs": [],
      "source": [
        "# import onnx\n",
        "# Load the ONNX model\n",
        "# model_path = \"dtmf_classifier.onnx\"\n",
        "# model = onnx.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzrpNGACjEDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl6erovhKUfL"
      },
      "outputs": [],
      "source": [
        "from onnxruntime.quantization.shape_inference import quant_pre_process\n",
        "quant_pre_process(\"dtmf_classifier.onnx\", \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dIsBgCdAk-U"
      },
      "outputs": [],
      "source": [
        "from onnxruntime.quantization import (\n",
        "    quantize_dynamic,\n",
        "    QuantType,\n",
        "    CalibrationDataReader,\n",
        "    quantize_static,\n",
        "    QuantFormat,\n",
        "    quantize_dynamic,\n",
        ")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    def __init__(self):\n",
        "        # self.data = calibration_data\n",
        "        # self.data_iter = iter(self.data)\n",
        "        self.counter = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.counter >= 10:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X, _ = dtmf_gen.generate_dataset(n_samples=64, t_length=2**12)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data = None\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "# Quantize the model\n",
        "quantized_model_path = \"dtmf_classifier_int8.onnx\"\n",
        "\n",
        "quantize_static(\n",
        "    # quantize_dynamic(\n",
        "    \"dtmf_classifier_pre.onnx\",\n",
        "    quantized_model_path,\n",
        "    calibration_data_reader,\n",
        "    # quant_format=QuantFormat.QOperator\n",
        "    # quant_format=QuantType.QInt8,\n",
        "    # per_channel=True,\n",
        "    # weight_type=QuantType.QInt8,\n",
        "    # optimize_model=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUvZQOpBDmME"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "\n",
        "# Load the quantized model\n",
        "quantized_model = ort.InferenceSession(quantized_model_path)\n",
        "\n",
        "# Run inference with the quantized model\n",
        "X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=2**10)\n",
        "input_name = quantized_model.get_inputs()[0].name\n",
        "output_name = quantized_model.get_outputs()[0].name\n",
        "\n",
        "result = quantized_model.run([output_name], {input_name: X.astype(np.float32)})[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk0jgMEAE8a6"
      },
      "outputs": [],
      "source": [
        "thresholded = (result > 0.5).astype(int)\n",
        "(thresholded == Y).sum() / Y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onROy1OoTfL_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOiAOUUfH7oQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2P3-yuoH7w8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorRT Tests"
      ],
      "metadata": {
        "id": "FGuwxgoDkgGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gpu_type():\n",
        "  import torch\n",
        "  if not torch.cuda.is_available():\n",
        "    return \"cpu\"\n",
        "  return \"_\".join(torch.cuda.get_device_name(0).lower().split(\" \"))"
      ],
      "metadata": {
        "id": "a3of1tuYcNrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.2, 0.3),\n",
        "    dur_pause=(0.01, 0.1),\n",
        "    noise_factor=(10.0, 50.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ],
      "metadata": {
        "id": "fSJVcrVW6gPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "from cuda import cudart\n",
        "from cuda import cuda, cudart\n",
        "\n",
        "def check_cuda_err(err):\n",
        "    if isinstance(err, cuda.CUresult):\n",
        "        if err != cuda.CUresult.CUDA_SUCCESS:\n",
        "            raise RuntimeError(\"Cuda Error: {}\".format(err))\n",
        "    if isinstance(err, cudart.cudaError_t):\n",
        "        if err != cudart.cudaError_t.cudaSuccess:\n",
        "            raise RuntimeError(\"Cuda Runtime Error: {}\".format(err))\n",
        "    else:\n",
        "        raise RuntimeError(\"Unknown error type: {}\".format(err))\n",
        "\n",
        "def cuda_call(call):\n",
        "    err, res = call[0], call[1:]\n",
        "    check_cuda_err(err)\n",
        "    if len(res) == 1:\n",
        "        res = res[0]\n",
        "    return res\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_host_to_device(device_ptr: int, host_arr: np.ndarray):\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(cudart.cudaMemcpy(device_ptr, host_arr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice))\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_device_to_host(host_arr: np.ndarray, device_ptr: int):\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(cudart.cudaMemcpy(host_arr, device_ptr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost))\n",
        "\n",
        "\n",
        "class MNISTEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    def __init__(self, training_data, cache_file, batch_size=16):\n",
        "        # Whenever you specify a custom constructor for a TensorRT class,\n",
        "        # you MUST call the constructor of the parent explicitly.\n",
        "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
        "\n",
        "        self.cache_file = cache_file\n",
        "\n",
        "        # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n",
        "        #self.data = 2 * np.random.rand(32*batch_size, 2**12, 1).astype(np.float32) - 1.0\n",
        "        # self.data = training_data\n",
        "        self.data = dtmf_gen.generate_dataset(n_samples=32*batch_size, t_length=2**12, with_labels=None).astype(np.float32)\n",
        "        #print(self.data.dtype)\n",
        "        #self.data = self.data.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "        self.current_index = 0\n",
        "\n",
        "        # Allocate enough memory for a whole batch.\n",
        "        #self.device_input = cuda.mem_alloc(self.data[0].nbytes * self.batch_size)\n",
        "        n_bytes = self.data[0].nbytes * self.batch_size\n",
        "        # print(\"n_bytes\", n_bytes)\n",
        "        self.device_input = cuda_call(cudart.cudaMalloc(n_bytes))\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
        "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
        "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
        "    def get_batch(self, names):\n",
        "        # print(\"names:\", names)\n",
        "        if self.current_index + self.batch_size > self.data.shape[0]:\n",
        "            return None\n",
        "\n",
        "        current_batch = int(self.current_index / self.batch_size)\n",
        "        if current_batch % 10 == 0:\n",
        "            print(\"Calibrating batch {:}, containing {:} images\".format(current_batch, self.batch_size))\n",
        "\n",
        "        batch = self.data[self.current_index:self.current_index + self.batch_size].ravel()\n",
        "        #cuda.memcpy_htod(self.device_input, batch)\n",
        "        #memcpy_host_to_device(self.device_input, batch)\n",
        "        memcpy_host_to_device(self.device_input, np.ascontiguousarray(batch)\n",
        "            )\n",
        "        self.current_index += self.batch_size\n",
        "        # print(\"Schalom!\")\n",
        "        return [int(self.device_input)]\n",
        "\n",
        "\n",
        "    def read_calibration_cache(self):\n",
        "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
        "        if os.path.exists(self.cache_file):\n",
        "            with open(self.cache_file, \"rb\") as f:\n",
        "                return f.read()\n",
        "\n",
        "    def write_calibration_cache(self, cache):\n",
        "        return None # for now\n",
        "        with open(self.cache_file, \"wb\") as f:\n",
        "            f.write(cache)"
      ],
      "metadata": {
        "id": "l5sW5xE4y3Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
        "\n",
        "\n",
        "# The Onnx path is used for Onnx models.\n",
        "def build_engine_onnx(model_file, trt_engine_path, precision):\n",
        "    seq_len = 2**12\n",
        "    max_batch_size = [1,2,4,8,16,32,64,128,256,512, 1024]\n",
        "    calibration_batch_size = 16\n",
        "    builder = trt.Builder(TRT_LOGGER)\n",
        "    network = builder.create_network(0)\n",
        "    config = builder.create_builder_config()\n",
        "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 8*1<<30) # TODO: Constant\n",
        "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "    with open(model_file, \"rb\") as model:\n",
        "        if not parser.parse(model.read()):\n",
        "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
        "            for error in range(parser.num_errors):\n",
        "                print(parser.get_error(error))\n",
        "            return None\n",
        "\n",
        "    for b in max_batch_size:\n",
        "      profile = builder.create_optimization_profile()\n",
        "      profile.set_shape(\"input\", [1,seq_len,1], [b,seq_len,1], [b,seq_len,1])\n",
        "      config.add_optimization_profile(profile)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if precision in [\"fp16\", \"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_fp16:\n",
        "            print(\"FP16 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.FP16)\n",
        "    if precision in [\"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_int8:\n",
        "            print(\"INT8 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.INT8)\n",
        "        # config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "\n",
        "        calib = MNISTEntropyCalibrator(\"\", cache_file=\"cache.file\", batch_size=calibration_batch_size)\n",
        "        config.int8_calibrator = calib\n",
        "\n",
        "        calib_profile = builder.create_optimization_profile()\n",
        "        calib_profile.set_shape(\"input\", [calibration_batch_size,seq_len,1], [calibration_batch_size,seq_len,1], [calibration_batch_size,seq_len,1])\n",
        "        config.set_calibration_profile(calib_profile)\n",
        "        config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
        "\n",
        "        print(\"int 8 model\")\n",
        "\n",
        "    engine_bytes = builder.build_serialized_network(network, config)\n",
        "\n",
        "    if engine_bytes is None:\n",
        "        print(\"Failed to create the TensorRT engine\")\n",
        "        return None\n",
        "    runtime = trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "    # Save the engine to a file\n",
        "    with open(trt_engine_path, \"wb\") as f:\n",
        "        f.write(engine_bytes)\n",
        "\n",
        "    print(f\"TensorRT engine saved to {trt_engine_path}\")\n",
        "\n",
        "    #return runtime.deserialize_cuda_engine(engine_bytes)\n",
        "\n",
        "# Example Usage\n",
        "precision = \"int8\"\n",
        "onnx_path = \"dtmf_classifier.onnx\"\n",
        "trt_path = \"dtmf_classifier_\"+ precision + \"_\" + get_gpu_type() + \".trt\"\n",
        "build_engine_onnx(onnx_path, trt_path, precision=precision)\n"
      ],
      "metadata": {
        "id": "J6k2njAel4z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "def print_dbg(*x):\n",
        "  if DEBUG:\n",
        "    print(x)\n",
        "\n",
        "class TensorRTInfer:\n",
        "  # TODO: This code still has a memory leak. The memory allocated by\n",
        "  # cudaMalloc has to be released!\n",
        "    \"\"\"\n",
        "    Implements inference for the TensorRT engine.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, engine_path):\n",
        "        \"\"\"\n",
        "        :param engine_path: The path to the serialized engine to load from disk.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load TRT engine\n",
        "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
        "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
        "        with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
        "            assert runtime\n",
        "            self.engine = runtime.deserialize_cuda_engine(f.read())\n",
        "        assert self.engine\n",
        "        self.context = self.engine.create_execution_context()\n",
        "        assert self.context\n",
        "\n",
        "        # Some Infos about the engine\n",
        "        print_dbg(\"num optimization profiles:\", self.engine.num_optimization_profiles)\n",
        "        print_dbg(\"num io tensors:\", self.engine.num_io_tensors)\n",
        "\n",
        "        # Create CUDA stream for asynchronous tasks\n",
        "        _, self.stream = cudart.cudaStreamCreate()\n",
        "\n",
        "        # Setup I/O bindings\n",
        "        self.inputs = []\n",
        "        self.outputs = []\n",
        "        self.allocations = []\n",
        "        for prof_idx in range(self.engine.num_optimization_profiles):\n",
        "          for i in range(self.engine.num_io_tensors):\n",
        "              name = self.engine.get_tensor_name(i)\n",
        "              is_input = False\n",
        "              if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
        "                  is_input = True\n",
        "              dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))\n",
        "              shape = self.engine.get_tensor_shape(name)\n",
        "              if is_input and shape[0] < 0:\n",
        "                  assert self.engine.num_optimization_profiles > 1\n",
        "                  profile_shape = self.engine.get_tensor_profile_shape(name, prof_idx)\n",
        "                  print_dbg(\"profile_shape\", name, profile_shape)\n",
        "                  assert len(profile_shape) == 3  # min,opt,max\n",
        "\n",
        "                  # Set the *max* profile as binding shape\n",
        "                  self.switch_profile(prof_idx)\n",
        "                  self.context.set_input_shape(name, profile_shape[2])\n",
        "                  shape = self.context.get_tensor_shape(name)\n",
        "\n",
        "              if not is_input:\n",
        "                shape = self.context.get_tensor_shape(name)\n",
        "                print_dbg(\"shape for output:\", name, shape)\n",
        "\n",
        "              if is_input:\n",
        "                  self.batch_size = shape[0]\n",
        "              size = dtype.itemsize\n",
        "              for s in shape:\n",
        "                  size *= s\n",
        "              allocation = cuda_call(cudart.cudaMalloc(size))\n",
        "              host_allocation = None if is_input else np.zeros(shape, dtype)\n",
        "              binding = {\n",
        "                  \"index\": i,\n",
        "                  \"name\": name,\n",
        "                  \"dtype\": dtype,\n",
        "                  \"shape\": list(shape),\n",
        "                  \"allocation\": allocation,\n",
        "                  \"host_allocation\": host_allocation,\n",
        "              }\n",
        "              self.allocations.append(allocation)\n",
        "              if is_input:\n",
        "                  self.inputs.append(binding)\n",
        "              else:\n",
        "                  self.outputs.append(binding)\n",
        "              print_dbg(\n",
        "                  \"{} '{}' with shape {} and dtype {}\".format(\n",
        "                      \"Input\" if is_input else \"Output\",\n",
        "                      binding[\"name\"],\n",
        "                      binding[\"shape\"],\n",
        "                      binding[\"dtype\"],\n",
        "                  )\n",
        "              )\n",
        "          print_dbg()\n",
        "\n",
        "        assert self.batch_size > 0\n",
        "        assert len(self.inputs) > 0\n",
        "        assert len(self.outputs) > 0\n",
        "        assert len(self.allocations) > 0\n",
        "\n",
        "\n",
        "\n",
        "    def input_spec(self):\n",
        "        \"\"\"\n",
        "        Get the specs for the input tensor of the network. Useful to prepare memory allocations.\n",
        "        :return: Two items, the shape of the input tensor and its (numpy) datatype.\n",
        "        \"\"\"\n",
        "        # TODO: Index 0 is wrong\n",
        "        return self.inputs[0][\"shape\"], self.inputs[0][\"dtype\"]\n",
        "\n",
        "    def output_spec(self):\n",
        "        \"\"\"\n",
        "        Get the specs for the output tensors of the network. Useful to prepare memory allocations.\n",
        "        :return: A list with two items per element, the shape and (numpy) datatype of each output tensor.\n",
        "        \"\"\"\n",
        "        specs = []\n",
        "        for o in self.outputs:\n",
        "            specs.append((o[\"shape\"], o[\"dtype\"]))\n",
        "        return specs\n",
        "\n",
        "    def switch_profile(self, idx: int):\n",
        "      self.context.set_optimization_profile_async(idx, self.stream)  # Switch to profile 1 (index 1)\n",
        "\n",
        "    def infer(self, batch):\n",
        "        \"\"\"\n",
        "        Execute inference on a batch of images.\n",
        "        :param batch: A numpy array holding the image batch.\n",
        "        :return A list of outputs as numpy arrays.\n",
        "        \"\"\"\n",
        "\n",
        "        # If the optimization profile does not match, change it here:\n",
        "          # In out setup the opt. profiles are selected in a wa that the\n",
        "          # optimal batch sizes are powers of 2. In practice, one would not do\n",
        "          # it in this way:\n",
        "        expected_profile = int(np.log2(batch.shape[0]))\n",
        "        if self.context.active_optimization_profile != expected_profile:\n",
        "          print(\"Chaninging to profile\", expected_profile)\n",
        "          self.switch_profile(expected_profile)\n",
        "\n",
        "        if self.context.get_tensor_shape(\"input\") != batch.shape:\n",
        "          print(\"Changing batch size for inference!\")\n",
        "\n",
        "          # Adapt the input shape:\n",
        "          self.context.set_input_shape(\"input\", batch.shape)\n",
        "        print_dbg(\"self.engine.get_tensor_shape(input)\", self.engine.get_tensor_shape(\"input\"))\n",
        "        print_dbg(\"self.context.get_tensor_shape(input)\", self.context.get_tensor_shape(\"input\"))\n",
        "        print_dbg(\"self.context.get_tensor_shape(output)\", self.context.get_tensor_shape(\"output\"))\n",
        "        print_dbg()\n",
        "\n",
        "        o_idx = self.context.active_optimization_profile\n",
        "        print_dbg(\"Active output index (opt. profile)\", o_idx)\n",
        "\n",
        "        # Copy I/O and Execute\n",
        "        memcpy_host_to_device(self.inputs[o_idx][\"allocation\"], batch)\n",
        "\n",
        "        self.context.execute_v2(self.allocations)\n",
        "        memcpy_device_to_host(\n",
        "                self.outputs[o_idx][\"host_allocation\"], self.outputs[o_idx][\"allocation\"]\n",
        "            )\n",
        "\n",
        "        return [self.outputs[o_idx][\"host_allocation\"]]\n",
        "\n",
        "def main():\n",
        "    seq_len = 2**12\n",
        "    trt_infer = TensorRTInfer(trt_path)\n",
        "\n",
        "    print(\"Starting inference\")\n",
        "    if False:\n",
        "      spec = trt_infer.input_spec()\n",
        "      print(\"spec\", spec)\n",
        "      # batch = my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        "      X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=seq_len)\n",
        "      o = trt_infer.infer(X.astype(np.float32))[0][:X.shape[0]]\n",
        "      print(\"o.shape\", o.shape)\n",
        "\n",
        "      thresholded = (o > 0.5).astype(int)\n",
        "      print( (thresholded == Y).sum() / Y.size )\n",
        "      for iidx in range(X.shape[0]):\n",
        "        predicted_key_sequence = dtmf_gen.decode_prediction(o[iidx])\n",
        "        original_key_sequence = dtmf_gen.decode_prediction(Y[iidx])\n",
        "        if predicted_key_sequence != original_key_sequence:\n",
        "          print(\"predicted_key_sequence\", predicted_key_sequence)\n",
        "          print(\"original_key_sequence\", original_key_sequence)\n",
        "      print(\"Done!\")\n",
        "    else:\n",
        "        print(\"No input provided, running in benchmark mode\")\n",
        "        trt_infer.switch_profile(1)\n",
        "        spec = trt_infer.input_spec()\n",
        "        # TODO:\n",
        "        spec = (1,4096,1), np.float32\n",
        "\n",
        "        batch = np.random.rand(*spec[0]).astype(spec[1])\n",
        "        print(\"batch.shape\", batch.shape)\n",
        "        print(\"batch.dtype\", batch.dtype)\n",
        "        print(\"min/max/mean\", batch.min(), batch.max(), batch.mean())\n",
        "        iterations = 100\n",
        "        times = []\n",
        "        for i in range(20):  # GPU warmup iterations\n",
        "            trt_infer.infer(batch)\n",
        "        for i in range(iterations):\n",
        "            start = time.time()\n",
        "            o = trt_infer.infer(batch)\n",
        "            #print(\"o.shape\", o[0].shape)\n",
        "            times.append(time.time() - start)\n",
        "            print(\"Iteration {} / {}\".format(i + 1, iterations), end=\"\\r\")\n",
        "        print(\"Benchmark results include time for H2D and D2H memory copies\")\n",
        "        print(\"Average Latency: {:.3f} ms\".format(1000 * np.average(times)))\n",
        "        print(\n",
        "            \"Average Throughput: {:.1f} ips\".format(\n",
        "                trt_infer.batch_size / np.average(times)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    print()\n",
        "    print(\"Finished Processing\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VY4AP6jrmJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Erneutes Training des Keras Modells (Optional)"
      ],
      "metadata": {
        "id": "bN2XVzIyy_Ww"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_hSCvRHtgy"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AWzMtPVQkgb"
      },
      "outputs": [],
      "source": [
        "# from collections.abc import Callable\n",
        "from collections.abc import Callable\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX1JtkVWTrI5"
      },
      "outputs": [],
      "source": [
        "# from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "model = build_dtmf_classifier_model((None, 1), dtmf_gen.get_num_keys() + 1)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")  # multi-label\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcganU0yPkdG"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=50, validation_data=(X_val, Y_val))\n",
        "model.save(\"dtmf_classifier.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrpNO97eX3Y"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"dtmf_classifier.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoeSluZ-MoYQ"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "idx = 9\n",
        "\n",
        "# TODO: Duplicate Code below:\n",
        "pred = model.predict(X_val[idx : idx + 1])\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(X_val[idx, :, 0])\n",
        "\n",
        "for key_idx in range(pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8)\n",
        "plt.show()\n",
        "\n",
        "wavfile.write(\n",
        "    \"val.wav\",\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (X_val[idx] * np.iinfo(np.int32).max).flatten().astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(\"val.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SozwcF8LNNIZ"
      },
      "outputs": [],
      "source": [
        "# Compute Accuracy\n",
        "pred = model.predict(X_val)\n",
        "thresholded = (pred > 0.5).astype(int)\n",
        "\n",
        "(thresholded == Y_val).sum() / Y_val.size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRTExec"
      ],
      "metadata": {
        "id": "jgfqAPHRf7OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a\n",
        "!cat /etc/os-release\n",
        "!ls -l /usr/local\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8dNOfG_zsJAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/NVIDIA/TensorRT.git"
      ],
      "metadata": {
        "id": "oNF6VAAXf9c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export LD_LIBRARY_PATH=/usr/local/lib/python3.11/dist-packages/tensorrt_libs/"
      ],
      "metadata": {
        "id": "5bmGz0fzgCD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt\n",
        "tensorrt.__version__"
      ],
      "metadata": {
        "id": "6-LkjeFSqfDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export LD_LIBRARY_PATH=/usr/local/lib/python3.11/dist-packages/tensorrt_libs/ && \\\n",
        "./trtexec --onnx=dtmf_classifier.onnx"
      ],
      "metadata": {
        "id": "j61a8sHE6UQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhtGJcVZ8ag7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ayEwe5ir9LAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments with different Data Types"
      ],
      "metadata": {
        "id": "PKxcfRC-l55h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyFnYjTSIBz-"
      },
      "outputs": [],
      "source": [
        "# Load cuDNN libraries\n",
        "import ctypes\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "from nvidia import cudnn\n",
        "\n",
        "\n",
        "def try_load(library):\n",
        "    try:\n",
        "        ctypes.CDLL(\n",
        "            library, mode=ctypes.RTLD_GLOBAL\n",
        "        )  # Use RTLD_GLOBAL to make symbols available\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "\n",
        "def try_load_libs_from_dir(path):\n",
        "    # Load all .so files (Linux)\n",
        "    for lib in glob.iglob(os.path.join(path, \"*.so*\")):\n",
        "        print(\"try:\", lib)\n",
        "        try_load(lib)\n",
        "\n",
        "\n",
        "# Get the cudnn library path\n",
        "CUDNN_LIB_DIR = os.path.join(cudnn.__path__[0], \"lib\")\n",
        "print(CUDNN_LIB_DIR)\n",
        "\n",
        "# Try loading all libraries in the cudnn lib directory\n",
        "# try_load_libs_from_dir(CUDNN_LIB_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbQfmvwtIUei"
      },
      "outputs": [],
      "source": [
        "# Import tensorrt_libs\n",
        "import tensorrt_libs\n",
        "\n",
        "# Import ONNX dependencies\n",
        "import onnxruntime as ort  # Import the ONNX Runtime\n",
        "from onnxruntime.tools.symbolic_shape_infer import SymbolicShapeInference\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    CalibrationMethod,\n",
        "    create_calibrator,\n",
        "    write_calibration_table,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av7uiBncTrdZ"
      },
      "outputs": [],
      "source": [
        "ort.get_available_providers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXvqz8RSJH_P"
      },
      "outputs": [],
      "source": [
        "providers = [\n",
        "    (\n",
        "        \"TensorrtExecutionProvider\",\n",
        "        {\n",
        "            \"device_id\": 0,  # The device ID\n",
        "            'trt_max_workspace_size': 4e9, # Maximum workspace size for TensorRT engine (1e9 ‚âà 1GB)\n",
        "            \"trt_fp16_enable\": False,\n",
        "            \"trt_int8_enable\": True,\n",
        "            \"trt_int8_use_native_calibration_table\": False,\n",
        "            \"trt_engine_cache_enable\": False,\n",
        "            \"trt_engine_cache_path\": \"./trt_catch_dir\",\n",
        "            #\"trt_profile_opt_shapes\": \"input:1x4096\",\n",
        "            #\"trt_profile_min_shapes\": \"input:1x4096\",\n",
        "            #\"trt_profile_max_shapes\": \"input:2x4096\",\n",
        "        },\n",
        "    )\n",
        "]\n",
        "\n",
        "sess_opt = ort.SessionOptions()\n",
        "sess_opt.log_severity_level = 0  # 0 is the most verbose level\n",
        "sess_opt.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "# sess_opt.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
        "\n",
        "# Load the model and create an InferenceSession\n",
        "session = ort.InferenceSession(\n",
        "    \"dtmf_classifier.onnx\", sess_options=sess_opt, providers=providers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIIulQNILIaO"
      },
      "outputs": [],
      "source": [
        "# Run inference with the quantized model\n",
        "X, Y = dtmf_gen.generate_dataset(n_samples=64, t_length=2**12)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "result = session.run([output_name], {input_name: X[0:1].astype(np.float32)})[0]\n",
        "# result = session.run([output_name], {input_name: np.ones( (5,1) ).astype(np.float32)})[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twzCNuMFrgvd"
      },
      "outputs": [],
      "source": [
        "# <TODO>: Add custom ONNX layer which does the pre-scaling of the input signal...\n",
        "# and post-processing: rle of the signal, discard keys which are short than 23 ms\n",
        "# Save inference times of each algo in a csv file (in case of a crash)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDOsXA3oy3Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7Cuomwoy3UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Experiments with Data Types"
      ],
      "metadata": {
        "id": "4y0ndHlTcqzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlBaeR_oBUS7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.float_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frFXsleBYGPT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def float_to_binary_fp32(num: float) -> str:\n",
        "    \"\"\"Converts a built-in floating point number (64-bit) to its FP32 binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the floating point number.\n",
        "    \"\"\"\n",
        "    print(\"fp32:\", num)\n",
        "    return \"\".join(f\"{c:0>8b}\" for c in struct.pack(\"!f\", num))\n",
        "\n",
        "\n",
        "def float_to_binary_fp16(num: float) -> str:\n",
        "    \"\"\"Converts a builtin-in floating point number to a 16-bit floating point number and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the 16-bit floating point number.\n",
        "    \"\"\"\n",
        "    # Convert the number to a float16\n",
        "    float16_num = np.float16(num)\n",
        "\n",
        "    print(\"fp16:\", float16_num)\n",
        "\n",
        "    # Convert the float16 to bytes\n",
        "    float16_bytes = float16_num.tobytes()\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(float16_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_bf16(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to bfloat16  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the bfloat16 floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to bfloat16\n",
        "    bf = a.bfloat16()\n",
        "\n",
        "    print(\"bf16\", bf)\n",
        "\n",
        "    # Convert the bfloat16 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(bf_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e4m3(num: float) -> str:\n",
        "    \"\"\"Converts a  floating point number to float8 (e4m3) and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e4m3) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e4m3)\n",
        "    bf = a.to(torch.float8_e4m3fn)\n",
        "\n",
        "    print(\"fp8_e4m3\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e5m2(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to float8 (e5m2)  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e5m2) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e5m2)\n",
        "    bf = a.to(torch.float8_e5m2)\n",
        "\n",
        "    print(\"fp8_e5m2\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_int(num: float, bit_length: int = 8) -> str:\n",
        "    \"\"\"Converts a floating point number to its binary representation as an integer.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "        bit_length (int, optional): The bit length of the binary representation. Defaults to 8.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the integer part of the floating point number.\n",
        "    \"\"\"\n",
        "    return np.binary_repr(round(num), width=bit_length)\n",
        "\n",
        "\n",
        "num = -8.875074538462327 - 2**-7 - 2**-8\n",
        "float_to_binary_fp32(num)\n",
        "# float_to_binary_fp16(num)\n",
        "# float_to_binary_bf16(num)\n",
        "# float_to_binary_fp8_e4m3(num)\n",
        "# float_to_binary_fp8_e5m2(num)\n",
        "# float_to_binary_int(num, bit_length=8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_f2kRTHj4Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubud1lCaBUS8"
      },
      "outputs": [],
      "source": [
        "-num - 2**3 - 2**-1 - 2**-2 - 2**-3 - 2**-7 - 2**-8\n",
        "\n",
        "\n",
        "(int(\"1111011100011101\", base=2) - 2**16) / 2**8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-X1F7z9BUS8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "s = \"1100100001111100\"\n",
        "b = int(s, base=2).to_bytes(2, \"little\")\n",
        "print(b)\n",
        "c = np.frombuffer(b, dtype=np.float16, count=1)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjV-2lyBUS9"
      },
      "outputs": [],
      "source": [
        "# Binary string\n",
        "binary_string = \"11000001000011111000101100101011\"\n",
        "\n",
        "# Convert the binary string to an integer\n",
        "binary_int = int(binary_string, 2)\n",
        "\n",
        "# Convert the integer to bytes (4 bytes for float32)\n",
        "binary_bytes = binary_int.to_bytes(4, byteorder=\"big\")\n",
        "\n",
        "# Unpack the bytes to a float\n",
        "float_value = struct.unpack(\">f\", binary_bytes)[0]\n",
        "\n",
        "print(float_value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}