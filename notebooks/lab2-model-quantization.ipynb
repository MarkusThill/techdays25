{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkusThill/techdays25/blob/feature-lab2-initial-draft/notebooks/lab2-model-quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKWrVTJSVVy4"
      },
      "source": [
        "# üöÄ Lab 2: Effiziente Quantisierung tiefer neuronaler Netze\n",
        "- Dieses Jupyter Notebook **ben√∂tigt eine GPU Laufzeit**. Falls nicht bereits voreingestellt, kann daher der Laufzeittyp im Men√º unter \"Laufzeit\" > \"Laufzeittyp √§ndern\" > \"Hardwarebeschleuniger\" > **\"T4 GPU\"** ge√§ndert werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHjiyBN9VVy4"
      },
      "source": [
        "# Vorbereitungen: Installation der n√∂tigen Abh√§ngigkeiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zRp0QsBVVy5"
      },
      "outputs": [],
      "source": [
        "# Remove the `%%capture`, if you have the impression that something is going wrong during the setup\n",
        "#%%capture\n",
        "!pip install \"techdays25[lab2] @ git+https://github.com/MarkusThill/techdays25.git@feature-lab2-initial-draft\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PetUdSKZVVy5"
      },
      "source": [
        "**IN ROT 'WICHTIG: Nach der Installation der Abh√§ngigkeiten (siehe oben) muss die Google Colab Laufzeit neugestartet werden! Im Anschluss kann mit der Ausf√ºhrung der n√§chsten Zellen fortgefahren werden werden.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/MarkusThill/techdays25.git\"\n",
        "!cd techdays25 && git checkout feature-lab2-initial-draft"
      ],
      "metadata": {
        "id": "TvMZAZUyiYx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf2wjy7rVVy5"
      },
      "outputs": [],
      "source": [
        "# @title Colab-spezifische Konfigurationen {display-mode: \"form\"}\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "\n",
        "    output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPuTmcJKVVy5"
      },
      "source": [
        "# üìò Einleitung und Gliederung\n",
        "\n",
        "Dieses Jupyter Notebook ist in 4 Teile gegliedert. Es empfiehlt sich, die einzelnen Teile von vorne beginnend, nacheinander durchzuarbeiten.\n",
        "\n",
        "- üìñ Teil 1: Darstellung numerischer Datentypen\n",
        "  - In diesem Teil wiederholen wir verschiedene Darstellungen von numerischen Datentypen und lernen in einem interaktivem Modul die Unterschiede zwischen diesen kennen.\n",
        "- üî¢ Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
        "- üï∏ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
        "- üìû Teil 4: Quantisierung eines DTMF Klassifikationsmodells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-emxsEEVVy5"
      },
      "source": [
        "# üìñ Teil 1: Darstellung numerischer Datentypen\n",
        "- Zweierkomplementdarstellung\n",
        "- IEEE-754 Standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0MW1AnSVVy5"
      },
      "source": [
        "### Ganzahldarstellungen/Zweierkomplementdarstellung"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Darstellung von 8-Bit Integer Zahlen {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Initialize 8 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"40px\")\n",
        "    )\n",
        "    for _ in range(8)\n",
        "]\n",
        "\n",
        "# Color bars for sign and integer part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 40px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 40px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    for i in range(8)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Hex representation (2 hex digits for 8 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Bin√§rdarstellung: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:]}</span>\n",
        "            </code><br>\n",
        "            Vorzeichenlose Dezimalzahl: <b>{unsigned_decimal}</b><br>\n",
        "            Vorzeichenbehaftete Dezimalzahl (Zweierkomplement): <b>{signed_decimal}</b><br>\n",
        "            Hexadezimaldarstellung: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars)]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()\n"
      ],
      "metadata": {
        "id": "Vooo4D08nI9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDlSxZqOVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "\n",
        "- Was ist die gr√∂√ütm√∂gliche bzw. kleinstm√∂gliche Zahl die mit 8 Bit dargestellt werden k√∂nnen?\n",
        "- Signed vs. Unsigned Darstellung: Setze das 8. Bit (h√∂chstwertiges Bit) auf 1 und alle anderen Bits auf 0. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?\n",
        "- Was charakterisiert eine negative Zahl in der Zweierkomplementdarstellung (unsigned integer) im Allgmeinen?\n",
        "- Wie negiere ich eine Zahl (z.B. 32 -> -32 bzw. -71 -> 71)?\n",
        "- Angenommen ich habe -33 als 8-bit Zahl vorliegen. Wie w√ºrde ich daraus eine 32-bit unsigned Integer Zahl machen?\n",
        "- Maximale und minimale Werte: Was ist der maximale/minimale Wert, den man mit einer 8-Bit signed/unsigned Zahl darstellen kann?\n",
        "- Alle Bits gesetzt: Setze alle Bits einer 8-Bit-Zahl auf 1. Was sind die dezimalen Darstellungen dieser Zahl im signed und unsigned Format?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q1kp8MaVVy6"
      },
      "source": [
        "### Fixkommadarstellungen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Darstellung von 16-Bit Integer/Festkomma-Zahlen {display-mode: \"form\"}\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits, MSB to LSB)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, integer part, and fractional part\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 7\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "def twos_complement(bits: list[int]) -> int:\n",
        "    \"\"\"Convert list of bits to signed integer using two's complement.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        int: The signed integer value of the binary number.\n",
        "    \"\"\"\n",
        "    if bits[0] == 0:\n",
        "        return int(\"\".join(str(b) for b in bits), 2)\n",
        "    # If MSB is 1, it's negative\n",
        "    inverted_bits = [1 - b for b in bits]  # Flip bits\n",
        "    incremented = int(\"\".join(str(b) for b in inverted_bits), 2) + 1\n",
        "    return -incremented\n",
        "\n",
        "def fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to a fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = twos_complement(integer_part)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "def unsigned_fixed_point_value(bits: list[int]) -> float:\n",
        "    \"\"\"Convert a list of bits to an unsigned fixed-point value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of 16 bits representing the binary number in fixed-point format.\n",
        "\n",
        "    Returns:\n",
        "        float: The unsigned fixed-point value of the binary number.\n",
        "    \"\"\"\n",
        "    integer_part = bits[:8]\n",
        "    fractional_part = bits[8:]\n",
        "\n",
        "    # Calculate integer value\n",
        "    integer_value = int(\"\".join(str(b) for b in integer_part), 2)\n",
        "\n",
        "    # Calculate fractional value\n",
        "    fractional_value = sum(\n",
        "        bit * 2 ** (-i) for i, bit in enumerate(fractional_part, start=1)\n",
        "    )\n",
        "\n",
        "    return integer_value + fractional_value\n",
        "\n",
        "def update_display(*args) -> None:\n",
        "    \"\"\"Update the display with the current binary, decimal, and hexadecimal values.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Unsigned decimal value\n",
        "    unsigned_decimal = int(bit_string, 2)\n",
        "\n",
        "    # Signed decimal value (two's complement)\n",
        "    signed_decimal = twos_complement(bit_values)\n",
        "\n",
        "    # Fixed-point value\n",
        "    fixed_point_decimal = fixed_point_value(bit_values)\n",
        "\n",
        "    # Unsigned fixed-point value\n",
        "    unsigned_fixed_point_decimal = unsigned_fixed_point_value(bit_values)\n",
        "\n",
        "    # Hex representation (4 hex digits for 16 bits)\n",
        "    hex_value = hex(unsigned_decimal).upper().replace(\"X\", \"x\").replace(\"0X\", \"0x\")\n",
        "\n",
        "    # Clear previous output and update\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Bin√§rdarstellung: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:8]}</span>.\n",
        "                <span style=\"color: blue;\">{bit_string[8:]}</span>\n",
        "            </code><br>\n",
        "            Vorzeichenlose Dezimalzahl: <b>{unsigned_decimal}</b><br>\n",
        "            Vorzeichenbehaftete Dezimalzahl (Zweierkomplement): <b>{signed_decimal}</b><br>\n",
        "            Vorzeichenlose Festkommazahl: <b>{unsigned_fixed_point_decimal}</b><br>\n",
        "            Vorzeichenbehaftete Festkommazahl (Zweierkomplement): <b>{fixed_point_decimal}</b><br>\n",
        "            Hexadezimaldarstellung: <b>{hex_value}</b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels (0/1)\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "def reset_bits(*args) -> None:\n",
        "    \"\"\"Reset all toggle buttons to their initial state (False).\"\"\"\n",
        "    for btn in bit_toggles:\n",
        "        btn.value = False\n",
        "\n",
        "# Create reset button\n",
        "reset_button = widgets.Button(description=\"Reset\", layout=widgets.Layout(width=\"100px\"))\n",
        "reset_button.on_click(reset_bits)\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars), reset_button]))\n",
        "display(output)\n",
        "\n",
        "# Initialize display\n",
        "update_display()\n"
      ],
      "metadata": {
        "id": "X37wJrQDpVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN_oFcfjVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Was ist die kleinstm√∂gliche vorzeichenbehaftete Festkommazahl?\n",
        "- Wie stelle ich -1.25 als Festkommazahl dar?\n",
        "- Was ist die kleinstm√∂gliche (gr√∂√ütm√∂gliche) Festkommazahl gr√∂√üer (kleiner) als Null?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8LgC7KNVVy6"
      },
      "outputs": [],
      "source": [
        "# @title Darstellung von 16-Bit (FP16) Flie√ükommazahlen nach IEEE 754 {display-mode: \"form\"}\n",
        "\n",
        "import struct\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Initialize 16 toggle buttons (bits)\n",
        "bit_toggles = [\n",
        "    widgets.ToggleButton(\n",
        "        value=False, description=\"0\", layout=widgets.Layout(width=\"30px\")\n",
        "    )\n",
        "    for _ in range(16)\n",
        "]\n",
        "\n",
        "# Color bars for sign, exponent, and mantissa\n",
        "color_bars = [\n",
        "    widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: red;\"></div>'\n",
        "    )\n",
        "    if i == 0\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: green;\"></div>'\n",
        "    )\n",
        "    if 1 <= i <= 5\n",
        "    else widgets.HTML(\n",
        "        value='<div style=\"width: 30px; height: 10px; background-color: blue;\"></div>'\n",
        "    )\n",
        "    for i in range(16)\n",
        "]\n",
        "\n",
        "# Output widget to show FP16 value and components\n",
        "output = widgets.Output()\n",
        "\n",
        "def bits_to_float16(bits: list[int]) -> np.float16:\n",
        "    \"\"\"Convert list of bits to FP16 float value.\n",
        "\n",
        "    Args:\n",
        "        bits (list[int]): A list of bits representing the binary number.\n",
        "\n",
        "    Returns:\n",
        "        np.float16: The FP16 float value of the binary number.\n",
        "    \"\"\"\n",
        "    bit_string = \"\".join(str(b) for b in bits)\n",
        "    # Convert binary string to integer\n",
        "    int_value = int(bit_string, 2)\n",
        "    # Pack as unsigned 16-bit int, then unpack as float16 using numpy\n",
        "    packed = struct.pack(\"<H\", int_value)  # Big endian 16-bit unsigned int\n",
        "    return np.frombuffer(packed, dtype=np.float16)[0]\n",
        "\n",
        "def update_display(*args):\n",
        "    \"\"\"Update the display with the current binary, FP16 float value, and its components.\"\"\"\n",
        "    # Read bit values (MSB to LSB)\n",
        "    bit_values = [int(btn.value) for btn in bit_toggles]\n",
        "    bit_string = \"\".join(str(b) for b in bit_values)\n",
        "\n",
        "    # Extract components\n",
        "    sign = bit_values[0]\n",
        "    exponent_bits = bit_values[1:6]\n",
        "    mantissa_bits = bit_values[6:]\n",
        "\n",
        "    exponent = int(\"\".join(str(b) for b in exponent_bits), 2)\n",
        "    exponent_unbiased = exponent - 15  # Bias = 15\n",
        "\n",
        "    mantissa_raw = \"\".join(str(b) for b in mantissa_bits)\n",
        "    mantissa_value = (\n",
        "        1 + sum(int(b) * 2 ** (-i) for i, b in enumerate(mantissa_bits, start=1))\n",
        "        if exponent != 0\n",
        "        else 0\n",
        "    )\n",
        "\n",
        "    # Convert to float16 value\n",
        "    fp16_value = bits_to_float16(bit_values)\n",
        "\n",
        "    # Clear previous output and display new info\n",
        "    output.clear_output()\n",
        "    with output:\n",
        "        display(\n",
        "            HTML(f\"\"\"\n",
        "        <h3>\n",
        "            Bin√§rdarstellung: <code>\n",
        "                <span style=\"color: red;\">{bit_string[0]}</span>\n",
        "                <span style=\"color: green;\">{bit_string[1:6]}</span>\n",
        "                <span style=\"color: blue;\">{bit_string[6:]}</span>\n",
        "            </code><br>\n",
        "            Vorzeichen (1 bit): <b>{sign}</b> ({\"-\" if sign else \"+\"})<br>\n",
        "            Exponent (5 bits): <b>{\"\".join(str(b) for b in exponent_bits)} (biased: {exponent}, unbiased: {exponent_unbiased})</b><br>\n",
        "            Mantisse (10 bits): <b>{mantissa_raw}</b><br>\n",
        "            <hr>\n",
        "            <b>FP16 Dezimaldarstellung: {fp16_value} </b>\n",
        "        </h3>\n",
        "        \"\"\")\n",
        "        )\n",
        "\n",
        "    # Update button labels\n",
        "    for btn, value in zip(bit_toggles, bit_values):\n",
        "        btn.description = str(value)\n",
        "\n",
        "def reset_bits(*args) -> None:\n",
        "    \"\"\"Reset all toggle buttons to their initial state (False).\"\"\"\n",
        "    for btn in bit_toggles:\n",
        "        btn.value = False\n",
        "\n",
        "# Create reset button\n",
        "reset_button = widgets.Button(description=\"Reset\", layout=widgets.Layout(width=\"100px\"))\n",
        "reset_button.on_click(reset_bits)\n",
        "\n",
        "# Attach observer to all buttons\n",
        "for btn in bit_toggles:\n",
        "    btn.observe(update_display, \"value\")\n",
        "\n",
        "# Display widget\n",
        "display(widgets.VBox([widgets.HBox(bit_toggles), widgets.HBox(color_bars), reset_button]))\n",
        "display(output)\n",
        "\n",
        "# Initialize output\n",
        "update_display()  # 0 01111 0000000001 ^=^ 1.00097656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBCmHSNeVVy6"
      },
      "source": [
        "#### √úbungsfragen (Optional):\n",
        "- Wie w√ºrde ich 1.0, 0.5 und 7.0 darstellen?\n",
        "- Was ist die gr√∂√üte/kleinste darstellbare Zahl?\n",
        "- Gibt es einen Unterschied zwischen +0.0 und -0.0?\n",
        "- Wie stelle ich `+Inf` bzw. `-Inf` dar?\n",
        "- Wie stelle ich `NaN` dar?\n",
        "- Was ergibt der Vergleich `float(\"nan\") != float(\"nan\")`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7youIav3VVy7"
      },
      "source": [
        "# üî¢ Teil 2: Quantisierung eines linearen Regressionsmodells (aus Lab 1)\n",
        "\n",
        "TODO:\n",
        "- In diesem Abschnitt werden wir das lineare ONNX-Regressions-Modell, das wir in Lab 1 erzeugt haben, quantisieren und uns die Ergebnisse f√ºr verschiedene Quantisierungsstufen (FP32, FP16, INT8) anschauen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KX9mB2kgqHH"
      },
      "outputs": [],
      "source": [
        "# Load necessary libs\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import onnx\n",
        "import pandas as pd\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "from techdays25.onnx_utils import (\n",
        "    OnnxModel,\n",
        "    benchmark_models_on_batch_size,\n",
        "    plot_benchmark_results,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify, which model to use\n",
        "onnx_model_path = Path(\"techdays25/assets/lab1/pytorch_regression.onnx\")"
      ],
      "metadata": {
        "id": "vMj1QPe8umFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the model again\n",
        "from techdays25 import onnx_utils\n",
        "onnx_utils.netron_visualize(str(onnx_model_path))"
      ],
      "metadata": {
        "id": "zHbGI4Lwuh8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ls-fTM1gqHH"
      },
      "source": [
        "## Quantisiere ONNX Modell nach FP16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbYQ_9fjMCUD"
      },
      "outputs": [],
      "source": [
        "# Load the previously saved FP32 ONNX model\n",
        "regression_model_fp32 = onnx.load(onnx_model_path)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    regression_model_fp32,  # path to the onnx model\n",
        "    min_positive_val=1e-7,  # Constant values will be clipped to these bounds\n",
        "    max_finite_val=1e4,  # same as above\n",
        "    keep_io_types=True,  # If set to false, the IO types will change to FP16\n",
        "    disable_shape_infer=False,  # Skips running onnx shape/type inference\n",
        "    op_block_list=None,  # A list of OPs which shall not be quantized\n",
        "    node_block_list=None,  # A list of nodes which shall not be converted\n",
        ")\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_fp16_path = onnx_model_path.stem + \"_fp16\" + onnx_model_path.suffix\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_fp16_path)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_fp16_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbOmu6lDgqHI"
      },
      "source": [
        "## Quantisiere Modell nach INT8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process"
      ],
      "metadata": {
        "id": "VG3h5hRa25kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cemKbQh6gqHI"
      },
      "outputs": [],
      "source": [
        "# First try static quantization and then switch to dynamic quantization\n",
        "# and see how the results change\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "#\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = np.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process"
      ],
      "metadata": {
        "id": "wB9FrJXeab4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = Path(\"dtmf_classifier.onnx\")\n",
        "# First try static quantization and then switch to dynamic quantization\n",
        "# and see how the results change\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "# Shape inference and model optimization, in preparation for quantization.\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = dtmf_gen.generate_dataset(\n",
        "            n_samples=32, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        extra_options={\"CalibTensorRangeSymmetric\":True}\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ],
      "metadata": {
        "id": "kgQGXuHvab4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_77SjqWgqHI"
      },
      "source": [
        "## Netron Visualisierung der ONNX Modelle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPJlTiVRgqHI"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "# Change model path accordingly:\n",
        "onnx_utils.netron_visualize(\"pytorch_regression_int8.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ZYUTq7gqHI"
      },
      "source": [
        "## Vergleich der quantisierten Modellvarianten mit urspr√ºnglichem Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX1nKqsDgqHI"
      },
      "outputs": [],
      "source": [
        "reg_model_fp32_cpu = OnnxModel(onnx_model_path, provider=\"CPUExecutionProvider\")\n",
        "reg_model_fp16_cpu = OnnxModel(onnx_model_fp16_path, provider=\"CPUExecutionProvider\")\n",
        "reg_model_int8_cpu = OnnxModel(onnx_model_path_int8, provider=\"CPUExecutionProvider\")\n",
        "\n",
        "reg_model_fp32_gpu = OnnxModel(onnx_model_path, provider=\"CUDAExecutionProvider\")\n",
        "reg_model_fp16_gpu = OnnxModel(onnx_model_fp16_path, provider=\"CUDAExecutionProvider\")\n",
        "reg_model_int8_gpu = OnnxModel(onnx_model_path_int8, provider=\"CUDAExecutionProvider\")\n",
        "\n",
        "print(\"\\nSpezifikation des FP16 Modells:\")\n",
        "print(reg_model_fp16_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGYkUWNzMJGz"
      },
      "outputs": [],
      "source": [
        "# Create some random data and compare the results of the FP16 and FP32 models\n",
        "u_range = (-10, 10)  # set range for which input values shall be generated\n",
        "\n",
        "models = {\n",
        "    \"FP32/CPU\": reg_model_fp32_cpu,  # first model is the reference\n",
        "    \"FP16/CPU\": reg_model_fp16_cpu,\n",
        "    #\"INT8/CPU\": reg_model_int8_cpu,\n",
        "    # \"FP32/GPU\": reg_model_fp32_gpu,\n",
        "    \"FP16/GPU\": reg_model_fp16_gpu,\n",
        "    \"INT8/GPU\": reg_model_int8_gpu,\n",
        "}\n",
        "\n",
        "uu = np.linspace(*u_range, 15).reshape(-1, 1).astype(np.float32)\n",
        "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
        "\n",
        "# Extract the first key-value pair (this is the reference)\n",
        "first_key = next(iter(ii_predictions))\n",
        "first_value = ii_predictions[first_key]\n",
        "ii_diffs = {\n",
        "    \"Œî\" + k: first_value - v for k, v in ii_predictions.items() if k != first_key\n",
        "}\n",
        "\n",
        "df_data = {\"Input [U/V]\": uu.flatten()}\n",
        "\n",
        "df_data.update(ii_predictions)\n",
        "df_data.update(ii_diffs)\n",
        "\n",
        "pd.DataFrame(df_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzNNq4CUgqHI"
      },
      "source": [
        "### Fragen (Optional)\n",
        "- Wie verhalten sich die Modellausgaben/Differenzen der beiden obigen Modelle f√ºr unterschiedliche Bereiche, die in `u_range` spezifiziert werden, z.B. f√ºr `u_range=(0,100)` oder `u_range=(-1000, 1000)`?\n",
        "- Wie lassen sich m√∂gliche Abweichungen erkl√§ren?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRlxbLaqgqHI"
      },
      "outputs": [],
      "source": [
        "# Comment/Uncomment the lines in `models` to unselect/select certain models\n",
        "models = {\n",
        "    \"FP32/CPU\": reg_model_fp32_cpu,  # first model is the reference\n",
        "    #\"FP16/CPU\": reg_model_fp16_cpu,\n",
        "    #\"INT8/CPU\": reg_model_int8_cpu,\n",
        "    # \"FP32/GPU\": reg_model_fp32_gpu,\n",
        "    \"FP16/GPU\": reg_model_fp16_gpu,\n",
        "    \"INT8/GPU\": reg_model_int8_gpu,\n",
        "}\n",
        "\n",
        "# systematically evaluate the model differences for a given range\n",
        "uu = np.linspace(-200, 200, 100000).reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "ii_predictions = {k: m.predict(uu).flatten() for k, m in models.items()}\n",
        "# Extract the first key-value pair (this is the reference)\n",
        "ref_key = next(iter(ii_predictions))\n",
        "ref_value = ii_predictions[ref_key]\n",
        "ii_diffs = {k: ref_value - v for k, v in ii_predictions.items() if k != ref_key}\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for k, v in ii_diffs.items():\n",
        "    plt.plot(uu, v, label=k)\n",
        "\n",
        "# plt.yscale(\"symlog\", linthresh=.0001)\n",
        "plt.grid(which=\"both\")\n",
        "plt.xlabel(\"U [V]\")\n",
        "plt.ylabel(r\"$\\Delta \\hat{I}_{ref}$ [mA]\")\n",
        "plt.legend()\n",
        "plt.title(f\"Abweichungen diverser ONNX Modelle zur Referenz {first_key}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fragen (Optional)\n",
        "- Unterscheiden sich die Kurven f√ºr INT8/CPU (FP16/CPU) und INT8/GPU (FP16/GPU)? Wieso?\n",
        "- Wie ist das Verhalten der Kurven f√ºr die INT8-Modelle (statisch quantisiert) bei $\\pm 10.0$ zu erkl√§ren?\n",
        "- Gibt es Unterschiede zwischen den statisch und dynamische quantisierten INT8 Modellen?\n"
      ],
      "metadata": {
        "id": "PBHXjy_NzPci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Messung der Inferenzzeiten f√ºr die quantisierten Modelle\n",
        "- Wir variieren die Batch-Size und messen die Laufzeit f√ºr jeweils $n$ Durchl√§ufe"
      ],
      "metadata": {
        "id": "5F97gmC9waHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJnVIlNxgqHJ"
      },
      "outputs": [],
      "source": [
        "# measure inference times/latency for different batch sizes\n",
        "\n",
        "batch_sizes = [2**i for i in range(10, 23)]\n",
        "model_dict = {\n",
        "    \"ONNX Regression Model (FP32/CPU)\": reg_model_fp32_cpu.predict,\n",
        "    #\"ONNX Regression Model (FP16/CPU)\": reg_model_fp16_cpu.predict,\n",
        "    #\"ONNX Regression Model (INT8/CPU)\": reg_model_int8_cpu.predict,\n",
        "    \"ONNX Regression Model (FP32/GPU)\": reg_model_fp32_gpu.predict,\n",
        "    \"ONNX Regression Model (FP16/GPU)\": reg_model_fp16_gpu.predict,\n",
        "    \"ONNX Regression Model (INT8/GPU)\": reg_model_int8_gpu.predict,\n",
        "}\n",
        "\n",
        "benchmark_results = benchmark_models_on_batch_size(\n",
        "    model_dict=model_dict,\n",
        "    input_shape=(1,),\n",
        "    batch_sizes=batch_sizes,\n",
        "    n_runs=100,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg8OpUBIgqHJ"
      },
      "outputs": [],
      "source": [
        "plot_benchmark_results(results=benchmark_results, title=\"Laufzeiten der unterschiedlichen quantisierten Modelle\", xscale=\"log\", yscale=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fragen (Optional)\n",
        "- Wie stark ist der Einfluss der Quantisierungen bei diesem Modell auf die Laufzeit?\n",
        "- Wie ist das Laufzeitverhalten des statisch vs. dynamisch quantisierten Modells?"
      ],
      "metadata": {
        "id": "E-_5yC16xqIe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fd481-eMB-R"
      },
      "source": [
        "# üï∏ Teil 3: Gotchas bei der Modellquantisierung am Beispiel eines einfachen Modells\n",
        "\n",
        "In diesem Teil werden wir uns damit befassen, welche Probleme bei der Modellquantisierung auftreten k√∂nnen und dies anhand eines Beispiels illustrieren. Folgende Schritte werden durchgef√ºhrt:\n",
        "- Erstellen eines benutzerdefinierten Modells in Keras zur Mittelwertbildung entlang der Zeitachse.\n",
        "- Konvertieren des Keras-Modells in das ONNX-Format.\n",
        "- Quantisieren des ONNX-Modells von FP32 auf FP16.\n",
        "- Generierung von 3-dimensionalen Zeitreihendaten f√ºr die Modellinferenz.\n",
        "- Modellinferenz mit dem Keras-Modell.\n",
        "- Modellinferenz mit den FP32/FP16 ONNX-Modellen:\n",
        "  - Laden und Ausf√ºhren von ONNX-Modellen mit der ONNX Runtime.\n",
        "  - Vergleich der Ausgaben von FP32- und FP16-ONNX-Modellen.\n",
        "- Diskussion der Beobachtungen und m√∂glicher L√∂sungen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pncih_L8dWVa"
      },
      "source": [
        "## Modelldefinition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya6rTWHfamy3"
      },
      "source": [
        "Unser Modell unten nimmt einen 3-dimensionalen Eingabetensor mit den Dimensionen (Batch-Gr√∂√üe, Sequenzl√§nge, Merkmalsanzahl) entgegen. In unserem Beispiel hat der Eingabetensor die Form (2, 10000, 3), was bedeutet, dass wir zwei Batch-Elemente haben, jedes mit einer Sequenzl√§nge von 10000 und 3 Merkmalen pro Zeitschritt.\n",
        "\n",
        "Nach der Verarbeitung durch das Modell wird die Zeitdimension reduziert, und die Ausgabe hat die Form (Batch-Gr√∂√üe, Merkmalsanzahl). F√ºr unser Beispiel ergibt sich eine Ausgabe mit der Form (2, 3). Die Ausgabe repr√§sentiert den Durchschnitt der Merkmale √ºber die gesamte Sequenzl√§nge f√ºr jedes Batch-Element.\n",
        "\n",
        "**Beispiel (Visuelles Beispiel weiter unten)**\n",
        "\n",
        "Eingabetensor (2 x 4 x 3):\n",
        "```\n",
        "[\n",
        "  [\n",
        "    [3, 4, 5],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "  ],\n",
        "  [\n",
        "    [2, 4, 6],\n",
        "    [8, 10, 12],\n",
        "    [14, 16, 18],\n",
        "    [20, 22, 24]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "Ausgabetensor (2 x 3):\n",
        "```\n",
        "[\n",
        "  [ 6,  7,  8],\n",
        "  [11, 13, 15]\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBhX8Vul3feC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Layer\n",
        "\n",
        "\n",
        "class SumLayer(Layer):\n",
        "    \"\"\"Custom Layer to sum over time dimension of a tensor.\"\"\"\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        \"\"\"Reduce (sum) the input tensor along the time axis (axis=1).\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): The input tensor of shape (batch_size, sequence_length, feature_dim).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The reduced tensor of shape (batch_size, feature_dim).\n",
        "        \"\"\"\n",
        "        return tf.reduce_sum(inputs, axis=1)\n",
        "\n",
        "\n",
        "# Custom Layer: Division by sequence length\n",
        "class DivisionLayer(Layer):\n",
        "    \"\"\"Divide a tensor by the length of the given sequence.\"\"\"\n",
        "\n",
        "    def call(self, inputs: tuple[tf.Tensor, tf.Tensor]) -> tf.Tensor:\n",
        "        \"\"\"Divide the summed tensor by the sequence length to get the average.\n",
        "\n",
        "        Args:\n",
        "            inputs (Tuple[tf.Tensor, tf.Tensor]): A tuple containing the summed tensor and the original input tensor.\n",
        "                - tensor_x (tf.Tensor): The summed tensor of shape (batch_size, feature_dim).\n",
        "                - original_input (tf.Tensor): The original input tensor of shape (batch_size, sequence_length, feature_dim).\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The averaged tensor of shape (batch_size, feature_dim).\n",
        "        \"\"\"\n",
        "        tensor_x, original_input = inputs\n",
        "        seq_length = tf.shape(original_input)[\n",
        "            1\n",
        "        ]  # Get the dynamic sequence length (length of the time dimension)\n",
        "        return tensor_x / tf.cast(seq_length, dtype=tensor_x.dtype)\n",
        "\n",
        "\n",
        "# Define model with separate Sum and Division layers\n",
        "def global_average_pooling_1d() -> Model:\n",
        "    \"\"\"Define a Keras model with separate Sum and Division layers for global average pooling.\n",
        "\n",
        "    Returns:\n",
        "        Model: A Keras model that performs global average pooling over the time dimension.\n",
        "    \"\"\"\n",
        "    inputs = Input(\n",
        "        shape=(None, 3), name=\"input\"\n",
        "    )  # Define the input layer with shape (sequence_length=None, feature_dim=3)\n",
        "    sum_x = SumLayer(name=\"sum\")(inputs)  # Apply the SumLayer to the inputs\n",
        "    output = DivisionLayer(name=\"divide\")([\n",
        "        sum_x,\n",
        "        inputs,\n",
        "    ])  # Apply the DivisionLayer to the summed tensor and the original inputs\n",
        "    return Model(\n",
        "        inputs, output, name=\"GlobalAveragePooling1D\"\n",
        "    )  # Create the Keras model with the specified input and output\n",
        "\n",
        "\n",
        "# Create the model\n",
        "model = global_average_pooling_1d()\n",
        "\n",
        "# Print model summary to see the architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beispiel"
      ],
      "metadata": {
        "id": "eix_OlBl-Nmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample data\n",
        "batch_size = 2\n",
        "sequence_length = 5\n",
        "feature_dim = 3\n",
        "np.random.seed(0)\n",
        "sample_data = np.random.rand(batch_size, sequence_length, feature_dim).astype(np.float32).round(1)\n",
        "print(f\"Input {str(sample_data.shape).replace(',', ' x')}:\\n\", sample_data)\n",
        "\n",
        "# Pass data through the model\n",
        "output_data = model.predict(sample_data, verbose=0)\n",
        "\n",
        "# Print the output\n",
        "print(f\"\\nOutput {str(output_data.shape).replace(',', ' x')}:\\n\", output_data)"
      ],
      "metadata": {
        "id": "IoVsJOuP5j7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualisierung der obigen Beispieldaten {display-mode: \"form\"}\n",
        "\n",
        "# Visualize the input and output\n",
        "def plot_data(input_data, output_data):\n",
        "    batch_size, sequence_length, feature_dim = input_data.shape\n",
        "    gap_size = 1  # Size of the gap between rows and columns\n",
        "    total_cols = sequence_length + 1 + gap_size  # Include gap for output column\n",
        "    total_rows = feature_dim + gap_size  # Include gap between rows\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=batch_size, ncols=1, figsize=(9, 3 * batch_size))\n",
        "\n",
        "    if batch_size == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        ax = axes[i]\n",
        "        data_with_output = np.full((feature_dim, total_cols), np.nan)  # Initialize with NaNs for gaps\n",
        "        data_with_output[:, :sequence_length] = input_data[i].T  # Fill input data (transpose to match dimensions)\n",
        "        data_with_output[:, sequence_length + gap_size] = output_data[i]  # Fill output data\n",
        "\n",
        "        cax = ax.matshow(data_with_output, cmap='Blues', vmin=0, vmax=1)\n",
        "\n",
        "        for (j, k), val in np.ndenumerate(data_with_output):\n",
        "            if not np.isnan(val):\n",
        "                ax.text(k, j, f'{val:.2f}', ha='center', va='center', color='black')\n",
        "\n",
        "        ax.set_xticks(np.arange(total_cols))\n",
        "        ax.set_xticklabels([f'$t_{t}$' for t in range(sequence_length)] + [''] * gap_size + ['Modell-Output'])\n",
        "        ax.set_yticks(np.arange(feature_dim))\n",
        "        ax.set_yticklabels([f'Kanal {f}' for f in range(feature_dim)])\n",
        "        ax.set_title(f'Signal {i+1}')\n",
        "\n",
        "        # Remove tick lines and surrounding border\n",
        "        ax.tick_params(axis='both', which='both', length=0)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_data(sample_data, output_data)"
      ],
      "metadata": {
        "id": "D2PXtb-z98pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_5U6zHgR-_"
      },
      "source": [
        "## Modellkonvertierung nach ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-9pMzIv6oUY"
      },
      "outputs": [],
      "source": [
        "# Convert our GlobalAveragePooling1D Model to ONNX format\n",
        "import onnx  # ONNX library for handling ONNX models\n",
        "import tf2onnx  # TensorFlow to ONNX conversion library\n",
        "from onnxconverter_common import float16  # Utility for FP16 conversion\n",
        "\n",
        "# Define the path where the FP32 ONNX model will be saved\n",
        "onnx_model_path_fp32 = \"gap1d_model_fp32.onnx\"\n",
        "\n",
        "# Convert the Keras model to ONNX format with FP32 precision\n",
        "# Define the input specification for the model conversion\n",
        "spec = (tf.TensorSpec((None, None, 3), tf.float32, name=\"input\"),)\n",
        "# Convert the Keras model to ONNX using tf2onnx\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=18)\n",
        "\n",
        "# Save the converted FP32 ONNX model to the specified path\n",
        "onnx.save(onnx_model, onnx_model_path_fp32)\n",
        "print(f\"ONNX model (FP32) saved to {onnx_model_path_fp32}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdLdCuQBgaLi"
      },
      "source": [
        "## Quantisierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8A1tP9V679a"
      },
      "outputs": [],
      "source": [
        "# Now quantize the ONNX model to FP16 and save it\n",
        "\n",
        "# Load the previously saved FP32 ONNX model\n",
        "onnx_model_fp32 = onnx.load(onnx_model_path_fp32)\n",
        "\n",
        "# Convert the FP32 ONNX model to FP16 precision\n",
        "# The keep_io_types=True argument ensures that the input and output types remain the same\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(onnx_model_fp32, keep_io_types=True)\n",
        "\n",
        "# Define the path where the FP16 ONNX model will be saved\n",
        "onnx_model_path_fp16 = \"gap1d_model_fp16.onnx\"\n",
        "\n",
        "# Save the converted FP16 ONNX model to the specified path\n",
        "onnx.save(onnx_model_fp16, onnx_model_path_fp16)\n",
        "\n",
        "# Print a message indicating that the FP16 ONNX model has been saved successfully\n",
        "print(f\"ONNX model (FP16) saved to {onnx_model_path_fp16}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7m2fr58kMm"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"gap1d_model_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R_B8RE7ggas"
      },
      "source": [
        "## Datengenerierung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PORbJXNx4yav"
      },
      "outputs": [],
      "source": [
        "# First create some data and put it through the Keras model\n",
        "import matplotlib.pyplot as plt  # Library for plotting\n",
        "import numpy as np  # Library for numerical operations\n",
        "\n",
        "# Create a random input tensor with a batch size of 2\n",
        "# Generate a sequence of numbers from 0 to 9999 and reshape it to (1, 10000, 1)\n",
        "tt = np.arange(10_000).reshape(1, -1, 1)\n",
        "\n",
        "# Create an offset array and reverse it\n",
        "off = (np.array(np.arange(6)).astype(np.float32) + 4)[::-1]\n",
        "\n",
        "# Generate a 3-dimensional time series data using a sine function with the offset\n",
        "xx = 0.4 * np.sin(4 * np.pi * 1e-5 * off**2 * tt) + off\n",
        "\n",
        "# Reshape the data to have dimensions (sequence_length, batch_size, feature_dim)\n",
        "xx = xx.reshape(-1, 2, 3)\n",
        "\n",
        "# Swap the axes to get the shape (batch_size, sequence_length, feature_dim)\n",
        "xx = np.swapaxes(xx, 0, 1)\n",
        "\n",
        "# Convert the data to float32 type\n",
        "x_input = xx.astype(np.float32)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensions of the input tensor:\", x_input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGQTVao-GYZM"
      },
      "outputs": [],
      "source": [
        "# Plot the generated time series data\n",
        "import matplotlib.pyplot as plt  # Library for plotting (re-imported for completeness)\n",
        "\n",
        "# Create a new figure with a specified size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the first batch (b$_1$) of the time series data\n",
        "plt.plot(xx[0, :, :], label=\"b$_1$\")\n",
        "\n",
        "# Plot the second batch (b$_2$) of the time series data\n",
        "plt.plot(xx[1, :, :], label=\"b$_2$\")\n",
        "\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"t\")\n",
        "\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"Amplitude\")\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Ein Batch bestehend aus jeweils zwei 3-dimensionalen Zeitreihen\")\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(1.1, 0.6), ncol=2)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRHQY_j_gzEj"
      },
      "source": [
        "## Inferenz mit dem Keras Modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9EP5mXQ-Ln2"
      },
      "outputs": [],
      "source": [
        "# Put the data through the Keras model\n",
        "\n",
        "# Use the Keras model to make predictions on the input data\n",
        "y_output_keras = model.predict(x_input, verbose=0)\n",
        "\n",
        "# Print the dimensions of the input tensor\n",
        "print(\"Dimensionen des Eingabetensors:\", str(x_input.shape).replace(',', \" x\"))  # Erwartete Form: (2, 10000, 3)\n",
        "\n",
        "# Print the dimensions of the Keras model output\n",
        "print(\n",
        "    \"Dimensionen der Keras-Modellausgabe:\", str(y_output_keras.shape).replace(',', \" x\")\n",
        ")  # expected shape: (2, 3) -> reduced time axis!\n",
        "\n",
        "# Print the output of the Keras model\n",
        "print(\"\\nKeras-Modellausgabe:\\n\", y_output_keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq_N1o4Sg7p9"
      },
      "source": [
        "## Inferenz mit den FP32/FP16 ONNX Modellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8LdB2clSPgQ"
      },
      "outputs": [],
      "source": [
        "# Run the FP32 ONNX model\n",
        "y_output_onnx_fp32 = OnnxModel(onnx_model_path=\"gap1d_model_fp32.onnx\").predict(x_input)\n",
        "\n",
        "# Print the output of the FP32 ONNX model\n",
        "print(\"\\nONNX (FP32) Modellausgabe:\\n\", y_output_onnx_fp32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8wCn4znSZ_s"
      },
      "outputs": [],
      "source": [
        "# Run the FP16 ONNX model\n",
        "y_output_onnx_fp16 = OnnxModel(onnx_model_path=\"gap1d_model_fp16.onnx\").predict(x_input)\n",
        "\n",
        "# Print the output of the FP32 ONNX model\n",
        "print(\"\\nONNX (FP16) Modellausgabe:\\n\", y_output_onnx_fp16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsQD-7RzO2Ao"
      },
      "source": [
        "## Fragen / Diskussion\n",
        "- Welche Ergebnisse erwarten wir? Stimmen die Ergebnisse mit den Erwartungen √ºberein?\n",
        "- Was f√§llt bei der Ausgabe des quantisierten FP16 Modells auf?\n",
        "  - Wie k√∂nnte man sich dieses Ergebnis erkl√§ren?\n",
        "  - L√§sst sich das Problem ggfs. vermeiden?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5i-XeVZVVy7"
      },
      "source": [
        "# üìû Teil 4: Quantisierung eines DTMF Klassifikationsmodells"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Unbenannt.jpg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAIBAQIBAQICAgICAgICAwUDAwMDAwYEBAMFBwYHBwcGBwcICQsJCAgKCAcHCg0KCgsMDAwMBwkODw0MDgsMDAz/2wBDAQICAgMDAwYDAwYMCAcIDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAz/wAARCAF8AfsDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD9/KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooqC51GCzP72aGL/AH3C/wA6AJ6KwNR+KGgaTIVuNUtYyvXJJH5gYrD1H9o7wrpjlXvs4xyoHP65q1Tm9kB3dFeR6t+2X4R02dlNyhRRklpQp/LFc9rX7efh+0Q+QgBHHznd/LHatFhqr6Ae+0V8vah/wUbsLV/ltbZ13Y3DcB+ea5rV/wDgpuu/9zFHH6gJn09QfX1qnhai30A+xqK+FdR/4Kpz2w+SSM4Az+6Tjtj7uf8AP5497/wVi1W1nKBrcN1w0SZHseKn6tO3QdmfoFRX5/WX/BWXU3hHmPbburbY4xn35GMf/XqaP/grRfK5DLbOQehVB6eg/wA5qHTadmx8rPvuivh7Sv8AgriWi2zaTZu4J3MWPQemCM1raV/wVo02dl+0aXCo43Y3AD8cn/JpcjtzD9mz7Lor5k03/gp94PvHRWs5IiepNwMA/wDfP+c11mk/8FAvh7qkKn7ZcRuR8ykJhT6ZLDNJwa3Fys9vorz7SP2pPAusWySR6/aoX42OG3KfQ4BH611Fl8Q9C1FIzDrGmP5uNii6Tc2fbOaTi1uibM2aKQNmlpAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRXA/FT9obQfhjCyT3MU14MjylPCEep/wA9DnGKaTbsgO+NYuufEHR/DiZu7+BOvAbd069On418b/F/9vC8vZJY4pkgjBwoLYAweyjjPXnr0r5V+NX/AAUl8GeCZ9vijx5o9hM44huL+OF3zz8qFgW6HoK6oYVv4mVbufpZ4t/bN8L+H9whZ7l14xnBB7cDPHT0rzLxX/wUBvI/+PC1tIgvJZlJLdARgk+vX9K/Hv4o/wDBd/4VeHS8emX9/rzxM2IrawcH8DMEU9OoY9/x+fvH/wDwX8mvEY6J4VumjfIZ7q7S3ZAxPJCK4OMevr6c6+xhHUnmS2P2/wDGH7cmsTyOkmqsgc5KBtqkdx6dP515n4m/bkufLlVtU/eDAGH68ZH4cfpX4R+MP+CznxG8RSN9kj021jIwgMckrIwz0bzApwB/dHU153q3/BQn4o+KGbOt3ECyEpiCOCND6c+XuyCeufTnOa2vBaR09Bc6SP3L8W/tmPft81+QBKPlaUfMwyM4xjnJ/XrXG65+16FHlvfr8wIP7wY57+nX3zxX4c6r+1B471hHkk1TV9wDBv8ATpUIHU42MuPXpwfyBe/HLXdW2wy6darNHjfMdQ1CYlgOpWW4ZOhGQFwfbtDbeqevz/yYo1F1P2a1T9sqAIZH1K03Bif9cMADqM+o9OK5jVf2xNPdJca9HEUILMsq4A64J568+/3sYr8oPBH7VvxC8FX3+ixeBJGRdoOoeBNA1RmUgjn7TZyEqVyvJPUg8E13Gk/t1fEy5Ch9G+Bca5+8fgp4K+Qj3Gk59Of/ANVRzOSjZNv1t/mUpq+ux+g+oftraHvH/FQWcikZKtcjGOnrkHjGMfzrFvf23vD0EyrL4ktW8zuZl5x7k8YP4DmvkPwp+0P8V/HGq2UVtr3wX8Mrcy7Rdr4G0HSYon7hjb6cCvP4DjpXvfhb9iv9pLx9ppvNK+J/wT1e3uj/AKyCGGRJD6Fl085OARxuGfzGVT26avHT11/I1jOk9bv8P8zrNa/bS8MzW+weI7IcfMTdJvzjGevv/MdqoRftm+Ftqt/wkunyNkBQtymXbPGPm6+1Og/4JQ/teeLtSPkXfwQ1qSVFRf8Ain9MZXDN8vMung8ep5wOc8VUtP8Ag3i/bH8R3LXdj4M+GGoeXzuktNFVeTyAs1uq9u397jitnypc9VNL0/q5nzxbtB3fnb/MvD9rHTZVhjt9atC8jhHUTISuc4BHX2yKtRftL6dcSK41GGUN8rEyAgY46jkc5x7AY7E8N4r/AODcr9t/WZFEvwg8MzqG25sNS8OWK7ck5IjnjzyT75JxjvwXjn/g3u/bM+G+mJe3fwT1zB3ZXRtWstRlxnpstbmRh+R6CuKVajJOSdo+ehS59t/nc+gf+Ggre8fdDfxFii9HGV9iOPQ9fQ+lX7H47Suo/wBNSNyeGEnCjBHY9eD/APqr4mn/AOCbH7WPhhpf+LGfHSIRDc7J4O1R0HP98REdgcg8e1eZ3XiHx98PdWOl6tLrmizxMqywX0LQPC3Qlg4HHfkDp71ip0WlHm39NfxKkqi1cX9x+mo/aAmWA/vXDLkId2cDj/63XtitfTf2gbu3kUrOqMo6LJgFT/8AWPI68fWvy9sv2jPFOj2kZ/tCWe4EjfupIwiqmBt+YnJOS+QVGAFwTkhdiw/bA1+yjUyxCVWXBJYuqge3p7nNdcYR5rRYvan6iaP+01d20qeVebV3Z2q3AI5z1rqNA/bH1TSJP3epXEYVeWExwnOOuc9/89vy70X9uRYn8q4EqleXaWNkLthQQByOvv0GT6HsdB/bS0y7jUNNkn5CrOMgk8Bfr8v9eua0jGSlrLYanFn6teCP+ChXiXw/crLaa5dxvwSQx74zyOf/ANdes+B/+CtPivSP3UmofahK2A1wolIPflskD8K/IXSP2qdLvIUH20jptOTksecE4z2rr9F+Pkd8rmO9DrJyCXxuxkkD3/zitrX3SK5ovc/afwX/AMFibWeeJNX0qzKKgD+S5WST1OclR+VeseCP+Cn/AMPPFEX+lG7sJm6ICsi4/wB47efbBr8K7L4xFgAkgCE9Vl/zj1roNJ+MDiRv9KkjKNkDquDjoRzkgD6Vh7JO+hNl1P6DfC37SPgbxkrmw8TaW2xA7ebL5IAPu4A/Ku0trqO9gWWJ0licBldG3KwPcEcV/PJonx51GwePyr9xtAbKSkMv4Z+mTXqHgX9vvxl4GuBPYa5exsw8vzIpipKHkKCCDjkf4c0vqyavcnlP3Por8tvhd/wWf8V6OyR6o1lqkCoIwLmIZ+uVw7HHctz6V9I/Dn/gr34D8SbU1i0udMdo1w0cgcO/8WQ23aO/3j+dQ8LUSvYlqx9cUVxngL9oXwV8Tto0TxHpt47uI0jMnlSSNjOFV8M3HoDXZA5rn23ELRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRSMcCvm39pX/grP8Dv2XGlt9b8WxatqkWB/Z+iqLuVjuKMPMysIZSDuQyBh6Ub7AfSdFfmn8TP+Dlz4feEryMaV8PPFt7aTj91Pqcy6d5h74wkqke4buK5u0/4OgvCdyQR8OY5MttKQ+LYJZfT7ggyeeKznVjCThJ2aLUJNXR+qFFfn54P/AODiX4WXPh+C+8U+C/iN4VW4cIksmmhrU5xyJZTDnqDwp4I9a6H9sb/gtB8IPDH7DPxF8ZeA/iBpN/4jsNMNpplmJzZagLq4KwpLDFMqtL5Jk81igYARHmtHo7Pcnle55n/wVH/4OG/hP+x5q2o+DdL1G+8S+JLGU297BokQlMTjIeNpXZI1wRg4YtkdMdfxx/aP/wCDi/4n/FG6uovC+iaR4UhmzH5t1K9/cqAT8yn92i9ejI4GOvevhP4neM7vx14w1LUbqVpHuJmfLA5xz06+nfjj3rlo7xMqroi5zvXsAeMhevHX04GTXbQ01RHNfQ9S+KH7a/xa+M8jnXvHfiK6t5jtaCG5+xQSA/wmKIJG3XqwNeVM0yW7kfLuILKhHX8DzjPb1qcpmTag+U5GSW+vFMll3oAvJdMMm7AJHoPwHTt09a0eq1Mbme0gAG5duNuAO5z9eOtMBBYAZzzu6Hccn0Gauy6G9xbs6/OFPzc42jpk+v8A+vgVlz2pj7EnoBjsevP+e9ZttFLXUtLd7V/hBC7Q24kEfTP6VZnv3XlGCjBIUc9SPf8Aw6/jWe6sFzxxnkg4OOv86R7hlHVs9cZo5imatnrJmBLOeAcAgHJz9cZ59s+vQ1vaZpuoa/ZF9L0/UNQmiXJEUTSqmMkliBwOvXr/AC4q3ujzt6E9D93r/wDrr9Fv2Wvjx+wF4S+BHhrQfir8KPjPq/i5bVZta13QdWg23Fy7ZKxQSzRxokYPlqR1CAsdxyMpyaXOo83zSf4jhFN2vY+Erm81HRb7dcW8EOeQhY8MAOoXP15z159KjPjS4tJHLWrqMfMVyMd+rL65/wD1V+kh8Zf8EzPFt1Fb6UP2t/h8tyc/b3Gg3MEAX5TvRJ5Zh0JxjOOcYPPwd+2U/gXSfihq1r8MtT8Tat4JuLvdpV1r8aJfXVtGip5zhDtTzJvtGI8AoiR5ySaKVao024uNu9v87/gXOnFbO50Hwi1+y8YWLeWWiNpGHkiYkkDjLA55wx546Y6/MR9Rfsn/ABT1fwL4ptG0b5TK6xupzi4JIGGOOR8o47HJ78/A3wa8Vv4W8SJIs3loW2lN2N+Rj/P179K9y+H/AMWJ9L1i0YSj5G3hjL03Lg5ycHP5gHr2rvo1NFa/bQ5Z6NpH7s/s8/FXVIdMtTOnkMsal1ByCTz789PXtX1L8N/jdqHlwjzvMj83zGBbIkABBXjGQQT+dfz9fCj/AIKd+N/AviK8gtZm1uyikZYre4jGETdkfMAG4AHXI68dK+nfhl/wWlms9O8zVNGZBboCrROYw2MZ6575x7j73XFwVSCMmlLU/dLSP2i7hoopHjiRjGqlWfKljntkYPH489MgDX0v9pRSwFzZQ5JwCJ9vp7Hv/wDq7V+OnhT/AILl+CdSK2tzNdxM7+XuCK43cE42tnpjjGMgfSvXfAX/AAUz+Gvj9bdLPxppEU8jMsUdzI1u7kfKMCTaScnjbk4/Gsq1F2tyfMqndPRn6vaN8T7fUrMyy28kHooYPnjv0x17/wD67era9Y31rJDcW8s8ToVeEqCsyEDIK5ww5xg+4r4b+Gf7VQkXzZL9NR5LiGKX5JBtJBGOM988+vcV6hov7SUmqSCO0O53IxCTyEx8xIx/LknNeLXUeXkmv1/A605J3Re+K/7B37M/xT0nUYdZ+BHwr1GXVVaK7uo/DdraXrA8ki5ijEyE8/MrqevNfIf7Qv8Awbf/ALL/AMTdAkfwV4I1XwBrHlkxTaX4kubiJ5CVw8kdyZCcAMAEdFO4k7q+y7D4mWWpWmI7nzZnwY5QpcdPUcckfiR9Km0TxSI7jfell2lo49mAXPJ3cdQc9CTgqemCa5nGOjiuVLtpb+uxo609pa/ifjV8Rf8Ag1E1qxR28L+PpgvBjGoRLMQMAkbcKOoYdey896+dvip/wbjfH/wHeXP9laf4Z8VxREpGkUxtp5mBxwWAjBx6yYHGcHr+/X7Sf7VnhL9mL4V654w8Y6munaBodlPfSOXCyTPEhZbeIu6o9xLjZFDuDSyMEXJNfiT4j/4Oz/F+q+Ir1m+CFpFpEkjeXbJ4il+1QpgYDTG12sc558peOMHHPZSVST+PTz1/T87kX7xPi34p/sG/Ev8AZWmF18Tvh78QvB2kQMjy65ZWf9p6dbqWwFLg+QznJOw3Cnpzijwp4N8BeM9Rx4d/aL0PQAj+Stv4+8P6polzdNz0/s+LUrZVJON0txGACMjrj0H9un/gvz8Qf2wdCOhaPp2rfDnw7eWz2+o21nrX2ya/Vsq6tKIIXCFSVKA4ILZyDivhC9vxNiXOSxIGRz0HX8/0Ndi2sn+n4f8AADm12Pv/AED9j/8AaQm0a61bwp4etvi5pdndC3uJfh54h03xo9uSCVMsOlT3E0IYDA81Ezg9+K5e+/aH134VeMLzw7430bWdA1zTHeC8sNQtXt7y2kztKSRNteNgCeCOoXjmvii01ufTrq3nhkkhltnWSJlcgxuDncMHgg9DX0z4J/4LNftF+F/C82gaz8SdU+I3ha8lhkuND+IFtbeMtPl8o/Kqw6pHcLEMcfuthxnBGan2lVaRa+f9foaKcH8Wh7z4F/aT03V0UC+UyudmH+UbsBiPTgEdM8DPrXpGj/EaK+SNoH3BgHweQRwSwPpwO3H4HPhUH/BSf9nj9oK5vH+L/wCy1oHhzWdWvLcf8JH8Htfu/DDaJaJt3mDSrprvT5JTgn7sKtk5Kn567fwt8GP2b/jPIH+CX7W9z8OtU1O++z6f4S+NmhPpMcECr+8mudbsvtNgu452ApETkg7TgtpRxFv4kdPI00esX957HZeLPMt4lSV90fyFgeSScn69/wAh26b1h8QfKl8id2R3zjC+mOp6Y5/rXl+ufsL/ALUPwq8OWWv2Xw4k+LPgnV7mSHSvE/w3uofFlhq0cWQbiP7E0zpCSpAaZIuQwIDEgeaeE/2xNF1RYY726SwZ8qovU8gEqQCAzHacEN0Y49auFaLfNF69iWmt1ofY3hT45aj4ZcfYtUuogpJHzHI9Rj6HpXv/AMHP+CpfxE+FaRw2+rT3VnBGALa4kEqBN2cKj5VM9OBnryCa+CNI8c2OpzD7PMh3IpQsm7zDx8gx6c9ufxrT0/xfdW9yscLPcbiAsSOX3bjwFxye/P4c5xXby+0XvK6ZCt0P2g+Cn/Bazwx4mWOHxdpD6dKysTPZHCls8KIpD029W39R92vrL4YftCeDPjLAreGvEWm6m7AkQpLtnIGMt5bYcryPmAx71/N5F4++UFUKSopbKPzHgc8DvgH06e1dd4G+PepeFbovZ6ldLtI2gPgHvnGSM8nr/d71wvCqXwD5T+kiivyB/Zs/4LbeMvh9fQWfiqRfEelhv3n2p2ebBfLFZfv5xwNxZRzgcV+mP7MH7VXhj9qvwP8A2x4dmIkg2Ld2khBe2dhnGR95cg4bAzjoOlc1WjKm9RSi0em0UUVkSFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUV4N/wUk+Nlx8EP2U9buLCeW11XX3XRLKaMHdC0ysZHBBBVhAkxVgeHCUDWrsfJ/wC2J+0/8S/2+Pjhf/BX4HvLYeG7Z3s9a8QRv+6ulyY52LjIFuoJXPzB8thJXZEXrP2ev+DfP4T+BrW3vvH0t1491xyHu1uVVrWXgfKTIHlyrbh5kbxbhj5FOc/TP7Df7L2nfsr/AAK03SYrOCHXtRiS91ydQC810wyY9wJykWSigHGFLfedifYycVK1V/6/r/hi3K2kTxHwP/wTm+Dfw4YHR/ByW22LyFEmp3s4WPIOwCSZgFyFO3pkDjiunv8A9kH4aana+TN4M0QpnOVhKtn/AHgQf1r0cHIpavmlblvoZ9bnyv8AE3/gjD+z18Tknlm8Ff2bq033dVtbyWS8gznPlmcyoucnovevw+/4OPP+Ccfg/wD4J66j4St/BvibUtQtvFHnXk+lXoL3FmseEikeUsRKZGefoiBfJHBzkf001/NR/wAHd/xbl8Tft5WHh0lFTw1odpZqB/EHVrnn8bkj8BUwilKy6lOcnufkS8qsucDdnAUe/c/4dP0qpcEyAqFAIO7ggdPp/jUryja537XxkEsfmx6j8euagmdYlz3yDkduR2/zyBXd8Ksc/XUcbwR5PzqcdVPDZ9evb/8AXRFdAHf/AKtV+YlTkk/Tj3P9ahcHyRw7qh27lydoyP8AE/n+Ue0RTkgtsH3jjj3+XP8AWldsLJovW97/AGfdbgzIwfKkAbs8+p9z1/pXtPwx+Alt+2b4cu7PwXpr2/xM0mzkvJtFtkbyvEFrBG0kksSf8s7hI0eR1BMbojMBEY8TeFW9wVlG3+A4yw4J/lXSfC74h6/8DPiHoPjPw3qFxpfiDwvfwapp91C/z208Tq6SAg9mUcd6JykoNRtd9xqK5tTmJ7ebS55IJhLbTq7Rusi4dSMhlPcEAkHNZ7yMBnpnqDX3p/wVa8Q/Cj9s34b+Df2jPht/Yvhfxv4qV7H4o+AdPjaJND1ZG2DULVWALWt0MM20uIWkhV28yfFfBV++JNnTbwRWMZynDmmrFtJOy1EWYu+APvcEAdanF22erdcEZ6jOcfnUOm2/2y5WP154HYdavXlhLazsrcEAEcde/Q8//XoWquJ72IDdyNu+Yg5DfeOSR3z7V0/xa8TWfxC8T2V5pmnw6PZ2+j6Zp/2VCSnm29jBBcTDjA86eOWYgfxTNXMQoyuhwGB6DJwR+NRyXphlIwGwx55FWpNRt/X9ah1HWeiT3drdzhMQ2WPNdiFAJOAoz1Y8naMnCscYUkLaaBdX9nc3KR/uLXb5rlgApY4VRk8scMdoycIxxhWIsT63da/Fb28sirDaIVTICpGDjLNgfMcBRk5YhUXnaoCT+IPNhgt1Upa2xJjC8HJxuY/7TYXPsoHQCi1O39b/AOS/rfR3kURp0v8AcPpXX6L8AvHWq6PBqWm+F9fvLS6UtFNaWkkocZIONgJ61zH9tvcSQ+dtKQL5a7UC/LnPOMZ6nnr719yfs9ftR+A/DPwt0LSTrkMd1ZWSieOSGRAkh5fnbg/Mx6Hvmsm7K8So6v3j5Uh+EXxY0myAj8MfEO1t423ALpt4iA8c424zwPyHpWFqOueLPCd03286nbTN8rC/gJb6YkBr9FtO+PPhnVXRbbWNPmY8jbMhJyOh5OD+ta1l47iivo2trk7H67JOh7Ec4/pgfjU/WZ3tqi/ZRZ+fPw5/a+8dfC3UWn0vWbyCOQgyQWl5c6YkxAwNxs5IXPBP8XOTmvoP4Z/8Fx/i14OuxFf3NzNpfliN4bK9zdP7m4v0vW5zyMYPfPSvovxNZaR43Jh1WzstVUqdyX1otwmB0++CO/44Ncp4n/Z1+HniSGOC48HeGo48hN1pYx2bHv8AehCt+tVKvLl5ZrT0X/D/ACBUuqZtfBT/AIOSfGHgvxvqN7e6jrcOjSbTZ6dq+gaf4jeIhdh/e2cmjbSVJH3XAH8JOSen8ef8HPfjDUrGG70Hw/4CtpbeZsR6lFqM13ImeGVIykUJIAJXz5ecfMcZrxLX/wBg34Ya9beRa6LPpUgHzT2eozs4+gleRc/8B/wrj/Ef/BNHwlfWiDR9c8R2Ex4Ml4YbtR7hFSL/ANCpyqUpUuScE/W99Xfv08tCfZScua/5G5+3n/wUr+IP/BQX4PeH5/F914U02z0bWpo7LQNAkeb7Wy28TS3l2GuZFRkEqJAwQbxPeruHlyBvkdZ3ifEaxSeZ8gQRjke4xzyCe3bjNSeJNL/4Vd4n1zw8Lg3KadqU9ibox+U0qxzNHu2hmxkrkgFsZ6nGK58eIZLlyz7SxYAMVVFOcdQOO36USjFO8du39f5f8GbtaHoPwe8HS/Fj4t+F/Ddr9mN54m1ez0yAzTi0iaWaaOFVeVyEiUs4y7kKoJJIwTXmXjPXR4k8S3d6sEFuk8hZI4Y1RVXoOFAXOBzgAZzwOle2fshfG3wl8K9Q8eXvjTSP7YXUvAviDSNFidQ0dvql9YTWdtcspDbjEbhpFyPlZVIIIDDwM/vmGTyTyTVSd46f1/X6grWBWLEdc9sU7PGaWztjPMArxoc8Fn2/rV0+Er9E3LDv91cHj25oinbYTaKAfHSpBOwHXGB2/wA+9MuIHtpNkiPG46h1waEba2RnOMcVa7Bbqdt8G/2h/Hn7PHipte8A+MfFngjW5ITbvqPh/WJ9MunjJBKGWFlcqcDKk4PpX2J4e/4OBvih4/spbD46+D/hn+0Hpl5py6JPd+I9DTTfEcGm5y9ra6tpwguIg5yWZ/MLFmJzuOfgcwkL04yMVYdJZ4gGxiNdoyAuPr0z168/pTlrqwU3F3TP0i0v48fscftI3017pj+Of2afFFzO9z9guHGpeG9pCpBp1reWVvmzhDEyST3Wl3krdd4IO/Z1/wCEGrfDnRUvYPGfhTxPpEtzFplprCXKxaJrN7JOyGGx1eJ5tPKRqoeSTVJdKYA8QgjFfmMls27C8lT8xVup6/yz3rsPg9rfjbwv4vj/AOELv/EWm69q4Glp/ZM00V3erKy/6OPKIZg52jYM7uBg5OOiNVtOLbv339b31d/XfXvd+011PvjVNdvvBgsk1/T7vRBrvnDSrmdQLPXo45GjllsbpWaC+h3ZAmtpJYiDkOQRUx1UlxJG5CkkgBskkA47889Pxrwuw+Fv7T/7LPw/1fXbv4f/ABO8GeF9SltpNfj1Xwzcw6Jq/kOZLcanZ3MJtbuJXPyx3MbxFnHyndzkWX7ZOj+Jtdi/tjRh4Ru22JcXvhpTLaXRzI8s8mlzyiLzpGZVWOyuNPtYQPlt8DbWsat9LqxfNbWWh9TWni5yFdvnAUA/3vQ9APb8vevsf/gkh+2K/wADP2kNHtJrkw6Nrkv2C8RlBXY44/EFVPB7DtnP5a2/7X1j4cW2j1G50vU0liWH7bp0zvDEfLido2gmSOaMoX8vcY2jLB/LkcJuHcfDH9oGW58WWt7pU6xSROkkT8tGuCDnAIz26H07HNJpybjLUammj+umGZbiJXQhkYBlYHIIPen183f8Evv2pIv2mP2Z9MuJbhZtV0mNba4G7LFQPlJzz2I9MbfXFfSNeXUg4ScWQFFFFQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfGf/BZq5ubP4ZeAZWXdo8XiSJ7zJ43Dbt/HyzP+Ga+zK8S/4KDfAh/2gf2ZdZ0y2hnudR04HULOKAnzJGEbxSBFAJaTyZZti95PLzxmpmrxafUcd0Zn/BRj9vDRP2A/gFc+J71Le+1q8Dw6Pp0km0XEigFpGA+YxxhlyF5LOiZXeGH5q/DT9l/9r/8A4LByp408W+NG+Gnw+1C5juLH+0IXldoGRhvs7BcRHaBGCz+Xu3ZWWRt+3xX4vftv6L+0l+2T8J9M/aGuT4b+G/gK2g03xBc232vU4tXFlHcSbmjgVpWa6mMIYxAkJ5cmQEbb9JfEn/g7++C/gL7NZeD/AIW+NtWtoECEX15Y6dDDGMbPKNu90hXbjglCvQqKmPtJN2Wi30/D+vka6RWmrOqb/gnh+0j/AMEovBF/8R/h38a/+FqaL4ahk1fxF4W1DR3sPttnAA0n2ePz5hNIsJnbYXRjtATMhXH6Ifsl/tI6N+1r8A/D/jzQh5dnrduHeAvvNrMvyyRluN2GBw2BuUqcDOK/PbwD/wAHaH7OXxM8BeJGudF8c+GfEmm6JcXthpmr6fHNa6/eLEzJYQT28kuxpCAoe4SFPmHPau9/4NkdK1rTv+Cctu2pSyvZS6pL9iEjZZQAMn6FfLI+tQoezmlHZ3+X/DhJuUby3P0Ur+UD/g5c1+48Tf8ABTvx3cXGFWC8FiG64WGONE/8dA/Kv6v6/lj/AODl34Zyab/wUH+IjOpZ11CO8DBRys1rDMMeuA/6c5roTs79P6/4JifmNNLnpuUcj8MHpz35/WoY4xCycHGOvcjOOR/TPOakkDyMQF2c4Unqfbp1qFmLc8tzkbX4x/Pt7fjnnrl5mXkCg5YYyoBGSeQPft7fh1ptyXCLFvbCtkqAcKxAz7eg6dhz0w6H5Qp5MmSck8DjPHpVryd0XzKdx5DMSMnrSXkJ3KcUy29wiB8Rk5Jz09evf39q1o722gt5I5ZTtKhtwzjPORjGO/8Anqc+20w306RJIE8w9GbCj1zjtx/P0qvq9hLpWoNbz/KQ+N5B6ZxuB7jjt6Giz+KxK10IG1aWydwsm5JBsZeu5RjA/Tj6Cs2Vt8jH1JNbFp4MvtUsLu9gtpxYWLhLi6dCsURbdtDNjAJ2nAzknoKyJAFbg7uOTis581ryN1Yn0sI07buu0lOcDPv7da27ppLmSBpZdwt49g3DG0Bj8vqDk/yrDsJliD54zj5ucj8j/nFWjPCoCq0hHKtkZJHGMD8+PbrSg1YTJ9L0WW71CMrG0is6gEcbjkAY49x/nisy4zPevty5Zzjj72TXf/DnwL4p8a2ct9ovhLW9T07SU+0Xl7Z2Ly29jFGwZpZpNpSNEypLOQoAGSAa46XSrjSb2W3uIpILyN3inikTa8LAlWQqeQ2QRjj07mqtaNwV7lWRPITy8L97727g/T8//wBdQ7CP4T/n/Iq5JE1zPnn94SznaCTk/oef1+lPggMDq21fmwdrDOexz0xz9OPaold6D1KTQhGKnIx2x0/GrWlWf2iJyC+7OMKcZHU/59jUZXd0HfBI+6R2pbiRk2iLcBgHG7oeOnTv0/DrUeQXNUW99bEMtw5EZwrDsR757VLpnjnVtLUeVczKc4wHI/T/ADzmsy316ZU2v86A5IdA/wBeKdJ4ikeZy8UQ3nBGzG09jijbYD0DQP2jPFtpNHt1C+BjPyA3DPg9QME8ZP5/jXQ2H7Y/jLTcD7RLIMYYNDHJjHvjPrnPp+Xj8muMrbvKjx2fkEe/B4P+e9KutyTAExoR024Pb6H/AD9aLtvmKvZHukX7evjCyRC0cHyj7zRH5mHqc/5/Crh/4KGeKLZlLadplxyAQyOP5NjPp9DkV89HWTIpUqBnuP8APsKhu74gY9cnjpg9/wDPtVc0t7i5md74ntZ9YgTU5UW41HUwbyZAhKEzMZWHP+/6fj3OHLbC4yTEgIAUoo656cjHp7dPpXYa/pYs42sdyMLRmtlMmfkC/JkjA/hUD359K5e6EyMDJG2VYsSQDlhnORnr2/GtHO0n9xjqYmsWSR2JZV+YfMTnkDp9fwr3PUPgf4e+H3wQ+Fuoz2Kalqfji61Frp8liyLHpzQwKOMECdySuG3PweBXiOsODpbK8hZ1CnGMg9O/Xp/h25/Sb/gmX8LvBP7SPh34fjVZZm8RfCvXf7cjiUj7PLDNA8aoApHzLPbWsvAIAi2n74x10oxm3Bbu1n87v8C4eZ4Z+2r/AMEldd/Z++CNr4+8OyS6npUCmbXtMeIG50bcQBKjjmWAcKwPzR5DfOpd0+NrC4mt5cR3Bg3YBO/A/HFf0jXVjba5pVzp17YW99YagJba7tZo1kiuImUq0bg5VkYEhgcgjI9a/n9/bJ+Bsf7N37UHjbwVbtO1hoWqzRWDzHMklqW3QMxHBJjZMnuc1niKaUuaOxo1oP8AAniawna3ttSS2vi/y5eLevH8QB4bv+X4V9a/8E4v+CJ3iT/gqd8YdS/4Rnb4Y8BeFo0m8Qa5PiOEtIXMUMKsf9Y2x9xAKxRoX2MfLjl+J/g7ZW1z4oSS9ltobVGUSPO2xRnn7+Pl4Dc+uOvSvt39tb/gtxqeqfBO3+AvwBsIvh38FdIEBuri1g+z6v4xvUjUT393IHLKssw3rHn5VigHAQIvNJVHD3dF3/rf7vWwotJ2OK/4KpfDf4A/syfEST4c/BbUk8XyeHnW21LxLEsnl3FzGCJPLlaeQT8lVaWNIIndHaOIJsLfHLSeenmSEk78cYGPTt6Z/KoJ7x7mTc53H1b06AfkP0pPMyvDngYwR169Pb/GtFJuybuQ1qb2jxQqqbUk3lc54wT/ALIz065P8q/pj/4NUP2EPBng/wDYuX4xXmg6XeeMPG97eQ2uoT2qtc2GnwSvaG1UnO1WmgmkYrgyB492RFHj+Zvwqge/iLfMoILeijn1/Cv6WP8Aghz/AMFRPhh8O/8AgmFoGk6l4p8NeHLnwNDcW+sQXV9FbtZk3EjRylWIO2VXRt4ypdnQMXRgKr3VK5EPisdh/wAHKv7Tdn8Av2NfElnE1rHP4oi/4Rmzh2jEhuUKzYA+7i3WdgxGNyKOpFfy5a3e+Zqc5GVO4kYTocj3GPvE/XjpX2b/AMFrf+Co95/wUd/aSN7ptxOPAvhrzLXw/C0Rje5WTaZbuUEA75TGm1TjaiKCqsXz8RT3Xkqm1gr53ZUDKkgd+p4x34OfWpwt4x99bv8A4CNajV+VdB87mRSGZmGM5xkLxkck/wCfXmvTfgN8RWtbqO2ldj9mKlMuCQoxxjj6V5REoe4Az1bGR/8AXq/4Z1v/AIR7WYp0k+VTh9yg4UnnHY8f571d3GWpFj+g/wD4N6f2tf8AhFPjJD4euJ0j0/Wl+zyB5sDc20A59ASCT7LnqK/dMGv5H/8Agnd8bZ/h98UNDvY5HUx3SNwCCOnTB6DJ/A9K/q8+DnjdPiT8LdB11H8z+0rKOZmwBl8Yfpx94Gqx0dVI16XOlooorgEFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB/L5/wWb+LfhmX/AIKGfE6y1XwqRocGu3NncRaZKbcxtE8kfmxuVcLI7RPIwIPLuVUAfL5l+z58V/2UvAfgS30XXv2ZNd+N+to++71q7+JOraFOC38EdlY2xRFAOPnldiRncNwA6H/gu14fm0D/AIKHfFfT9O1VZbTVNdkubqKNy8AmEjuGIIBEqbypb7wzKASkh3fJur2vi34faTYyXaeGr1ICl1ZXQbTry8KtGCGVwWmdAgwUJKochlV8gaxp80Vq7Lql+dnt69drFc6Tsz2f4hfspav4cOp/EXWfhbF8A/h8yGewtdeutQ0061+7zDa6XFfyz3160pKh5YPPSJphJK9rD88f9LH/AARj12LxB/wTY+GU8VvFa/6FMphjj2LH/pEpUAemwrj2xX8sf7Jnw8tP2rv2n9CsdautM0v+17yFLqVNOjh8wBhkrBAiIz4Jxu2g85bvX9hP7PHwN0f9mz4MeH/BGg+Y2m+H7UW8ckv+smbJLO2O7MSfbOOgrl5LVL3vv2X5f8HqU7cp2tfz2/8AB0l8LWsP2221EI6x+I/DVpqPnEDYHhLWxXnr8qqT9B6V/QlX5a/8HPn7KN78Sv2fvDfxN0bSJdUvvAf2qC+WJ8EW0yghmBB+VMSfMPulwSCoONG2mpIjfQ/l78RaPLol9PbOjRhXIHpjnBH4fzrOMnlyncAcDgl8DHqfx/pxXdfEWe/1qMySaBdQR7iEmyXT1+V9u09+Qcf15P8AsK6aRfKjC+Y5VS8gUuSegIPPTpXRC9rMya1KaymEdmHUZUD04/X/AD1qxakPkjY2AS2M5IHX+X6dK7Pw18DLm/bF3qMFnDgsRGC+Bj+JflHGOu73r7c/ZD/4JI/Gj47fCG81/wCC/wAJNT8RC8tprRfEOsWGlx2F4jl43No+qOsTNG6sBPaDzImTiQd25RWrdvzfojSEf6/4J+f+jeHYNQnabUNRj0axMExW4eMzPJIsblIxGp3ENIqIWA+QPuIIUgvtvFOgeE2uGstH/t68dF8m81hSiWrlVZitvHIVZkfIBlZ42TO6HJAX7/8AGv8AwbOft2+PvEl5q+ufDmXXdX1D57rUL/xvpNxdXLBcbpJHuy7EgAZJJ6elZqf8Grn7aTRuW+GOlRbdzLnxVpTcdei3DZPoBUrFQ3gturT/ACen6+YOi+v5o/Pnxl8Sdb8eC2j1XUri4tbFpPsloCIrSx8w7nEECARwqzDJWNVBPasE8mv0O8bf8G63x7+FXhkTan8OfiH4l1x8j+zNA0KeaCEYOHN2kcoYhsfuxGNwyQ68E+an/gjv+0to0Z8r4AfGFXwAfJ8Fam5cdT8xhJHocEZ9KxeMoyetRN+qb/M1+q1ktIP7j5KtPD08q7nBiTGfmGCe3St/TjDplmY7eG2LXAKtPNGryHlSApYHYQVyCoVuSCzAkV9CeIf+CV/7RfgLQ21HWfgx8UNGso+ZLm/8M3lnbx/7zSRhc4x17E+5HkuqfCfXbG5ZWsyZUZldImVpcIQfuKScAj8cH+7io+sw+GMkn8hewnvYreHvjT4q8DaDe2ej+KfEWj2Wo20lneWun6jcW0N3buMPDIqMFeJsLuVhgjPBrH8exNB4k8wSZa/tbe6JEYwWljjlYDJ5KuzLz029eK25/hF4qCNcL4b139wAXkGny7Iumdx2gDGO5H6VS8b6JImn6PGqMs9vZmCYBDwRJIVDcHnnGB0I7YrWNb3bN/11/P8AAz5epx7QtFIeQ3HyqeOvHT/P6Cp7jQbiBCfmPIcBTkfX0B+lOmhmtUAYOPQFMFvTjsOv0rStvEM1ogQxFT1B3nPTOAT9ev0xVTfu8yIV7mFPBsC7PNDY2yADjOcgfTGOveq4h8sK20nf3B5/L0rpoNStPMfz4TswC2H7DsMd+PXOavxWmj30bD7U0DMw+Uofm44yfUfjWPPd2GkziGyAcYwMfif8g097cRJ69+vTI/M9q7hPDOgs+RqhDSdAIWHr+lJF4T0PLFdVtwVOceWzcgZx0z1x+XsRT5u6/Irl0OJMIGVLDgkjbkDA7844J/HinC2SNo9yj5zhhzkDoemf5fywewPg3SrmX/kK24TJI5VexwCe3I/X2qabwHpiYkuNVhOFUKNnytgYGDz2GM+3r0PaR3Hys4F1w5fGB2IGMU+2sjcOCx2whwsjgZKjucdTj9OPUV3A8GaEgijOu7TkA5tiQD6e5/xrX0dNG8BWt1NZX8F7Nf2M1myz6dHNCUliKMGEodcgHcrbS6OsbxlJESRXGcbpvb+vMTXYyNR8d/2tfXNw37xruR3I3LuRmOT/AD4/+vTLXxBHb3ReMy7mky6s/wB71zwR15xz1rQ+CWl+GtR+IFnZeIdFk1nTr6QQTW9vrB0q+3bhhYboxSwwykgJvmt5YwJDlQw3L9EfG/8A4JZ3Oi+Br/xF8OvFyay2i6aNZ1Xwd4ptk8P+KrCzaS5Au7RWkez1iz226FbjTrmWRxPETbx7gKurJP8Aet9fxJVJy2PkPxXLESqRdPvErypP+OMV9of8ELfG3/CMftbzaDdTR+TreiTYCzCRSyxpIgBUnDBd+Rn5TkEKRx8M3c5mbk+3HQ/5xXUfA3xbL4L+JFjewyNFJ80SspxjepQ89uGP5471rCShJNLYNbH78+KfjRoHw3nkl1jVtN06G2JciSQbnBP8K/ebls8DHX0r8T/+Cl3xh0n48/to+NPFGiR3EWm3k8dtEk4AfNvEluzYHQMYiw74YZ5rtPiD8YL/AMTyXN5q2oSXToN8szsXYqB/h29O3FfLF7ePqF5LPKd0kzmRz6sTk1VSreHL0/yNGNWdljK5+UnOPehWAbnkUylB5rnu3uSSJL5b7lZkOOuaU/KOPSoweafG5Lk985rS+mgmjS0ScJcL8qpyFDOmVQHqWxyQK6WHxJFYpgmSaKcFgjhcBhnbxypGcA8fdzxnpxyHy+CNqscgn0p1zd+dNlg27GM5rspzcIpx3MXC8rl3VrsMrIpUqGJO3IAPbr1PXqPWqRYRwnenXBUgncOG4+hJGfpQ5URqoB6c/Nwx9RxxUWEKNywfICgKMEc9Tn6dqmUXuykSQzIu3cckOpxjqPr2/I/pTEbeW5+oJ5pgjIi3dMEAZ79aJD5k5yDyck56+tYyu0rl2XQ+lP2TvFT2FzpR3GNkPlHIxt2tjp27j1Pt2/rF/wCCRPxP/wCFn/sUeHZ3nE0lkWt8Z+6vDD8Mlq/kA/Zt1NoLqIKCdlx+CjjnA5xkn8/av6h/+Dcvxn/wkP7KuqWbyb2tJ4towB2fPTt8w/rzmtqi5qF+zRUb2sz9FaKKK88AooooAKKKKACiiigAooooAKKKKACiiigAooooAKx/iF43s/hp4D1rxFqO4WGhWM+oXO373lxRtI2M98KcVsV8of8ABa/43aZ8D/8AgnL4/uNReVZdct00iyWIne0sjgk8f3UR254JAUkbqOoH8wP7b3xq1H4//tW+LfFEsrmXXdSmuJD/AKzcGckA5OSR8oznPfNcd8aPC03gPSra1udR0jUGkG/dZJcIUX5dpdJIk5JOAFJI2/MFyuek+A/wpvfjz8ULuOBrmGCxtpdRubuwXdJaxQKZHlIOAQuMnccgZPONp4H40+NL/wAb+Mbi41W+n1K9eXY146/vZegyx/iIA6jr6DOK7UlGm+Zb7fr1/T5i62R9+f8ABtb+w5pf7TX7X1t4h1XXbWxj8KsNRSxEPmXF6YyjbQR8iggnnORg/Lzz/T5X5K/8Gtv7B6fBT4Ial8UpNV0vUj4shNjbJapJvgAZHfeXRMEYUfLuByeeBn9aq4E7yb+X3f8ABuW9NArD+JHw/wBO+KngTVfD2rQrPp+r2z20yMobhhwcHjIOCM9xW5RVEn8ef/BWr9ijxB+wP+014l8FyWxj0G+uXutLdgdqqSDtVuDgAjGeWQoepNfLtjoiXPhW8lEbeYsh2HPIK4PB7Gv6sf8AgvV/wTEs/wBu39nOfVNMsTL4r0FPMRoYt0siKCVcAclkP5qTnha/md8V/A3WP2fb3U9I8UWMsTJMSA2YzcKcKoQ4yNxOPUAk9qOyv3L13PTv+Cfvwo0X40fEL7X44vjpXw98CaPJ4w8a3QkVZk022Mf7iFXZN1xcySwQQKpYtNdW4xwRXsPiz/gpt+1P/wAFDPjFp9l4I8b+J/hhoFskWn+G/CPgTxFP4d0nQrBUSONHeCSKScBY1/eTFjuciNY1ZIl+ZdW+IV74G/Zz/wCFfWEk1vcfEO9g1zxA6OFeWwgLfY7YgBWEbSmS7kjJaOQx6fIADEGb7B/4J9/AGw8H/CrUtY1N7Sz1fXrW6trSG7tUlCQRxkKuJE/dl5mBIIIAt45N8YKlues2pe/5drpdrtdTfDwjN+Rymuat+2zoiiRPjZ8dJhlwjr8V9RAlZDhgolvF3Y9McjDcqQa6Xwj+11/wUF+DraVcWnxL+KMjSjNqNS1W0183QO0LiOdphLyDj5STk+tfVeg6vYwaRffaNMsreW2uVktrWOdJYLCGMQAgq7IW2xbAyKT5jRqWRBEmzM13w/po1fbpF5p1rBJbRyWSoI7aS7hzsMRdliWWT964LsSCsEsbblWNRlzOL5ot/k/xV3qvLdb7HX7KM1a2h86av/wWd/4KNaYYy/xG8YRiRVdD/wAK10cRyowyrK39nEMCCCCCeDmrfw//AODlr9tj4Lakp8Saz4X8bOoKta+JPCsFuCWxjixS0fIGcfNg9SK+lfEWj2a6Ra3cqadoNxdtdyTiOY+c8Ly3Eb/u1Vn3AtNGXfP7soG3MTWbdaNd6b4jZJSt1c6qS32wCSd3iR57d2jaSdGKNEr7RMOFAOYsoE3UZKVk+33Py0et7L8yfq8LHE+Cv+Dtb9qiLVUu9Z+Evwl1fR0G6eHTdJ1SznYHptla+mA/GM/QZr0l/wDg9Q1C2Plv+y+S6jDlviE0ZyM5ODpZCjjue/415+Phzo/iPSW/tWz0XXneBby3trqC1miuFBWLb86FvODEOFkGCrBcPkEZNl8APA8DTsNI0PRUMdxI8NtYf2cVTjB3wlTgNLGflJURnILMqxtcG5abLe7t/mvXd97a65vCLdM9Utv+DlD9iH4vxy618U/2Rbi48VztuupIPCXh/wAQ7iMZY3Ny9vI2D3MfTB9qz7//AIKR/wDBLX9qLU7i81/4eav8Lw8RGy50nU9IzISdx26DcTx7SpxtKDOfvDAB8b0j/gn58P8AxNHPeTWVuXMJu4728ubjUBdjcCPJVzIrMu4ySRMqyBHhAV2kAbhPFP8AwSi8IeNbxp7W71FbJBII5rey0+IDy0DjfDDDG24oS2GkDnoATxURp03aShrf+r/1bzsEqdR6KR6f8QdF/wCCaHxJK2HhP4kWfh+GVR5k8VhrJKMSDjzNatZAvKr8wHRjnq1czr3/AATD/Y58aaVnwb+0h4Ftri5VQDrPiHR7uclskJHb25smB9eT2GOePENV/wCCPOl+I5bKLQfEyy3V9BHJHaHSmEm94hIqArdylmZWXG1OpAcISM+ZeJ/+CUOv6Pb4g1XSbiVirW6JfyvPK2xGKKjWyAt+8AyXABUjOa2cYy1a12309Px+85vYVNos+iPiH/wQq07wF4Vk13TPH+heJrOMCQfaY59It51PZZBLehmI9FPOevGflHxn8H/hv4e1O9tNTsfFSTW7mMXGmarZ6pa9Mfda2spGHGPv9Bn0rPl/4JnfEPTrKS7FjPHMZMRRv5G5h85L5WYlQuxuoySp2hirBcLxz+yl8RfAtlIzXV/d7GHnLDY6pEkZIB+Z5rZIu4/i7cdRneLaTVtN/P8AzM3SqLdENx8I/hpqMMnlePb3SpMeYsOr+GriFWAzx5lrPeY7c7D71AP2bbLUoDLpXj34f6gUb5kGvjT5lXg8JqEVoDwRxnPBzjHHD3fhvxM1wU8qO+ZB8xt5opzxn+6xzyfeqHijwr4g8Myxrqui6pprSBTEJbZ4d47MMjkfT25rNODjfl0XyE4zTt1PR7r9i34jf2fFdab4a1XXrWUYSfSDDq6MCQMBrSSYY5HH864rxp8L/Evw9uwmtaPqujdHU6hYzWZlwcDiRRnH9PasnTPEIs7smXchLbn8xN7KOgI7gZY/n716BpP7WHj7w39kl0vxz4j0+1tyPLtl1a4CS7eOU3hAMAdBnnr6TaGrSt+PqF31PObm2nnBjaQyKqgDnfz1wMA98nHuams4onB3CYuoCsCqtwRhju49yAfoTxuPuN1+2b4o8S3Y1PV4PBvjWWMKrW/iXwzZXGVIb5xIsatwAM4kz8y9s1514t+KegeLi15J4R0TQ7qUsHi0C4uLaDGVKkxzGZVGcjCFc7cYHBLurafiv+HBnOAb7mOQN+8JwzLuJwf4j1GM7sc846Cvb7X9pnxpq/7P+peEVu5dT8L32EvtIlkcnd5kcjSRgfMCxiiL4/iijPYY8ag1Dw48Xz6jq1pNLiN0ks0liUE8neJAeOuQme2MV03wu1v/AIV54p07W9G1zSNTk0y8SZ7QzyWzTIG5VjMiL8wGPlYkZzjjIyUZSnfp1/4br6BFpKyPMvGGlPYaq5ZUCSMSrIMB+TnjpkHggcA9OMVn6WzJqMO0kNvGNvXOe1fVXwRjm+K+gD4deLdDu9d8DiYrpevxRgX/AIZlkJ2TIx48hsEvE52n7wYsgB4H4x/sbeIv2YviNbQa6Ir/AEW7X7Ro2sWgLWmqpngq38Lr1eMncp29VZWPRy9fv8v66Pr+AvQwPHV9JbeBrxtxQyMsY565PI/EZ6ds15VXrvxlNnoPw3s7GQK2q6lcregcbo4VDqOh7kng+nbkV5FSm72YXuTNYyJbiUqRGxwG7f54P5H0NRgL5ZOfmyMDHUd/6fnVzStcbS0kTyopYplKSK4+8pxx7dPzweoBFq50OLUIfO06QuON1vJ/rYzjnHZhnpjn2qowUleO/Ym9nqZkC5Devb2pXj+vvWn4et4tSnNo8WyYofLcHGSBkhh9BgY79j1GcsokLZDei49c1SjorBdjCu3Pc8UCTA/nimO2485/GhjwKXN2HYe0pUdT+dNDYFJjZSyr5bEAhhnAI6H3p80ktQ0JjPmFBtztPIP8qW1hW5v9jZVS3JXnA+n/ANeoVXacHseo6Ve0iyaeUNu7+nv/AJ6VTnKbVxWtseg/B+KO3vniRdy+ZwDJnaff346hecDgZ4/pL/4NiNT3/DfxRAZWkZ41mIJ4XlBgckD8PWv5wvhnpC22pQxj92NyhunJznr1/wAiv6KP+DXazMPhLxWxwNtqqlQehLof6fp705Sfsmi/M/XOiiiuQQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFfiZ/wdi/tp2q6T4c+C9jJHvt2XV9Vcr80UrpiBQSB0jYk4ba3nDPKCv2P+L3xQ0z4LfDHXfFeszRQaboNnJeTNJIsYfaPlQFjjc7YRR3ZlA5NfyIf8FC/wBqbWv2zf2oPEfjHXZ5bqfUb53hVGLeRH0SNAcnai4VVycKOOAaa3DXoYPwE+Den6/8M/GnjC/1d7CPw5DEsS2moxw3byTMVA8sjc0ZUOCwB2ZBKsDg8l+z54C0z4pfH3RtF1i+XSbTVb5YZr5oC4hDHG9kHp1+X06Gu0/aS1HwBoHw78F6N4EDXGox6ZHceINZeF45Lm9kGXt8NzthBEZGNrHcwByHP0p/wb//APBOqP8AbZ/alhvNUn+w6b4Y26ndbo2YXUSugKKRna53cbuOevIB2xNoRst1v6v+kv1FC7Z/SJ+xb8CNI/Zr/Zg8HeDtDukv9O0rT08u7WPyxd7/AN4ZNvbO7jPOMV6lUVlZx6faRwQokcUKhERBhVAGAAOwqWudaKxTd2FFFFMQV/PD/wAHQn7QPgH4gftZaJ4H0nTdHto/CJkbxFqumWcH2y+u5drTiRlfExiQLGqybWWV7hScNkfuB+3V+1Tpv7GH7Lviv4gX8lt52lWjJpsEzDbd3rjbDHt3KWXd8zhTuEaSEdK/j++P/wAWNS+OfxM1vXtUvp7zUNavXnmmmcyzO7MzFndj8zOxJJ57k9altJqTV7f1+Ow9baGz+zf8Mbr40fFiwaV5gt5OkMssaIfsEEed5AYeXlIo28tGwp2KnGQD+l9vp2n6L4bg0q2trFYdLd7e106W8F7HHbqjQLDEr/u2c/Z0wu0EkIhKhpFf5q/Yl+DqeEvCxllh09L7Vd9iwvI2j+ypujLF2IXywZgqOCxaM2xYDa53/QtjBBqXhdh9puLpm1NLl/ssO2aVQkQLlVUlVSMGSNE+ZSsg2IpO3Cp8EnfV7/n968vO+tj1aMeSKR0uqagthq8t2moiUx25kS4lhQ+fM0fmrufLKH8m4I/d5WVGJUKGzWnaeN18L+IbO20SyEs9pNBPKLuXyVu42dJUgkgJcyK/2ePkN5gMzSYb5XXmtH195fD9le3d/ew2X2zzLgPfwFoYZJAVNohK8lMY3n7wQoWZudTSIvsU+pNqmsWE11eTLqC2lxDcKyRL+95TCoWLKrngKVWU/vI97hUY6qdN2v8Afrtu+rsm1rprqa6Wsyy3i86Tqk1zdXiJbCabEtvF5jXi52ryM+YFkYu3mMXMbSJt+UkJq2r6pqSeb/aLwOytbtLb+WyWp3OrSxGNFYhy8iFQp5mTZwI0qv4l1O3d7ebULOCRYLaZJFVltlWRp2kAMEsbPGFXzsyvvYBt0jBlWEzabeHT9N1uZvtU9xeo7XWoafI0UjqkwlcSLKY1IVpot2TlGK5J2tVxbqy5INr0v2v+eitZLV3vqPVas1PhP4Cn+J2uwwwHdoslvPPFLNMZ2CoxRY5VMTW4JfBVVSJlV1Yh1G2tPxb+zD4it7R2sbuyldURJIFvi0lwhZAY1MluFVc75GLucjjBK5fuf2M9Jvdb+HX9oXUSxxyyCw0/MCLI1vbkxhmKhWOH8xAsi71EYHINfRVn8ALubwp/bLMkVuZnhCSl/MOxEYv93bsxIoB3Zzng4JG9GlzQV+v6rpbzu1+NyJSs7Hxvrfw/8RaTYyajdeGrRXRXmkktI7VZdMhQQeSIY4pzNK3yuJF3n7qupfbiuK8VRabrkt1vjYSSxW8dxFDE6ThNkrlFy6DZvNvAI8uzEO4U71Fe3ftga8PA/wAKpbRXC3Ov3MdtACxVwkbLLJKhHXaViUj0mNfP2u2WjeCPG8d/a2PlWdraQm6t7XVJbrzbqLyzcyeZMZZIysv7oxlzmOEtj5/MHLWjHncJK/e+tr3XRfO711snsC0VzvNKnRdFnt9PvrKA6yGjtpr+7S2MbPGku1CZFb7HI4nZJWXMqvyYylcdd6dcaXJZpf2ttDdXpTVMRwo41LG5YpCDlQCJHhkUMAzxyEvkhq+5/wBlr4IWk37PVy/iC7hj1GHS73UFsA8MM8l39ne6ZZIJSW8tECxsFUscLzhXK3/iJ+wL4JsvDqXeoRaPb2ARxr6WtjAzQXgWASRKIJk8xxNdEFZDEymFpPmIQnOeLp0rKbd169dXtf0utlfdXI0k7H5qS3qWEFxaPaJN9mhSKFFYsWjZw65bBBJZOd2Qo5+XKVL9sg06axW2MFrqFmZbqKS8RvMfef3KxgKN+whSpyURuSfLV2b2r9pX4C6Rp3xJs/DXgTTLWHWL63n1F0S88tNSh8xo1MK3Mg2kolwWi3IpjJyAAxrw20n01bs6z/oO23JvY0KwqZ41l3Pv87zcRlNxCOu05VmUch9qk5Xco20/JO+mzutP6ZTs/wCvkN8T2FtqatZaimikqfMlVIIZIVlWCJo+AohlLEliqglhKhcliyjiJfhJ4Il06WPSdC0eB5POtnms4ktbyWUSDyzH5QSQ/KYwWOfmJcIAHFfZniX/AIJe+PdJ8NabqMy6S1rrBSSNZfMg8mV43jlgV0t33N8oCqXIXY52yKxVvHtX/ZY+JGjzxAeHtOkeG4Est1FLZBg21SQsTMofGwKQ6nIySDuKnNVUpOKerb9en9XW/wDd2BJtabHy5qX7H/gG+S4zaalok8JCNcIHu5JWZpCibbkT4LIjgcAZjAOAd54vxZ/wTa8PTSyrp2tWXlx5EkjWyalMzDczK7K8KKVVckqh5bHZsfQ3jLwfqHgHxLd6de6X/YM8iefALiOWCZ4m81PLKoWGyWVFAXlVaQEHyzms2O4ttatImjJed9iNEp3BmYKkbqwZ3LFQHPzEB8oq8EDRSah79v6/rpv562Vk9z5N1z/gnDqltcNFC9iLWNd253njndGIyojCbFbnoX4BOTiuJ8WfsA+MNJvL3dp+piO2m8hYwwurmdiwBAit/PO4bhuBOQSR7V953lvcgWgO+y80NIsz2arI0YXZlZI1DNlgwbH8a7idzuRY1axttK8TJbxMZsiUOHcMxuAzr5W1UBVs/KFUHB2ndtIKnNa/quvfy+77jJ0YM/MTxZ+zxqvhG5SPULS80+a4AaCG9tPJnckA48skP0wR8oJBz3rG1D4QahoLwG+tWgW6i8yHfvgZ1yyFlDKdw3Kw47qR2r9YdDvo7aKNLh4tzCHyYrtkS3iD9fO818eWzvF82du1W3bR/q8qP4UeAFtdRi1LwhpELXcIE5s4JLK5uHI4cyR7HG5mCfL5iKYpCVYMrHe+t3K3r/X9Ih4WD0Pyph8IXVleo9hcXFtIr/JIG2+WemQytnr6AVuXnxu+IOlaNLp2o+Ir7VtMnwGs9RnF9ESvAdUm3FWGOHUBh2YcGv0M8TfsEfDHxNaie2mvdOs7dwZItJu45RGhUgySyXGZtiyYRmLRqvmRHLeYhf5M/b2/Zntf2Z9QTRhe2upPd2f26KT7LJbzWu26mhK4Z2DKwj+/x0KgcF5GqkovW2na/wAu5jPDpJtdD558R+ILj4g6ybrUJQl46pEr5xCAoCqMdVAAzkZ57c5rDvbGXTrhopkaORDhlYYwa+xPiJ/wT0sPCv8AwU+vf2fNH8TR+I7e2+INr4Ft9ZWJokmmnuo7XMq8iN0kYo43EbkYKcAZ+YfiFqdt4v8AEmsajaw/ZzNfTXUMatkCCRi+3k7iU3D1JBOSAnOkX7Rcy1vrf/P9O+phKm4aPpocpjFLHK0T5UlSO4NIW3GkqOpJ7B8AvHvw71/xRaab8WNN1ldHndLdtf8AD8ywanpqvLArysrI6TqkKS/IU3NvIDAkMvvPiT/gjLrHxW8NN4m/Zu+IfhT9oLw8LaG4l02xZdG8Wacz2puDbzaXcSES3A8uZBDZT3UjGPOwblB+Jq1PB/jDVfAviCHU9F1LUNI1GAOkd1ZXT20yK6NG6h0IYBkZlODyrEHg10qtz25/v/rcFZLQm+IPw61/4TeMb/w74p0TV/DfiDSpPJvtM1Wyks7yzfAO2SKQB0bBBwwB5FY4O6vcIfi9r/xS8JRWvirUZfEkURRbf+0lWfyVjjEapG+A6AADgMAefVs8RrXwp812eyKKrHpubaM9AByenqaXInJ8j0XfQWttThcZp8UeRnjA9TWrc+CNVsGAeymYt0VfnP5KSapT2NxbZE1tPHg9GQrjt0xUqKTvICq75/Cug8KW5nEKDjLZOO/XvWE4D4Cg/ic10nhuy12e3WKx0medWwquIHIU5Bzu4A7deKqKTb5g9D1T4b6YZtQiO3bht4JUZUd/xHHP/wCuv6Q/+DZbwTPY/s8+KNZ+zzCwnngtbe5aPCXEgUtKq9/lBiJPQ+YOwBP4qf8ABJj/AIJIeO/23/jtoVj4lvX0vw1DOrXNvDiSaRVKvkhQY0G0Md7bypAylf1efBH4NeH/ANnz4V6L4O8L2EOmaFoNsLa2gjHAGSWYnqWZiWJPUk0qkrR5ev6F6qOp1dFFFc5IUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUVwv7SP7Q/hr9lj4N61438V3iWek6PA0mC37y6kwdkMY7u5GB2HJOFBIAPzE/4Oq/2vrz4d/Brwr8NtE1mOKTXXkv8AWbOJysgjXatsXOPulvN+XPUKSB8hP4hfAy9sPCHjvTvF+veHb7VfDujyfaLtHHmwSTgAqrqChMLPjeFO4KWPbnrv+Cgn7U2pftt/tT+JvGU01y41nUJJrSGWTf8AZYix2xDPVUHyDttUdOlc98TfF/iD4X/DHTvAup2dvpzS/wCnXSIGD3hYfuzLG/3XCgEEfKyuvRlYV00qaXvvp/Vv66edhO+yPPvF3iKf4t/F2a6NvAH1S53m3tlAijUn5Y4xjAVV+VRjgAAccV/Uh/wQz/Yg8O/sm/sdaPq2nW17FrPje2jvr37XEqyQIC2yMEDJXktuwu4FTtXGK/Fn/g3u/YesP2uP2qLaDxN4cn1HwxpCNqE88RMD2YTlVLgEFHfYrBlLYICsmTn+nXTtOg0iwhtbWKOC3t0WKKKNdqRoowqgdgAAAKwqT55X+/1KUeVWJ6KKKkQUUV5p+2D+0dpv7JX7Nvi34gan5TJ4esXlt4ZM7bm5b5IIjt5w0jICR91dzdAaAPxh/wCDrD9v3/hKPHel/BfQ9QJ0/wAMgXWsCJyUlvZF6EBtreVEQo/iVpJ1PSvyV/Zy+G1x8SviVBPEPNhtJFO6dA6vM3IjCtxNgK8jRAh3iimK8rwz9pf4xan+0J8bfEfinV7mW+vdWvZbma4kOXuHZyWdu25mJyR6+pyfpL9l/wCHSfDb4f2Kzwhb/UoEu590uIrgzqso5VngkRLRo/Lc7Xjlub6Ngdu2pS3lLZf0l8/x1Oiik5eh6/b3dhpPhb+y7Y/Z7ewitUe3ub8OLqLapLSoxw5LIC26QOUKEZVS469UOtGe6vZ4NQup5di3siCKMNIxiM5kJ2AhUaTb8qBE3NgKM89pGoXosPLaO6u7q4AMcd1tZY7ljKWfDgM2/wAuQlSWQiUMQSkexbvxCuv+ebye3jkSO3t7eeCwinVJ0DyRlAscYRNzsxXa3yn5lbBJ5ZNRfNLr6JdX3tp00+49JHR+HvGc2m20VvZTTQNJAC92hmjjRceSgfYxxl3bKqm/dMRhmKhbuheJYNYvYoBqFzb2MQXyltRcSJJNHtDTqZHQI4ycMCufLADeYzPXJ3eovJpcVg4eLzLeLNvLOZJUUM8QfaSGUfO4WL5fmkYkhXDV0b6vpmtyW7LE0+oRXdtCYRHJ5exlUJ5W0l33lAGGcsNuEYxlnulGUoJTadv6dtfn5vfRBpe5u6LNLptsEkuPItC8FykkV01vDJb+RI/ltFHtVZds1uoXIZDJIvmB5Fri/iFrFr4R0iS5voDD/ZkE13d2siG2gESq7BVyDIAqsVcMqnbCNzFiHjl1BbCS9jk2zTxPKjqphKPeNIoQKDtwG8wMwCgKEUnII2vN/wAKP1D486Hq+l2emQ6y9gUt7zyr6KKPBBAAO6JNhMePkBDhT/d+bJQjdU4q7T06+fRa7ed9S276s9e+Cv7f1l4C+H3hSy1/wndWF5baTawXphulLxSLEgKmJlUbgR8x8zk5OB29f8Sf8FcfCnjjS7PTWXxNYW9pAtsqPZRhWUEsWJFw+WJZieAOmABgV+ePx+/ZY+J8vi26a30TxNqh+7LLFpnmxvtAIbdbIgwAQMlz05OcgeOz+FvGfg66aG8/tCGeIEvG0ktt5XJ4IYSHse3aqniq0ammy0/Tp1+8zai9WfeXxo+NFt8W/imur2bTy+HPCdkLuMMvlvIkQ8x22M2A7ylYhzyPLz0xXnvwN0+08b+NfC+jeI9WtILPVtQkv7/+0CIor5gXuWhPzKA0u2YAqMjzj1zx5P8ADv4h/wBoeBH8KRjUptU1u4tzdG8kinjKxl2WOJkjjkBabyPvAg+WOe56HxnfjTviTDA6XKR6TYj+z4Xtpnhu3kGyOYvGri3kFvGAS/Lpcg/MAMKm3JupJf091p5JJddWtyn0SP1e+Gmjv4i8V2Kz3+i6ZErJdG51maOOzZVYNzvGHycYXnOewyR7H46+N1vp9xDZ2Ny66nDZwWcl3b3MaGZdiklfIkMUUZ+UlI2KAr65r8B/+Gw774a+JN2jambO+Vikn9mawiS5/wB5XQ54/Suy0z9vTxv4lgOnnXfHd6+po1q0Ek91fNKsgIKdWzkEjj1qo4uDqOpOO3T+uv5GLp9D2r9oL44weMfHXxB8a2mwWU6f2LoqHfGzxzK1spj9JPs0dw7DPDSZ6kVk/su+FP8AhYfx58FaPtM1vFdLr2qyJJ+8aK0aG5Bk3AM8ZuxZQuhyMXBOM5rhvizJNp3hbwl4cxNa3E6Sa/qEErkr5kx8qFXjOGjkWGJdyEAgzNnBrqv2Yvjzb/BPxX4h1ebQ/wC0/tccGkWjNOsEtokY82aWNljYNHK0saFMDDWQGeKMPeF51Ha7v89/Xsv6uaPsj9ZPCXxrt/EfjfQrIwQwGFrd5Jbu6V0M1rbvHZiNGaJUQSuZGQyZdmOHUcHe8CWniW48UeLFsYNYm1uZ4tOt7m4eRZdLhhEpkRXe5uGI88odnmujbWOQG2j4t+Bn/BT74b+E9ctrq+07xBaatZ3KXVtqD3DW6RFQwaKRYTKZYiSu5dqMRuUsVbbXUeNv+CsXh/RPhzr48MeK7KbWr+KTyIYNOubb/SJDsUjzIkTapYNgdkx3rCNGh7Z1J6LV77vyV/yW/mRZ2skfM37RkGl+NfF/j3xCLJZNV/tiHQtC1OK8m2CWCMpITGrhGSRYIjyhI+1ZAOAB4NqNss9+bXT3uL2S3jEN6JLFLKNZVlba5RTjaAUxkZLHkE5zvftBFdJ0TwP4bh2wvb2w1S7mi3pKJrkhykoByGjhjtgD6E844qhctba3Fa6pZXdjZ3oupHt2mjFshGd0TJuBURpJuDJ8jAbWBk+Zo6w+ivPrr9+9lp1e+umlzapa9kZrxmyurgRpJtvPIlt/OgjdtmTncrcByqbuwbYCcZFbGgaN/a99DaPpiTXZtFS3QSvbHUhNIxjBDuFLnchjTYvmLGMo3WltrmHT7l3gXTY0BFuZJsYnU72UuBMQfMZXVyMsm1NrBmCNYGnefZT2vk+el1OCWa1jLtC5EZMmJHKneyuE2mQSA7mZ056lo1fVL/h+vn5P56ox9Co80N9bxXLeZbwh5QJ0VHjlkAQlgpEeCz5O4ZEXnKCybcmzpmtS2+izpZWn2a4urWS2htLXzVCxTRmJ5Qy53gk7ThgzFFDFsYVH0qe3mjS2bTUjugGtbmW7SO2dnWR1ZnYqIxgH5shQUKvgZWrmsXF+/iOCNIbtJp4yksMibLq3SEgmUFGeQOFLM/AdvMlIDgir5tHN+j0/L8P+DZC66E2pzXWpz3267SaS8ENlHE2qwhpizukS3KhYSFRY3DO6KUfychVk2n5T+Nvw40n9pr/gqb8JPhTqFrJB4f8AEPijw74Y1AaZlJRbXlzAbxlZgzfK15NtZ92FVc5xX13oukz+GtIuJHwkIlFhcTSboXimdgyE+W+UdfKA835lSUpvLYjFfGP7O/xDa5/bk+MvxY07WJNP0/4ceCPFmt2l8M/aoZ7+0k0PSzEVziVNQ1jTW3Z+QKz5+WpnOadpu738+r+6+/mkS03HlXoU/hZ8Wf8Ahf37Z/xG+Nfmy+EdUv8AWvE3xU0NxKGGn6lY2Wq+IbOIbiNwa7s4YskZIYActXxIY2h1O4RiH8olCc8EDjnHsK+rfh3o2neE/wBhrxvfahp7S3PjaWz8M6LepCMW199vsrpwWA+VGsob9X43kugyUZg3yvNZSvcy5MjTM+45OMnrn+f8+xx0U48kF/X9P+uh5s53vb+v6/rczb2L7NcsnUA8HPWoTXsHjr9kvxn4O/Z3sviFqmhz6bpU2piyR5pP300UsReKQRYyseY5PnYgEyx4zkE+P5KmqqRs7ErYM8VLZxGedVHJJ6V+g/7NH/BHzw5+098EE1h9f1jwlrRKpDcxQJe2kqgfMzQMyMzMTjckqoNudpziuI1j/gh78evAniWB7Dwxb+PdLVomNz4ZmN7Luc/LGLVlS6dum7y4WUZ+91xpOhKA1d6nhOkaWLHTrW3VV+WPLYHOep/XNWl/cT4f+LCk8HHX1r1b4o/sifEP4RavdWPiHwhruk3FrtWeO4sZIpIGUA4ZCAVI9CB19RXDv4NvLNsTWtzDs7bCGUexxx0rJyctDSy6mdHZ+Zs+Xec5AAweB0z/ADFSRadtPygHbhkxxnPA/pWrHo+wD93zjIyNp/X/ADzSvp89w6rFFIdygEBSc/Xt0yfam49mF02UoYHuXWNDJ5LEksW+99ecd/SvWf2fvhJcePvF9nY2kTXcs7qgjQDknjrnHtVD4Q/s8eK/iNqcEWm6ZdtI7gJ8hHPvx9f0r9xf+CMv/BFXUPhLqNv43+I+mzWk8QWa0s7lAkjNk8bPvKB1Jbkhht6kgc7y1eiK0SPq/wD4JJfsS2/7L/wHs9QvrNYdf1iFXbfHh4YyP03dfccg4NfXVNjjEMYVQFVRgADgCnVnKTbuzJu7uFFFFIQUUUUAFFFFABRRRQAUUUUAFFFFABRRXj37Z/7cPgX9hb4UzeKfGt8UUgrZ2EBDXV+47Iv90fxMeB7kgE8wPQfiX8UdA+D/AIUuNa8SarY6Rp9urHzbqdIRIwUtsTcQGchThRycV/NR/wAFcf8AgsP4s/4KCeO9Z8L2GpR6N4DsZmudM015HEUhhSQDcQvzSurNhiBy5GQuBVP/AIK3f8FUvEn7f3x4T+zb3UNK8E20Ak0bT5G8sCPaA/A4LNIrAv8AxbRwAAq/Il94Di03WTfXdxBY2GoRT3dkk0rPIzxYzBwpIb5sjfjdgDOevRRp3fNv/X9feg23IvA/hg6boKeJmuZLY2TtJYF49y3EyYym11KOFJTcmD8rc4yKzH1LxH8YfGUGp2xv5b1LhGSaJ2MltIpBUI2dw2jG05PQc1JpFp4j+NXxDfTdHtp9Qvdbu12WdonMtwwCBhGgwXPAO0ZOa/ar/g3H/wCCWet+E18ReMPiHoNm/hu/h+yLperWazi+uFKssixyAhWi+bEgAZS7KvDPh1a0eXli9Pzff+v0CMXe7Pt7/gh38D5fhh+xHomrav4Q0jwv4k8Shbi6lsrf7O2pQKoEMzxg7I85bARUUjDbctuP2VUdrapZW6RRIkcUahERF2qigYAA7AVJXKvMbdwooJxVW61m2sv9ZNGvflqYi1X4gf8AB1v+3bsvNB+CeiXn/IOC6rrQTk/aZIz5MZBAIKQtuBBw32rBGUr9dP2gv2qfCn7Onwb8S+NNcvok07w3YveSr5io0xHCRKWIG+SQrGuerOo71/Ih+2H+0Lq/7WH7SXiTxhrFx9outZ1Ke8ldQQuWdmbC84A7AcAYAqZ7AnbUzP2avh8fHvj0z3Nn9s0vw9bLq+oQusixXcayxxQ2rvEPMjFxdS29uJAMRG4WRsKjFftW9uWm0qWe+vIdQvBcvJcmO0jgN9LI7edMVEYjSYyvJOVAXmZSpI3Y8c/ZV+F48PfD+C6n+W81JTqVwBEshgVvMgtYwUIkjk2yXErwyApLFcWEigkLXqli8jSC8dpNxjKhflXZvbBUJlgN7EEgLgKzDG3OzOaqOKgtmr/5fd5+fS56lOKSNibXHTTpLaBYGtrc+bbSOhUiQBd8ylnGWeMwFnBOSiBgyBXqez1R7CKa1vIpbeC2fbEzuGCHy2XDE4cMr9FPA2FAsTBs4EUv2KzgiSaCRsb/ACZE/wBWRtb94AMNuLnKvgL5RPKkbrF3bRx377ntDCHkU7Izti5b90VbJADZyMPnbjORWajJPR227f1/XyK5kzb0tQ97c4hlWL7KyzwCIDljEVBXgMSzqQe4RQwIGGvaS8EmlS39zIsV5F8iFncSohSTzJCRucMpZAuMjLHhTtzh2M0t4zSKrQXE0O8mQD92YwJnZN+ZI5jtBDZ/jGCFbAEP2KRLVfMR1ZIlV0CF8sCyu3XgjHXnGTtAK0tVrbvp59P8/wDhx3ZuahqllpFhd+WEYTxQ7p4m8mQo+yQxFMDe6sBuG0tuG/duKs32h+wLosHgr4WRX2tQuuo+ILcXUE5SN5IQZYijbyr/ADPapJsco5ie4UhRsG34Ql1TS9P1uwttUvL0aVd6pb29zdRxGOYQSzxxBlG3BlJkfGA3z5zzk1+jnwp+Pfwuh8QWsc2vaJNb2uxpLJ3k02IJ/wA8hI6oF4OBtY44x0xSdL2kZQk7K3Sy3vs+rKTtsd/r3hfRNT0C+uY7VjNd3N7NYXF5FHZQSSTywQpbTMipEjwRF7nKHylMqqfSvln/AIKC+JLKCb/hDtBGzS9V1xp4YbK7PnG1t98MOGk81SZzMTuO5d8TbRtAA+q/jX8dvD3xbi0jTtCvbSe205WESf2nZyokkhDMqLCqJEq4VPRggYhWLFvzx+LvxWXxb8VfE3iq1K3Wk+FrV4dLaSFpIZvLbyrftuQS3MpmGfu7iOi1yRpunTUk2nL8O/3Lfp1SLTu7NHEeKfDeneE/iFqtjpUlxcwWEr2cU89qn2ufCtFKW27VctKJgGVfuhcA4NfZ+gfsF+F9f+FN1DPpbtqej2UH2qa2vJszXMksUZWKPd5W8l2dVEeCsTcda+VP2SPBM3jv436FFKzNb6Go1e7O4AssJXy+oO8GcxKwznazHOQTX6gfAZD4q16w06713ULODRz/AGlpkC3gVHvFlXykUyq6Kd0juSyMOZOPnY13vn9nKXVbdbelzPZ6Hw78d/8AgijpPhfV9Z09tc1GLUtMh+16iDPBepFE1wkCMyrHERvaWJgpO8pIrFQDXy78Xv2Fz8GvH/maXrM+uXMdj/ad9q8NpJaz2TN5irHI6yMVz5Q+cyDKuDxjFfsZ8Y9Kn8I3+pWUthaXkWpJZ2wXU7mWS6iNpAbeMmSCSMM397dlWKKSuRX5hePfin/a/jTx/wCKbe5T7HfY0iwMivB5yzAwQyZX+OO1hkdh/eKnAOCM/wB5TtKuteny18tflffa41aS0PFvBXhrXYb24udUnvJppygF5e3kk01ztXAHmuzOwChQeu1dgGBgHv8Ax3+yD8S/AXhmKyj8NX0s4lubi1mGnyX09uJ5WuHRZLSRRGu52+8CeFznrXTfsweA/wDhLf2ivCOj+TdW8I1D+1LzdH89rbWxEzB0A/1ckkcVu/bN5nAyTX6v3PjH4c3Wlql3o0c15p0MH74sP9IiiRr6aMKwA8xpYmtC3XbNGEO1mFGJfJS55JtX2/Ht/lr+EqWtl/XQ/nb8YeHvFmi+IXhfzbW9zkpc3klvJHk45R0c9fU966T4QapqOj+OtPHiuLxLd6dHcCWeGwitJGcRneV3yTw7fujJ2kgdq/enVvhT4P06S7j0i9t9U0VbaSG71CHVyj2jw2+A0MRk/fSS3AdgdrxsrKq7Cskg/M39qrwHo/i34g+NdTspLbT5vCs9tpyWy2aQm+nYeVMpk3DLrIt1nMb5VQCcYxw0pUpatO19rr8NXfb8tHcvlvrE8w8R/ElPjF8UvEPiSV/sEs85urY3yYQRqyLBGVTfudUWJCoBXcVLEBM0zW7OO91OX+zLiVmKmdQMF2DSYTyyowGEflBueNjglcbVp6boGm+H/ON42+YkSMsF2JYZkcEqHcRHywpYIwD5G4JnK7q6Cy8K/wBsR2l491bPZS6i0E0ZuYfMG2PczSRCTKh1iYcZKKoyx/chvRppyXs0r/ffe3y+7zZDQ3SdeGq64NTaW5vLTMuyWUieRd4mfgSLhT5kgOSMDeG2sznOiNHk0yx8wjUIPkxA+5NsUYXbJhdgchkYFtpVSBzuC4VNG8Px29+0drbmY6fB/pUQuFlKyK7s+WBAEcRA37D8wbcG+YsnQ6RqUt2fMeGK4sNklrhrkNJGJPMIUSSPtjbbcMPlV0J3SPGVjkJ2vLlTqd79fJPtov0v2J6WMfTNGXSIbJthnt4ollWOKTfKq+cQ2AoAVwefvDb5kbbgMg3Rpkdppxt7hnS4iZvtVtDuRXVi0sjosiLl1CpESSyY2KW2PmrZ8Ux2Go6pa3VvejS7e/l+0JAW85R5UiShsfIQqqhR3JKGPj7x26OmwSf2MzsdRsv7KgE1wbmVjZLPcO8B3uG8uISMYW2uyqFLLuLYQxTlS5Wr201/XyWnn0sU1bcxtX8cy/DH4WeJvEekTi3vdO0S6vVKxMtuTGrRxvslXzFbd5sIl3EIWRU2ySIy/nV8K7ybwZ+wT8aPEkS/ZtQ8eeJdD8D2tw6g/b9LjF5qeoxQg94rqx8Ou7LhlEkYJ2yHP2t/wUq8Z3vg/wDY71mG4g1trW9+yaXp8l1NG0FlvZL/AOzLt+YmJYHiccFCcMiEug+LvHeiXWlfsn/s8+DbSM3Q8VP4g8fRNzlZNQ1BPD5tCo67T4ZEgI5P2sj+HJWjem1l5Wd9dNfvu7mFWW39eh6x8fdMuPh7+xt+yd8N4J7ie28UjUviReW0sYimWSSU2UGDjPlBYJQu7BzvwNhVn1/2Mv2HtC8IeJ4fEWvJFrWrwFZLWJkH2a1cAAMqdGYdiw4OGCqyg1s/t9aPYP8A8FZPEfg7RJzdaB8FPD+i/DrT3JyP+JfYQwztjcetyk5IHO5yTzkn2n4R24XSEII9TgEnqf8A9ddvtHJKo3te35K33L0ONRsjp/jJ8KLT47fB3xL4KvNiwa/p7WyySMwignDB7eVtvzEJMkchA6hcdzX42n4A+IPD/wAXrPwtq+mXVnfNd+RLFJH/AHWw+MZB9OO5xX7UJfrHa/3vMH93kNnj6/8A664/x38P/CfiXVbPXbqAJ4hsrpLjPl/8fW3oxxnJzg/XPqBU0pSunUKlTvoj0X9na1svhB8K9I01iq/Y4ERmRiBuCjcw9OQTmvof9j742Wul/GPRZX5W5vo4SrnKtlsEgevTPPevkPTtSk1mNTMx2nhVyxVePw9a9i/Z10i4k+IfhhNK/s9bhNTt5p1vJmiRbdJVe4wQrHf5Ky7M4BbaCVGSNYVJ1KnL3LUdLH7QX1z4S+MHh57HVrHSdb0/OZLW/tY7iHI45RwVOK8o+If/AAS//Z0+LGoJd6v8MPCzy7RtFkJLBMD/AGLd0X9K5Xw3rcUlohiLxRnCIM434x1xyevGemPetObxHdQ2af8AEyukIIkVzKWCegGSR6g49q6p5Y94u6Mddkcl4i/4IKfsw+JpS8XgV9PUn7tpqEu0fTeXPWtTwj/wQ1/Zl8Ipx8Oob9uz3V/cbh/3w616J4J+KtzoF4sc15PPDtxslA5/iyMKv079K9W0Dx3aa8cRnnvz3rinSnDcNbaHPfCP9lv4d/AeOEeEfBnh3QpbdDGlxbWSfaQp6gzEGQg+7Gu+pA24UtYkBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABTZJBChZiFVQSSTgAVzfxX+Mnhb4GeEpdc8Xa9pfh/SoQf399cpCJGCltibiN7kA4Vck44FfiV+3D/wWo8fftw674i8D/D6Wy8FfDfBs9XvdRZYjDGp3iSafaXR2MR2xxDLZ8sLK2c1CEpvljuPpdn3V/wAFC/8Agu18M/2UfA+pQeDtRsPG3jK2k8g21uzNbWQ+bMzOABIoIH3DtO7O7AwfxF/bp/aK+JX7Y2kad458c+JrLXNYgc3Gn6JD+9mTTRG1zJLIqLsihA+YA4OGfAAViOJ+Eviqzl0bxB4d8Rx6LYX1zg6n4h1WH7dMLJjE0S2sbKfKkzuZpF+dg4AZQrF/Pbf4rH4d+E9X0Lw1LIsV3qM8bXEyqJ7qydQIkLAZAwJN68A+YuOr52hTg4833+vpvp91++xXoanxPfRLX4aaJqs94sviC8Iv9L06GVzaaTaB33RMHJLI5JYANkBcnJfjidZXVPjx8UWazimMmpztJAjSGV48kYUsRliMYzgZ6kVZ8LeAtf8Aix4os9Kt4bnULshILW3hjyzIxO1UUcklyxOOSzsSSzHP7Tf8EiP+CCx+Hni/QviH448u++zRLdQaPc2+IIbg4OXO4+aEycLgKSBncMhtZubi7aLT8NP1fy22QJdWV/8AgiL/AMEHPEvwb+Kmj/Ez4mWq6Wuii31HTbJWRpLm4G2SMkAnainBOevAH8RX9nqZBH5UYBOTjk+tPri66Et3Cs3xD4ptfDdo0s8gG0ZxVjWNYttD0y4u7u4gtbW2jaWaeaQJHCijLMzHgKBkkngYr88P2zf+CzfwM+FH/CUwDxqvifVvDtkb9NM0iB5ft7BgvlQzkCFsBt7EPtCBjkkYrSnGMpWk7C16H0p8Wf2pJrQNFp5MeAckdQe1eDeKfjhreu3EjPdzkFjkk7fpjt6V+a/iT/gu/wCMPFnh7xZ4ig+G1voPhdtOnh0DVbvzZ0g1MW7zwpPKAsUhcRvtjVQxJTLY3Z+VPi3+3R8Z7fQpNW1L4v6fqGqeMLG3hk0jSrgtb6ZaXUTB5WMYFtbyjMQKqTIhlJPlshFaOcLaLR3/AA/rTvsVtqz33/gvv+3Hc6xpnh/4S6LrUkqyy/2x4hME+VAR3igtXKsQT5iyyPGy5Vo7dv4hX56fAf4df8LP+JNhpbyXFvYN5tzqN3HbfaJLGxgjee7uFjyDJ5VvHLIUX5mCYGTXM69qsniPXp7rdLLvyMyYMhQKEXeASpYKqAle/NfSf7KngOLwt8Lb3Vbi3hkvPFlwtjCGKFreytZY7h3I4ljaW7W1WGZMq62OoQtwSK5JPml5f191/wAzajCMpHrLX8mondPatbMscby2kUrXA0+BQsaW8crje8UECxwJvO5Y4Iix4Obdl/xNIxFCJvKhkj8mWBiqrL5bMi5CEFj5fyrgEZbdk5K0Hu47dUEU33cGGRsM45J+bjcSM5PI+6vB6mTTPtLFngBIihdJfsLbPNVsgswJHyHjPQ7ex24EaSlb7zu30LelOk9zFtht5YpWZZYRu/iJJSPJZiwBKbgrFcLhic1cRPtF+NPe3hknSRU+aQhS3zkRMTjO/KqrrIAoTjO4NWSJfMhuGeTyNzNJ5axlnlbfkYHCrgnBHXKtxitprmB7NULOkUspDmG6YsuyQZVQdwI2Y27gA5MfJ8ti5GMai3Vl/Xnb5/IL9CaW+t7ZFBispZlBl86JD8j5Vgx+9ksARtGwbWwfmDAusZYxCYYBeB/KKmIK0gaJU+ZmG7PDIWIAwO4XaAtCOdbcxSvJFLj5THPAzPAEwFGcbeCvGzaTht3UkSXOpSwloGY+RGxcBiSIlHICbzwgGcjksBjAOazfKnd/h/w/3+Y/IpeJfDdxqfiLRtRMn2lNNukuJY7gq63DujsqMGaMhxIyOGxjfEM81xPi34469oevXcM0GYLVvKiSNvPDAHoWdI2JHGSSc4PLdT+pX7Mf7PHgHwZ+zvptz46srEXdw5+zvLaB5/NRTPPlTbTK7obiBArtCpAb96CuRteK/wDglJ8N9a8XaRpl/baGNUayla4tbWExzxvCIlIghs7jE7edJLGFkSJ/9GmO0hcV588XTlL2MrqV9fy10v8Ap8rmsYSirn5R+Gv2lLm4nRLmHZvwqqsEq7fqVEgHrXqWs+JdOTwHpekWN7pN9e6neG/1KSxuHYW8cSbYIJCyrkFpJ2IZQQQuRjBroP2n/wBkbwh4B8W6fonhC4vptV1FZrmZbm5xayQK5ETwZjWTc5WTCy8naOhO2vNPh/8AD54NVigs4Wu57yRIYoNyuWZmA2AqQGJPHBI547EdMKKb3/4GzFeSR2Xwa+NOufDDxTrer6RfW9jZeVHprzC1W5V5T+9dGVkIXajQsrf9NDnkCvdvAH/BYDxT8NJ2s47vQP32BMYppbeWU4IDBlk2qwy2GC5G4461x3j/AP4JteNvBHhya8tjFZHWbX93LDNd6bJfttA81JiqiQKAoBL4wM8fdHzT4s/YJ+Lfh5JJn0XVXVSQrw39tqLyDnkRq8j88dVz6+2tTn2g7rqu336EaW2PtL4rf8FJJfif4C1LTbXRTZ3l9bm0Nw2qCdIUk+SQhBGpHylsEscdcZ5r56+Iiyad4Q8L6UDI0d8za/dYfzIXaUiO3xjJDrDECU6/6R7ivAfDnhvxN8G/FWzWtJslvrbDy6fr+kTo0eRkCSISRdiDhlIII4INeq6R43ufih4zuvEOppYx3U/lqUt3NtBGUjSNNgzlVVUXqwXcFJwDinyVKs0p77W/Hp/WvyE3aNkfSH/BPzXPDvhzxh4m1rVdR0+y1OKGHRtOW6HleREcXFwRMf3bJIWtOp4a1OCe36Dfs5+L/CuLXWLttGub631aBxNfw3F5Z/YhkStb/Z1dXuQxBHm/KCFIyclfxms/iJ/wjPgaznktrvS18ovLFd2ks4LszySGEwB8RiSRwpYAbcAgbcVw13+1iNI1tZIzFAyjKym6MMg6YI3BcVGJxH7v2b0/r+u34D5Efvj8WPjN4I+G/wANPE3iM2VxLNp8Fzeg3jAT3EmGZVZsYMjuQCecs3U5r8lvi74oubHwX4bsbm5nn1rXrubxFqCXMQ3TvIzQQSI5/vKsjkYP+szXC/C348eL/wBpfWLLwvY6h4k1C3vbqF5VmvXmso0EgJkky5Xaqg89eBjnArX+Nviiz1v4yaqLIKbHR7g6dZoswkightsQoUyMbW2eZjphiD1ys1G6rjJK0Vovv1a6O1kVBqMSWw8L2j2n21QJbSK0d0lcIoniHmEq43AckhQv3up8snkWdO0fTtOezW7ttRvJIbm3JhaQTm4t5WJ/drHt3hgSMBjjziAysay59SsDYtJE5sVMhumEcH7+32ZiULuYkZ+XJ3ZVuhf5ybKNew2UivaWc1xbPHfzskMgkZDG5EzvAAVi2NGd7Yfc3fdLneEo6cqVvlb/AD7NejWpOvQ6MK0bk3GoWkFvbCOOOSCJmjlj8ppIJBLhm3s0Z2hwCSgOCuK37XS7nQ7r+0fPjuVth9mu4l06SGGMMkW4MG+VHQxR7Vfau5YTgtvjXlEm/s1b2SSa6tgv74+dIbWSfYWRvMRjIFePa58pAx+eQfvFXbWvrOkxJo8yWh1BrF44rc/aIAkUjIrq0rlJDgxFVJ37tomUYYBTXSvgbfTzem9uv9eaes2sb8cNrFohupobuaO04upL1Bcw2kUCxStb7V8xEDSSOq+cgIWSIZUEh+g8A6Zrlnf6nHY295btZPEqpaMEj2uJiyXDGUMjSCeVWSVgYVQMzHyWAwtN8Jahr02oSaRb2EU2lWz213AIklkhDW8siEdPMJ2TdyQVm3uWY7uo0nURqGl3FvYQavpl9MGTU7drcCJzIhIkKF9tusu7z/mQok1spWOLy0lojJualZ6bdL7p2dum/k13WhL4T4c/4LP+MdN0zSvCHhnR55zE7yX88Uv8NuFjW2TDHf8Au9tyCsgypkdQ8i4lk77/AIJ6fAe2+KX/AAWq+H3hbWbOTwxovwQGmW2uxzbDaaZdeF9NibU5OSUENxqtldSMe/253b5mJrwX9tfxVpnjD/got4f0zxLYnWPB/hC4sotY0/T5vPJ0uBhdanGjhySqqbwgh/ujtjj3P9ijwl4s+Dn/AATf/av+O2pTrdf2l4Abw5Nq1zDLdXl5d+IdTt7OZgTIm7MPmmRy5aN5IpNkhXYRU3yOp5v0ul2+fl12OKq+aqo+i+//AC6ni/wE8bX/AO0d8bPiD8UNWhCal8QvFOoa/cqq/JG9zcPKyjtgMzYA7GvrzwParpug/wCw65HTB6Hp+dfM37GXg3+yvhzogKKJJIFlkJ6bmUMeOc8kn04z3r6StNQ/szTBgk9W559v8/8A66pK0OVbWJvzNs2dS1bZbkgg7fYcDn/A964vU9U/tDUjt+cbQvy85B/T/wDWcVW1PxH5xIDkgEgbu2fYD+f51SsLg3FwejLwy98dB0/z/il2GtDudDmWMhm3YbgOf8M8DA/Wvor9kh1HjKe6m/eR6daeSny9Hc/exjsFIPPf65+b/D7RyhQXBwVU85I6EV9Qfsuaf5Hh/wC0AHN7MxbEfIUEoo68fdJ+hHrXRSpt1U1/X9aC6H1x4L1r7dYjeqkthwGfawIOflx7AkeldSdS2WO/52R8cI+4x8/eHQHr/wCO1wHh3YlvCnI2owGDgnP4/Tof/r79lqssNv8AL5khyAX3BWXtk9OenT0FezySi7MrTqdT/asETmTzznO9xIwjIx14PJ7+nt7b+heKm04w3VvcMyXGGBRyyy8ZyT269Tya4C1eSN/NjxHI53NxkcAfKATz0/D8sbmgarHHOYQm3zWEj+VgK7cZ4Hcn8frWXvSTT0JtrofVHgG/OpeHLeUuX3IOpyR+Nbdcn8KtZtZ/DVrBG53pGAVZst/9eur714k1aVjGW4tFFFSIKKKKACiiigAooooAKKK8y/ag/a+8Bfse/DyfxJ461uHTbSP5YoE/eXN2+CQkadycEZOFzjJGRQG+x6XLKsEZd2VUUEszHAAr4w/4KF/8Frfhj+xZ4chg0rU9K8Z+Kb9Ga1t7G8Wa0tiMgedLGSN2VP7tTuwMsU3Ju/ND/gpb/wAF0/HX7X3w7vdF8CWh8JeFLW5xO0NwzPqgP3Ulk+UkLtYgBQuTkglVx8Ja3PY+L/hsLy7uZdPk+eS21K5WX7RqF2kcJe0RBI0SCNpfv8MyurHAOxdvq82r/wBf15l2S3PXf+CgH7dfxF/a9+KOl+IviHeajZ+FvEMcj6fp1lOnl2qhiirHFuykZkjxlsMQGOXb5n8h8cXdh4B+JthrHlabbXRaW0udJQSSxQFVAiEhJ+b5tpOScbMndjaea+IPj2XxL4TsYHW31HUfEcSalqV88nn3ZukuLiNssfmTdwxB5YlX4DAVY+G3wV8Q/Hrxiv2Sxnv76/kbzY44sbpTkOSMYGWDcdB0GK64pL4F2tf+v6vbWyY9djC8SfEXxF8SvEmo6hdTnOsWsWn3QSIRRyRI0ZjG0Y4Voo/++R9K+h/2Hv8AglF8Qf2tvGGmJpGmy22ktKwuNRuDtRQdh3KDhm6EDHG48kckfo5/wTh/4N5I7Ox0vxJ8VoIgWCXC6UQd8RHID9j29h71+sHw3+EPh34SaMlj4f0qz023RQmIYgpIHAyRXM5Jay1f9MG0j5M/4J6/8Ea/AX7HtrBqt5pVlqvilIfK+33CebKvUEgnhc7mHygcHBJ5z9qWtrHZQLHEixogwqqMACnk4Nfnp/wUQ/4L9+Cf2TvFUvhDwXb2fjLxUuwfaFl+0aeGbYVVPJbMxOWQ4ddrD+PBWsrynoiNXqfoTPcJbJudlRc4yxwK+Bf2xP8Ag4S+Dn7PcOo6b4Ynm8Z69DFKkE1uv/EuScK4Xc2Q8ih1GdoCspyr9K/Hz9qH/goz8Vv2wvH1xc+MvFt7bafqcYvNC0HTWM3nyPcLB9kt40LCBjGshy6hj5SbsmQM3i9pc3PwM+L+rwa7qGr+DLadW12C8tEiuvEVug+0WsVubiPa0DSBz5gJRT8rbf8AViqhTvrL+l33/O24rqx7f+0T/wAFdPjZ+2V4e106v4/utM0fVLa5sU8P2Mm0XDxsjCJraEAK37xCksqnJjxuJU4+UZfFOm+I/gfqMOpf2DomoojwXEsytd6rqd3EZHzHkfuI2LxIw+VTsbkncKgh+Itv4CbxhqPgG9vdFt5tQtLSwtZ18y8ltGjnZ5jMABGytFGGCgZ+0cDatcFdzTeIfDtrZTwwpPb3899JOqDzZhOsY2uw6orRMV9DK/qaSio7b2fz1s9d+ja2002eo3dm54o+I1zd/B/RrbxBFqup393YSJpsl5eu1pBZIHtI/JQAHKPDIo+baPKA24rnL3XJdM8KabFFfxS21zYgxmKJoZFZ8+fGzhfnKlVXBJBWQY7gN0rR59et4LRYZ757WaSG2iAMjYLltqrg9WZjgcEn3NY95bRK/wBni+YQAxIwdcONxbjC9NxYj2wMcVm3KK5vL8dL/wBehSinoa3wv8F33jzxjpmhab5M2oa3dR2cHmypEDNK4Rd0shCopZ8FmYKOpIAzX2YG0e3trSz0uVLzRNKhg0zS5AJFWayi6TIsoWSBbqaSa9aEkeVLfzqSuAa8a/Y28DwWGneJPFV3CpWxgGgWBcK2Lm+ilWR8HDrssob3ZNGf3V0bE8bga9bMwziRnAB4KNsVV5yOAM5z7de3Wufmsv6/rff0R30IcsfU0Y76OS5zuwkpcfc2oFZ+BsDBVAOGwByQavOYLK3bMdyRJOjOm9nW3J5jVpMDLD5mG3HRs5xhMsCQLM4EbGIbmSM5cZbliTuVhuOOCCc5xg5qZLuRIzCnEKKyogUsgViAw6EsT8vLc/KBzgEUtdX/AF/X9d1qjSYx3Hlkl5rmG3YMDMisdkPJ2YwPk2/MSSfLfGGNNEsc920byRTZRy0jqpUErkrvByfnJAPuM9SBWSIXTRrkBJgFcTkKVw6gup69jnjpuz0Bqxa3Eh+cq0/mbB5gViUVVCBSwGQMZ4BA9MEANUklZdL3/ruGpM92J8s9w852BQ1w7O20DgAg4xtwMDt3Fd1+zd8KV+Mvxm0bRjEklhakanqKvGG82CLadhU43LI5ijOCSBMWOcGuJtp3sYmMEmZRmSOTzNk48sgvJHjlfl3L0OAT3UEVfhP8U7v4XfFXUtXW9vNBFlpP2VTG728d1HPIrSZcZXciQRlQcbhLjp81YVoNpc+/p/XQuLuz9avh18E9W8V67BPHZ2V2kAMkxvZWit4olBLSSOrKyouckgg+nJwZviv4pfSPiAg8JefbYtFsRMHmmNxKZjM9xAtw8slvuncsmH8xThtyszAfAnw//wCCrvi3RLlmTxBHe2ZCxxCS1hlTYo4AZBuHOf4+p68VteJP+Ci994x8Naxbh9BtLrVLKa0S4VJIpULoVJUu5AbB4I5BwRjFZVZYaq/ayWtra/8ABNPfSsmcJ8X/AInDX/il4u8VWVz/AKLp+NJ0SaOfAAI8hJY94wAw824KY4JNaH7GHgv/AISr41WW6AC10SFr6bKtsDL8sQBHAYSOHAJ5EbV534zsl0jQfDukeYJPtEX9t3OJFkTMoKQYI5UiJd2D/wA969x/YJ+KPhHwp4a1z+07mTS76TV/Kmnkgcx3EEcETwrlNxJVppgML/Ew7YCoK2r2f66v/L0RLd9D78+GFhqvjPWtF0zRIr5bHQdPumnl5NtDqMq3YtrtgoP7xZZoUXAaRhD8oY/LXOSat4UXSvEix6UL3VXOm2Hh9JrCP995dpPazXEoIwu8sk+zJJn8kkOqMa6f9mH9pD4WaT4SJfxZ4WF/JdtfLDfTW6G6dIgtsy+aRLDJCzyspjTcfM6jjHh37bfxM0j4f/DPWr/THh+0alCdP0ryf+Wssg2tKpByPLj3yB+zrGCBupfVYzlKo9Ix1Svv6W7/AJiTktD4u+KHiXRvitfeOvEF9bJqXkXcMeg3NxPPFKUeTyYFVQQjbbaBnZSMjy19eM/9l/4SWfj/AONfh7QpLCd7XUrkidklKqkMcTzyq23oJI43iDdmlXkHFc14puv7O8OeF9MiaSP7d5muXRL74iJgIrdgc/Ji3j3Fe3nZ4r6Y/wCCX/hWOz8U+K/GN0kaxWNuPD1j+9yQ8nl3NzuQgHAUWRV8Y/eSjjBFduCUpcrn/XX8tCZ2T0Pc/i3/AMEofDeoeD2umtrPQNJ1G0jvprtbye3SzjnitRuEQE0aAyT+SGEQJNu7EKo48D+Iv/BDR7K51CysLzU9Pl01Ab1r17K/ksVaKaYeYEeERlo4XcFscDA5cKf0N+E2l3XxFtGvLq+1W5im1aKARwaXHfx2FxHb+Vb310XYEQRJKcBiUbyW3AhNp8/+J2r6r4f8OeLLzVfIsNM1mVNZ1u5sEkEc62onlkk2luVLSPKQw5dVIC4wOC9bnlC6aX4f130+fQVrWe/9f8E/HT4jfsh23wq8Y6hBFZ23iSz0q8W1/tN9LAjeYhXZMNuVXDNjZvJyBywOTa8DWLRXUf2mPyIXUpKScNKVJGCA3Quu3OcAPn+6a9T8XeM9Sufhx9pu5Wt7nxxrtzqMhhnHly7Q4K+UTuGZ2kJKjOLdeegPGzaPfQ3djeixvLs6mgkeOeFyt2FkBxlSTIN0ak4zggDkgE9NKKlDmite3Tp/n/wQnoWLm9uba1vnuPPiujA9pcSyzMWcHcrKBhCQIwseAu0HOAN2BsXDXWkWLXbX0QlvkdHt7WdZniiikR0B2JjCywqwCkZ++W2srPUsY7aG2SCHUofJaB1ERKeXFJn5pBmRXj3CF87ip8vYpI3BTp2+m3t6mm2elakb24vZHsllhvIbWC8BaB45RG6Lm3kEcRUSbBmMggeSzVfK2m1du3S29/x3trvfUi9t9jT8JaFrl6bW2sLq2uLq/wBOeM2cQCxoMR7vLlLASSzI+44YFnhkQ5WJM73h/WprC+lUXmpPqOppF50+mytm8uCvnRM0hIWUrIgj2vu2hZFILIu/ntMu5jZi33WMthfXIKXcli5NxKbiSU+XMsbOXPzFTs+f5VMbGONR3V34Xt9e8T6tfxRJdrfzvBYohhzYK4WQxiCRSyRpbMZGKI/kGKNXWBTItbU4c7i49+999Nl+e2uiS1H5MZYWsNpFpcoX7JYyW0ypqE8yvJLHM8yzeXG1xE6EM7RJE8pMhgnfcGeUJ2kOuan4ai0W61mO7sC1wNVjM1pFcWdjKJVQysceZBEGtrNSI1jYBJcCEPGZeU8Itpl5ren3RjvtP1MPaR/Y4IJPLmu5VWFhJJK5P7w28kgjaPyzHcSKWXBK4P7X3iO7+Hn7H/jDWzJcLO9rOksZmIivotTmzDexx7RvUO0gWQt8pjYbfNEpCp1Go369k9Ha3Ra7XsnZpLW7KaVz8n/FHj+Txp8cfGPifN3YajqguzDFCNybrp/JmhOTnY0E1wO5OBnua/TX/goFbf8ADP8A/wAEAf2Z/hTcTajZeKPjL4zn8T3CiL9zPptokkciyt944a7sZUVl5KnONoB/Nv8AZG+FN98dvjr4Y8KWQM194l1m2tIk5zJIzhQMgHORIeAOeK/Ub/g4q8bW3ib/AIKUfCn4Q6PqJvdA+BfgO3hazSHYNO1C4+Z1PH8dommNgEgADuDVz5uWFJrS/wCK1/K34Hm05NzlN+f46Hivwq06LS9FsraPlRGI1yccKMZx+Ga6Lxh4iEKiIN8qfL15A4yBnj8T7dqyPA1o4sgd7bB8wUjGPXj/AD9KTXIiiSgDa+4ncenuOR9Oabfu2YktTNttVLlmJ752gEc+uPz9e1aGnXh8sDcBkHcR396wZ7pNOfL5cnIJ3cjOcf59voazr7xKtpZKeGx8pxxnHX+n+RVU1ZFM9Ns/G8Wk24O5TJwo2vyScDHP0r6k/Z6+IMNpp9pBhsxKNzjGF9frzn86/OO98Yz399EifdkcKQeQfr9f8K+hvgz8RrrToIoXdvkAI+c4I9x6ccV10XDmuK/Q/SzQ/GtvqcKeXcTeZgq+1gcr+fT8v0rf0nVnxK0fzbcAkDGCQCT6dM18m/C74tSMqAz9s57HnsR+H6/Wvd/Bni/7QqpnJfG7k46AAH9P89fR51KVwXY9d0y93W6yT4VlXhgmQ3fH8/zOK3dJljzjozENuQY9M9B/SuB07WC0Cr8sQHO7JPIHIOPqOvrXS6fM0SfvFY+YQdxXv9P89RV2V3J9Co6PQ9e+H/xAuNAeAjcqrxtJx09O/pgnjAr3HwF42TxbZBwykkZGK+XtADXd9Ftba/3RngAjJ5H4devbvX0D8DtE8nTGuGwrtwFXoo9MV5mJ5X7wpRSjc9DooorgMAooooAKKKKACsvxn400r4d+F73Wtc1C00rSdOiM11d3MgjigQd2Y8e3uSAK+Sv26f8Agth8Lv2JfFtz4amjufFPiizGLizs50jit3x/q2kO47xxkKpAzgkEED8Tf23v+CkPxE/bA+J9zret63PbaKZCttDZb1j01T91Vj3nYnABKljwSdzZy4xcnbp3LUe5+iv7ZX/ByLZ2M+ueGvhDownuMSQWfiK6kV9rDAMiW7KF6527mbIwSv8ADX5D+Ovjn4o/aE8S6zfeINZ1XV9bvJZLm5DozxyQYLNOWLHfjLFgydBknrjmYmTwt8Q7VdZW70yzvriGLWYd7QtPbM0cpYgK56bHDBG4KsA5POLZ6teabqc9zHFbybFn02boyMkitEGGw/eUsHHJ+ZVPNdiio2S36/1/WzXQafRG5oHi0eGPDWowC6ee80+6jGmROxYRWz+aZlRGXBG9oz1BHmE7TlmTAsdK1TxnHa6MbWMJBNJexrHEBOGm2oy78bio8lSqk7VLSHgu1e9/slf8E6vHX7V3j7RdL8P6Pd3P2ol5ZzF+7ij+UF3Y4Crn8PlOOa/a39iD/gg98P8A9nXW7bxD4sKeKtcgRRHbuv8AocRGTyp+/wDMWPPHTrUzbjHkb0/z1/y+4Vluz8lf+CfH/BHXx7+1r4ruTbaY+maDayBZNQvUMcCHC7gDg5O5XIGPyzX7g/sBf8Er/AH7DHh1XsrO21fxJKfMm1GeFWMbklmMWRlcsSc8Hn8T9L6JoNl4a05LTT7S3srWIYSGCMRov0A4rmvjH8e/CPwB8Lzav4u17TNEtY4ZZo1ubhY5boRjLLChIaRuRwoJ+Yetc0pdhcz2R2HSvIf2xf23fAf7DnwyHifxzqDW8E0vk2trAA1xdPjJ2qSPlUcs3b3JAP5xftc/8HGN74yXUvDvwW0gwO9pO66tcR+bdIkcfmtKqZCRgKsgb75ABKsDivzH1r4l+M/22WubjX9X1XxJrWqyvb3q3E/kwWMpaNYZJ7iUlWVsYDblOVGD0zpToTk9v+Dt/mvz6MTtHc+mf+CnX/Bdfx5+1VoVzZ+Bnl8LeDbEqlzbQSEreBiD++c48zBT5fkVRgEYbr8S+NdHvdf8KN4zsdZvNPawZtS0vWL+5Nne3ksTR/LbxK7ETJJwGQkfKCSuKsaP4zHgHwH9r13TIPFGoQXtx4fsLu+nN1afZ7eJQ0cabhu8vz4ShIK7WX5SBtHnc9nceJ/D2jWsUZsotOiktLj52YXMhleXzthOFJjljjwo24iB6sa3dNwT5f6/q97+Wj1Fe+n9f1/mdN8S/ig3gqHw7pnh/SpdH1q0ttP1ibVZZxNe3F68f2hbhJAB5aFJ4yEXptG4ls48+0Gz1F4r2MyyRpq9uLOcBf8AWIHSVVyRkfPEh4x0I6EivfP2Sf2EvGH7Wvi210bwzod/fzQM1vJIkbOsaCU5JJyAADyemBX7KfsYf8G6vgv4faNYaj8Rgmq6qCJXsI23xRHGAGP3Tjp90jA4PelHljLmvb+v6T01Cytqfhn8HP2NvGvxj8RWNp4d0C/vDOxjL+S23qh44+YgEnC5buB1r9Av2cv+DevUb+WC88TlLqeRFBsotxUj0KrwTzwS3H9w5r9wPAn7Lfgz4badDZ6Lomn6baQRiJUghCsVHQFvvEZ569zXdaXodpokWy1gjhU9do5P1NZyqRtpuNtbH4Nf8FQP2CtK/wCCdH7HmseKtP0PStH1/wAVSjRrGSKOOKSMyqWlcKhDriJZCGzhZDFkcjP452mjPMQSYCxP7tflwTnoRnI69enUZ44/WP8A4Oh/20U+Mv7TVp8NdMuo7jRvh/C1rKItrg3khVrps4BGCiRFWJAa3Yjkmvzn/Z+8Kr4s8dLf3ttHqWm6DF/aN5DcM/2e8CMojtpWUblSed4bfePutcqx9awnNzV307/mzSlG7t3PcvBnhhvh/wCD9C0ONXNxpMTSysrA7NQuxG93t+USRuqxWtpLCxwk2mykffNaMbR20kAjjfyslm34G8tnJUHIAwFHccYPHARpbuRzLe3k+oXUsjS3FzcPvmvZmbdJJIwOWZ3JZj3Yk9TS4eUAy+epwEk3KTtwRgc9QBtH4AVhJ3Z6OliQX+UEKf6pQwbZtTfuzwSc8H+7nHJwASac19JPE28qwKhQMkpGnKhWIwO+ACMcnoTTlMdskcf2OTzWDuwckFsgbSFBycDdyTg8YGQSY7WWS3ijwyMcYiwA4ReQSQe/3vvegOMbTQr/AGmHqaVrJCtykrm3mmi8uWSNXPzIVTeFIBQHOO3ROc8qSYtHGsrqhgddsjtlgTkgMuQMDsCckMDjrgUjM0caNueZt+xVAGSo67T24I46cc9jVuS5lsrYxF/MXYo8sMW2AMxK9do55wP7x70u6EbfhjRbrxn4z03TLCW2gu76SGziYKX8mRm27zlsjBZnO08enANe8+O/+CfOna+bn+zvFN1ZRXAZnjn06OcyORkjeroFXJ6BDgDoTzWF+wt4Gl1/4iXetjLaf4dgMUBVvlkuJtyYT+FlEQl3YOQWiNfpZ+zv+y9ofxS8MaxJL4ks0srvTIo7qabTWin0i8WWK4KRySDy3AihmDGOQHY4LKAwqPauEXJrd/L+v8itIrU/Hzxb/wAErvFthHJdWWoeHdSZXJt4YrmRLlF65JkiSMY56NzwQME7fLrz4deK/wBnr4gS2d29zb67YbCB9oW7SMModWTl4m+Ug5GcHggMCB+u3x60HSvAvim+ngk0S38P20Bk83TNWj1QJBBH+8llMbEiTYpdhtXkttXFfnn4h8Vjxdo3inW9RtLWaTWb2RrSGaBZ4oJ52LPscjejRRA7CCB8w7hcc/NTSjKK1f8AT+f9JFpPa555FqWq+JDfanqci32o3n+vupWRGJVVC4VAFGERQPlOQOmaIvincfDvwpDbLpl5BHbeY0lzbzic3MjuXdhBIqqPmbOd7bdxAwGr6T/4JzfAzTfib8e7Y64be00y1EUcs85VoY3mYKrt5h2n5BIVJ43IhyBuJ+wPH/8AwTc+GPxTsJooYPDcSXOqwaRplkFS2lv5WaySRTc2skUkiRSXTgvFG8bC2c/JuQGqsqaXLJ6/1u0rrX56dSbtM/IM/tYzrev5nmxIWwDdWhbOPaJiBXZ+BfirpvxgvrbT7vXPDmgWYlVpby+1dLNkTO1jFG4+aTYWKgnGQMkCvtfx9/wRG8BaxoGq+IbTULy00PSdROms2kXkpjndWgRmjN3avlVa4UYMilvLlKBkQtXwRrXwT1Pwz4aj1e2iRtCmnMNtclolMpYkBWjDFwQEPB4B3cnjOUacKmkZXX+Vv8/J/gNSZ1Xj7xdZ+MviNrep2DWqafNcFLAIRFGlsgWOBjuyF/cxx5GOu4kgcH3H4BftI3vwR+G+n6HLFpTuzNdyw6iphuInmPmtECrLuMZby8ncQEX2r5++G/wl1T4uznQtKsJL27v7aVJIo5Ej2RlTuZ3dlRBjIwzKCSFzubAs/Fn4ZfFHwRoF3Nf2utpb2EmLi5ubH7ZEdxOCLt4zle5YSdTg7ciu7lqKN1/w/V9iOZbM+9fhr/wVG0/wraf2XqGi6lY6V5gnmjsLmKU3bg5UyApEXAIBUO7Beq4PXJ/bY/4KSaX8bPg/deGfDlnrNtJrLx2redbpHJ5YJlcL5cj5L7NvXlWYY54/K641/wARLeG7iSxlVj96FXjfn/a3kDHPOO35ek/AD4vz+CvFVprHiLTdS1G20+dLyGCDVVL+bHIpTdvQfLnHAYcdQfunmVatJOD05t/T5LsV7qaZ6d8Y7ZV+ItvpsBtJ4dAs4tLW5G9Yp5YkaSbcgwdxuHkJC5JOzJ7VGmkRPbxtY2Nl8yNJbzJdJCB5YJYSRuSTL88ePn5KkLuJbbzt74gHivxLJe38zanNcTCeeTa0ZDv+8l+6CNzSSPzhsFeQV4rbvJkimcO2oaddfa0FkvmgmEgOJGL7QzhGRVj29Dv+YtnO3soRhdq3pb83dd7a3v1FztsltH/tq21FrO1djcBhBb2+97iNTNAn2YEY3Allj6MSjn5MkBNzw5fXHifVZHlmjvZ7/wD02SSeVDFE6/vw0sYLkRkt8/QZYKSqgA5NlqUfiGbekX9kEMfngaWRTI9s8QZ3Ys4yxESo4b5ZpMMMM7ddNq2iw61dwFF1C1nleQySQeW8dvGyTSrFM8blGjHmI3mo8flSScksorWNkuZvTRdr79N+627WJt0N7yfFNzYXnlxeZDpGmxxahd+TEUktHURpBLEUQ7lYOQpUNtw2AIgxiOsTeL7a71GC0s7PVJ7gXn2gSTm5sEDxQpE8gV3lcFknB2hk2ybdioqtR1Tw7FJpkC6RaXdrdWWnyTrcNaNPNewvASI3t4o2IkVFeYvx8qZ+Z0kkboNS0CRdNs557WBZYorm2nluNRZoGkVJ/LUEP86pbghpFZYXiefy0YCSV9a3O/dX4u/kumlr/Pe7dmjY3/hd4ggl0WK2trCYXUk6KN1t5t4Vllka1aO3yyRp5awyMsJLglCHkXMdfKn/AAVO8W2Xhz4G6L4ftGkuZNT1Bp2v2dSbryUKXB2IAFjkmuN6B8uV2sdnmMlfUmi+d4b0mwFzdXX2iFVguXnvGkWNQsb+XHa/69ED/Y4xvIjiaGDLRM2K/Pz/AIKieP8A/hI/jZZaSWkSbTdOiFzHJOs8DXEx+0EwuS2V2TRKG3Et5ZJPzADKtDncYyXvR027W/rzeqe4pyahJ3PoP/g2K/Z5tvjP/wAFK9D1K5if7J4Es5Nd2onytIoIj3/NxiUoRkH5o15GMNxH7Svxsb9rn/gqD8fviLHeafqdrqniubStHvbQYhudOsf9EtJFGckvaw2p3Y+Y5PHf69/4N+V/4ZB/4Jw/tP8A7RUM2l22q6B4ZuLbQpb8COKS7gtpJoYSWPzCW6NtGE6sxAHLYr4E/Yp8Mix8F6edhdrlTcHtv3n5CTz/AAYH4Y4rXkl7WMeyv9+34f8AA8+CGkG+7/I+jPDujLBp8fygYUblB+4cD/H9TUureFWkt/l9CccY5Oc/Wur8JeH1mjQkdgQduCemcZ/X/CulXwd9ptmIXaR8oZjxyc//AF66ElLV7CvqfNnjHTprXeIwR0A+XjP+f88GuA1axvNRkePy2YscEjPAPoAe9fTPij4bPeSgLF8rnbtDZHuP6f5xTfBXwBbVJBKYGUQybwxXrgnnj05546Uo0nN+62Js+c/B3wzvNc8dafbGNx5aGd1C5PXAPH0P4V9DaF8O5NNgjEgkRV5yRkgHP/68c/Svpr/gn7+wFf8AxZ8T+I/EwtNlmtwLO1AUlGEfDkHpguM8c/MTX1Bq3/BM+68lAbUBh1CgHcO45B9s9frwK7FRjKF4vV/0iXKzsz4H8Bm50+7CnzD/AHcfxH2J+uPwJr3z4Yag6whpAwfCk9gPU98cf5717Ld/8E8L+yl2/YZwuQBtHzkcdeo/T+lepfCv9hi6ju4vOiKJxuBXhgD1PT/INa06Lg25SRSkkef+D7aW9iXap4XgnJXGORXrvw/+El74wURLaCKGRMZ2kKfUH9evrXsfw4/ZS03woytchZsdFC4A69unevUtH8N2eg26xWsEcKKMAIuMVhWxS2RTml8J514H/Z3ttJ8qW6+ZkGNp/wA/SvStL0iHSIBHCu1R2FWqK4HJszbb3CiiipEFFFFABX5v/wDBaz/gsfrH7E2sxeA/h+LYeLJrVLi7vWtvtMtjvwyqiMDGCU25ZlcYl4AIzX6JeJvENv4T8OX+qXe/7LpttJdTbFy2yNSzYHc4Br+VT/gob+0PrP7Un7WXinxHrT+S1xqEhSJX8xYAGIRFz1CqEVSSchV6gU4pN2ZpTXU5LxBeXXxn1WTV9Xae71rUHk3lYpkuvNJ4IbaFkZj7lt2cr0Jw/EmtWer6M32m9vrjxC9+TPNcsdl9BIvM24gnzQ/EmWBy6sN+5vL3La8h0jw/FJbaWcfZs7RqIlkujlg0nltEoK8EbUYdPbnmvAnw81H4q+LNP0zQLdrrUL/VEs7eAL86vIGwhGOh2g5OAAH5GDXS1G3ua/8ADef9fI13G2ugal4ruNShuo5Li8srdbZJTGAz4AjiyAAM7TGnA5xknJOf08/4Jxf8EANc+MPhHw54h+IMj6FotxIl7JbSIftd1GMMu1SMKGPzBm9AQDnNfTn/AASQ/wCCPWh/C7Q28X/EXQbTWPFGrXIv4o7pRNBpSDIihXgJI6rgMxBXIwvChm/QL4g/HHwT8DooYfEniXRdDeVVMUFzcqs8iltoYRj5yu7jcBgVlKUlo/61/wAiHpoiX4QfAzwt8CPCtto/hbRrLSbO2iWIeTEA8gUYBdsZY/Wuur4u/ae/4LqfBP8AZ7e6tNO1CTxpqls2wrpzqtpuDYYefzngZDIjI2Rhua/OH4/f8Ftvif8AtYeO/Eul6P4w0n4ZeG7BJJ4bVp5VM8JKRLADDGZZ5GV9xDjYcOcIABUKM5PYnkb3P04/bn/4K5fC/wDZV0HxBo0Ov/2l41torizhttPCSiwuwnyeazfL8rsMhQ+CjKyggivwf1v9onxd+118XdQHiLXPEPiPW7m/ilttPSY5vLVY3MjNcFtyeUiR8lThCxYoEGaNj4murn9pKR7/AFrytE8VL9ptvEmuaKWlhtUvCn9oxQgzGJzJbOjFHfBaZA2RWH8TvGejQfGSfUfDeua7qep6rolzbajrVy32eae/kknMjqFct5ctqFicMcnz5ic9D00qTj73n/X5prp8kNpJWK81l/wofU/Eej+I7O38R2+mrDqOm6QmsE2VleXYjdrh1hb94BDF5cgVlIcwgnam2uL1Hxle+Lbbxg0EZ0aTxVq8Opmx09zBp8cQ+0FkEI6bGljEfP7tS6jO6tn4X/BzXfiD4gW2tbee+vLxhH5caltq5B5/EA8nA2596/SP9i7/AIN8PFfxF1Cz1fx1N/YOigeYbdlInmJY8dOBtC8gHr7ZLUnFaP8ALzX5MhLq/wCtj80fg5+zZrvxY8Vx6JpNheardXXlvFHDCWJYllbCgHsFH4AZFfqP+wL/AMG8Wra3qket/Esvpem8MtlgrM4wD0+v0HU57V+nn7Mn/BPz4Y/sn2ajwtoMC3mFDXtwoknbHT5sfj9eete2VlKolpEL9jzT9nT9knwN+yz4c/s7who8NiCP3k5GZZj3LHuffqe5Nel0UVi23qyQrzf9rz9oSy/ZV/Zr8YePr7y2Xw7pzzwRyAlZrhsJBG2OdrSsgJHQEntXpFfkD/wdP/tdf8I78PPDXwp065CNdMdX1TbtOWKulvHkHcG2+cWUjBEsR9Kl7DR+IXxr+IV98YPixr3iTVLqXULzUbmSd57hy8juzMSzk/eLHJyeu7J64r2L4O+DW8J/D3T/ADE8m91knULgMuzzIFLwW+yQH5kaVb0yI38VvbPjgGvHvhr4Pl8WeNdO02ERrLcyJGJJV2xxbm+8TnAUE5zjopJx2+jtOCzEXFratBBcKjW8TRLHKIEiSKHzFGQJfJjj3kcGTe3elLRWf9f1+p24aOjkMn+Z8k+c3I4UEnoOxz2GM8dsdabF8iMBwSwJw3B5/Tr+noeZ0jEwYcMQScd3GcYA/H9DSRSb8Ej5sZY56k9/y/zziue1jpK8cvlT7kYx/eyODx09OQehH1yPSwjExFTE2+M4SPGFA+VW4zxkdep/mJX3FSC5lG0sFLbRHty2PzzxweTxyKerGK3+VHaDcpaNmCqQAc5ByQcE4PbJx1ppK+rDQbbW73H+jwujh/mbdGNx+Vud3JC4Jzg44UkDaKU6m8izvK8HyIWIyIweeqgnB6jgc8AgcE0tnKU3KdmHQZBLfK2R8wK/h6/yqrqDrZ2czNJDaxMq5lMyII/mTks3TJx78+hwasI+0f8Agnl8WfCeh/AiGO+s9ThlS/uTNPDFHImoSiZkMgzIuBtjSPOOsB4Iwx+1PDn7SfgxLDTDoXir/iZ6NbyR2MFxEI4bXzdxl2mUeWd29gcL82ByQFx+MWgfETxJ8OPCei2VvBYnTrGIQLcGJ47i4TH/AD1RlUHgZbYSSCSSWyej0D9refTf+P3S9Ut40k+RLWSG+aUdt7yiIjr0BPtS9tOFoyhdf0/6/U1Si+p9a/t3+PoPBnw9Gi2U8Mt34nk2NJFMsiwWqENKSyNwzNsTuChlBHSvk7xxbSaTe6PpHlfNZWi3FzE/yOk8+H8txyCVj2AEZ4c8Y4r0TRvix4P+LTWi+KNfstPtbSdLr7I2j3kjyxggywNLzEN6Dadr55GATxXknjLxhdeLtV1HVPs8st3qtyZEtoZGkYM5ykKZxuA4ReOgA6YrJwUqjqf8H+nf/hgeisj7p/YX+Ek3g34MwXl1EPt+usdSb7rERuMQKHH3lMYSQehlavqnRvgRZ6EmpyLdeIbTxPovh9vEDahaXqW0NtcbFmitVTZ5jMRLEpdZQQ7YC8HPxl8J/wBsKbwD4Y03RtRTTruTRbS3sprh4vsjTiKNU3BVIjy2MkgHnI6g19EeHf8AgqDp/iXwfLps+jJDZSRRwm6tnjmlmSJdqLIQq+ZtUgAs3AAx1rabhLkhGVu/9a/5GbUrnn37UXxm1nw78AvEgvtVvriK4BhgiuLptzXk5mXzkLZPmL9puJs9W2tnJxj4I8Z6mNM8E6HpTZVbuR9cnQfOjeYogt2VhyD5SkkEgZfrX0P+3P8AE+T43+PfDfhXQE1GHSrqb7QJjABJPO+Iy5iVmX9wm9hz0kck8gD5e1zU4fFXjfUNUiCyWkkhjslh4R4QBHCFXHGUCk47E8Z6xOCVflirW+Xn/XkPaN2fUv8AwTl+HT6ufFHiUQyJFZ2sWjRSiRdk7PtkmV15xIix2x68+cfx+srP9mjxLrfhSDW9PFncte3Hl2llb30T3l0qqWkdIlYsdhMQK43/AL1TtxyeL/Y58A23wq/Zr8Lo9tHJPqsC63drPA8H2iS4xKI5lVg2UiMUBIIJEIII4NfRuiav4O8ZeOrG9fQdXs9P8OwKNLs471JbaQJMXRGgMRZt7yPJJuuPmJZcnIFb4n2sYx9kvP8Ar/NeuvWNGz51+NHwBfQ/EkWjeNtAsLuf7PFcCPVLIXCeXLGD/wAtVwQpLIxGVDI65O01+cvxL+Heja3bzeJtJaGwj1XWZYl0pLR0/s1CPMyhUnciK0K7QoO6bAYlQh/Qz9uXUm+F3wd8WavdSvLe6rvsYZLkkS3M90SjsXyf3gjaaXPcxn8Pz48d6r9hbQdEdir6XY+fPFcxlZbae5PnyLnI34V4gOcHyyCeDjnqufOlPSVtfXovkr2/LqqjH3boyfCHh6PS5bR2kjuJZfKt1tCpH2p9yDYZWOBkg55GAyKNwZlTpbrSg6pO963k3dvJvuUl8z7OPNZRGxWMEqQVQRoxOTuOAViGR4QuZtBu7tLWVJpryNrWSJf3qzxtuV4/4Qw2buVyD07g1oWVzNZ21rOhjiu7y1kiidLfYhCttSUPuXLbl2s21ypjZwzSAKu9lbliv6Vv89rq19LbuFo7mpJp1xHPeqtzbH7jQRAyN9rRo22xBBGBvQygcIG33Tvu24atyzhTTbddXtA8NzO6zWqvbuBaSQyAO8ly8iyhwUV2kjwodtoKhtrYEuqSz6eTBOj2IljEUL2kbJsVEuDGwyOEkDEoAUVg/OJWrpfDl/f+HhbTLI2o3kV4yWlnPbtJBdTRP9oLvGVYzfvXTKqGZC+7cqhFaYTcpNW0XXqnfprtrp30bXUZ0Fj9r8aa5/Y7Wc0MkFtKf7NtPJ0+Ly5LuSQlpJ1YEJss13FPMkEJ6ld50dFg/svU9DtZGhspLO3FzZ3bzW4trq4XN0d8oeMtGYttuuZgxUjaB8oGL4MiSK0FjFr8hgiuVuYLbVbSJ2lNwA8cxRorgI+1ZZ2KCVCrAKXMwR9Y2z6pbxa4qW+j3hiub6PSbWBbiGaII/m+WqMDtXyT5ibhIoEmcNHI7acj5VKd+bS+q2TWl9dV6p3tyre6u1sa9nDZ6j4Nsmt9WhsVsp2u5re4crM5l+YyZXDOzSw2wIEaCPcThPOQR/lL+0P4zPxO+Ouv6/EJRZXmozPaO6n93AJAY0OSTlI2jXqSAFyTnJ/TX9orxu/gD4B+Lr29+3R6noVn5MV5b3cN0bi4uTcwieSeOMGTJlhLNkGdhKzA7Gjh/Lj4a+EpPiF8V9K0mG2V5tRvljCP1wzD5fcdOx+nUVChZRaWtkno077bO9lpa3l2sjHFStH3up+s37aej3P7GX/Bsp8OvAcZ0Y6x+0F4n064u7KSVftcVjj7crxqH5MclnYq5A2p9pIIDNk/LH7MvhwQQCNB+7iVIo8j7oUd/wAD6fzr6O/4OTPFkQ/aq/Z++B9odIvLH4MeAxfXM0Vx5t3Bd3jJE8NwA2FYR2NlMoIDEXO45Vlryz9mPw75GlCQceY3BHQD1PHbBrpw7c6kpvq/yOd6RjFf1f8A4B714G8KkW6SCPKthgoAHT616Np/grzV6ANgKPl5Xj/P5fnleBtIZoVPK7RuHTr7eteoeFNIeW9WPYzKoBJJ4xjH16//AKq7lFN7ESaSscK/woS/eRxEqlcE5HGepyOnPpn06V6J4N+DkPhjwLfah5O65ERMKyHG+Z22xxgkHl3dRznlq9C8OeAAfKzGuyV/unkY746j/wDWa9e8H/D3/hOPiZ4J8PiOUWz3j6telT8nk2oU7WBHO6aWEr/1yaulctKEpt62/F6L9CNXZdD6J/ZM+B9n8BPgXoGgwRgTQ2qNcOeWeRhuYk9zkmvSTGD2H5UoG0UteK2BE9nE45jU/UU9I1jHAA+gp1FK7AKKKKACiiigAooooAKKKKAPO/2tfEd/4T/Zn8dX2lw+fqEWiXS2yFA48xoyikqQQwBbJBGDjFfyi+ItZGjeN9S1O7srbUNRlmlZDeZeO2JJIkKZ+eTdggPujIJDo+75f67PGOnrq3hXUbV4IrmO4tpInhlGUlVlIKkehGa/lv8A26f2dW+Dv7VviXTbiGWXTbG8BKt8jiIqH69MlSTkf3/TFa0ua94b3NIbanlWialDqPh++t9QvRAbmVZYrMGVBMzZBclCAu07RnuOgOCK+hf+CYfx38C/sl/tDv4r8Z6fLqekmy+y74XJmtfMliJlTzEAdgiyKASpIdssATXjH7Pnwc8fftf/AB1Nj4O0X+1PE+ovNfxWtiqWywrH87eQvyrHGgYBUXAUbQMBeNH47+DfFvgu9tdK8cm6t77X5k1iK6vbl3cxqZ4GfJZshnjYZbn9zjocndwVlZ2f6a6/1t36mmzufsL8Q/8Ag4s0q48PX8Xwn+G2ta5DptuZo728ikljghjjMkpmhhGE2oCxPm4ABY8Cvy38I/HJ/j74l1fXfF0fjTxlr0N3/acemwXpgtpbZA0ty80wDS/NxkqUIG878sAOW0XW9b0j4ceH9F1681XUtKsYxq2k6Rd6nM2lxRNIZJAkIbavmSISxTaSRnriuV8C/Y5/h/rDW0d3a+I4dXjMM0cm2P7O8cv2hHGN2dyw7ecYMmexFU6ahr1/r+vuDSx0ngTVtX+G/jjxdo11rGnWHBhu9aisodRmilRJGjjt7kKxi82UYLwsM4BywUZreH/FNuvxh1zxzpuoXH9raPp1tqsa65H/AGjNrGqia0hvGcurBizz3N0DIDhYtpLNgmv4V0/UY/Dup6ArLJa65c2+oyoEBaSW2WZIznrwt3L067h7Z9t+A/8AwTK+KPxy1HTLrQfCd8tjIssTXcyeShBMfO9sBh14GclT1xRy8yjy3uvPz/Gyd/Mn3rngreMfEXiHXku766nnSWxn0iNWIkEFvN58rQopyEAlkdwBgBnZhz19y/Y2/wCCaXjT9p7xTbQaLpNyIkdWnupIzsjVs5yemAN3U+nPNfp9+yN/wb8eFPBlpYap8Qrv+2L1WE7WMIZY4z8wwW4PIOegx0x1r9Dvh/8AD3R/hb4VttF0Kwt9O020XEcMMYRR6nAAGah1VFb3f9f5EtpHzf8AsPf8Eovh5+yRotney2Eeu+KAqvLdXaK0UEm0D93HyMjn5jk5yRivqkDFLRXI23qyG2wooooEFFFFAFLxF4hs/CWgXuqalcRWenabbyXV1cSHCQRIpZ3Y+gUEn6V/KN/wU7/advf2wv2vfFPiu8aQW13fSG3h8wO1tAp2RREjAbbGFQMByFGa/fv/AILtftHz/s8/sBa8thO0GpeLZk0ZHjn8uSOAhpJmA/iUpH5TDpibniv5tvBHw/1v40eL5rHRdJvdb1mZZLk2drAzyPEil5ZNqDOxI0d3booQk4AJppdX/X+Y9Tf+CPhuS3sJGxv+2o9qV2IUjhljcTEow+YNEHiLDlXlQjopHqlwr3wkYKWMY3O2ScAnGT+JAz6mvNtC+KFxod3ZxXmnWz2NskyKlsiieB5CnmfNnDhvKi+UNt+TI5znr9L+JGg6y6hb6O2mZv8AV3f7huPTdhfXuc1hVktm/wBP6/yselTS5Uomkse0Y2nrzuPQcf4n86X78LN0ORyvG/qSevHbA/H6ztEeRgYPIY9x1G0985pqoN3+8cjtn6HH6+5p8rNSOGMwyOVPG0gA4PB46f5P0xQ6gW2B8yqxIPOc8Dr+v4n61LMN+dy9T2GAOMUNiQNkJ85xnAOMn06VOjWgkMQPKS5BOSox13AcDH5D8vauU+MN75uiQWuGaaeQH5PlJUZJPA5GMqV6/Op7CuxjTDKFCknnaox07/hiuNe9fxR43JLM9jp5LIhyqb8ruIXACsdsKsAefKPrUVI80LJ76C63N/wg97oNtbvbXO+5tYtqNPDHcbCTk7TIGxzjnrwK6a28W6Xcwi21bwhpdyjsTc3tlcTwahOS2cq7NJDHxkcQccccVU061Gn6Xvc/f5P/ANeqfyTOWUFQSrEhsdufYd+3H61raysn/X9f5E3NxLTwNrkqtu8SaBwsaWyJFfxg9C8k5eJh24WE9PpVzX/ghpfiLR7k6Z4y8J36xMIxDLM2nMyk8kfa0iDnPPyn6kVy/l5m9Sw6Mv8AntU8Kq8PIbJ4BXv1H+FPkUotd/69Plt5Fc2ppeJfhn8StA1OSTTZtb1aKOHf5ocarbwr/C0avvjAPOAF7fly8fxW8S6BLC99p2l3DFt3n3NrJbzsw/ubGWMd+kZ6H0417OW40m5+0WjyWtwVKeZC5ikxnkbgQfStvRPin4l0mKwga4g1C106XzoLe8sortWYYyD5isxHtn3681M6EJ/Ehqp5mro/x9tLfQ7u6n0S+/4SJrWa203UpPETz/2a08bRPIkJiVQwRjj73O0cZNcVZ/ZftloL/bFY3F1FDOzOwCxvIqOwKZIwhY7u20EkKCa6m4+JWlaydUOr+CdEebUihgm02W4sDa4G0lV3urdycrzuPI42yz6Z8OPEllZ2wfxX4dPMk8kkEN/EHXOAzhlcp7CPp6dRUadm9NPz1stNvv6Be56p4T/an1a1TydP1S41AW6g/wDEnvkvEIH3d4RiqkDGQxOTn1r0PwR/wUa1/wAM3YWS/tpnOVMF3YALH0B3NGqgfi3avi3xT8EtE1zTmntte06eOGXy4o7lJbdjkn5tsiADnP4Edepx7nSPEnhu+itrbX7meO3AeOCO+86BR0B8piYz9Mdqh+1hrB3W+jvf7rfmwunufXH7Rnxu1j9sbxb4X0K6vNKGlC5llns7SciDCJud2JZzlYFmwWOFy3Tca+c9duDrvi691W8hme5v5mu4Y79h5aREllRuPmwAq53DBjxzni14J+J/iXw54N1azj1e3uRrKNZX6/2dCrvAysJEVo4gq5XcDzkB8gAjctDSb2SAyoZIkWVpGO7cfMzGwxzgsPnZcOSDvIwQWFQoXlzy6+n/AAfz6g3pZGvqF5HNqEqfZ5GtbhEtI5fLQmJUVZHWN87N5coQ235g2QV3lWJNQvdftpZTePsLJE0chklji37lBd2Ljc3c/KMy5HG7ZmrdRSTidTMk9uSZJPmlUudzKQ24kc9wuPl6cknQuQlxeXMlz9o/tOGZpmxKRNFnDM8+VPJyqnDAg5OGLEnWUlzO+3/D/wDB0/Iyu9i9oulw28I86G0jg1F08qZ5Fj8uNyVVo1kJYqcy5Z8qGiG751Knd8G6de61oUdx5klzYRPLNbwRQtOjIiyPIRF80TSj7RJIVkdgFE4LZJD8/pBth/pLWNvdSySyu0bHaVYoUG7bHyfOkQopcSAhCCAfMrSjJtr+IzRl5dMnK2lpczCWO7QRM6rlYghVCItwXaW3hliJd2BDlVm3ZdtetutvVrfVeSRctVqavhx7aXUEtbS9imWRJYkiikuFR5fJjaKSIMySbCRJGoUPJ+9fC7mjWuj0TUWsPDV1BLexWlrBexzXdvcSzXFrcJLCwiJCSyeaZFWWRgCWkS6d4WiGJBjaRfXcevRyCJf7X3SxukNyUdZ5oolZDK0RJ2vITxmRTvVSzFZX6Gfw6mkS2mmRx+Jvtdm8ZSNoI7cN9qjkZAqgsoBjghcKGIVZCQhNrIZ38MeaKu9ejtsrLv3dr9NVqmnpex4L/wAFLPH8dh8HdJjtkWKbxBfSNI8PlqhSCKMPEV3OxxJLG24lVk8uMKgWJWfnv+CAP7Pcnx2/4KRfDi3+zm4tdH1NNWuycFVit8ztu46MItuRjlx68ea/8FHfiH/wm/xnisIzEo0+0itvMjQql0cb2mI6FyJERiBgmP8Ai5Zvq7/ghP43/wCGVf2Zf2nv2gDe2Wk3Pwy8FT2eiXtxb/aBHrOoEQ6cuzadytcRpGS2ABJz8pYgozjFynfTX8P835/N7nHibymoLyPH/wBtX45wftff8FRvjn8SrabTbvS9S8RvpOmXdiWMF3Y2KpZ2s6scnMtvbW8hI7scAV9A/s5+GDbaZZ5+XA8wBf4s8j/0IfmOa+Lf2VfC723hq0+QBroGYgH724/Kc89gBX6JfAXwh9h0pBjfsCr15YdOvc/r+NdFBPlUF2M5u8m0eseC9ExDE2+M7BtUA44ye3f/AD7V7T8PfDy7Ipdq7uDuwcNzx+HQV534W00SzwrGU6YUZxt9v58j1r6B+EWg5ESpu3bR86/MVBYj14HQV6lNK9omLeh2vgfwOCsMuJHWNskKufQf19elew/sw+C4ZPiB4s8RhMiIpoVq5QqdsLO84OfS4klT6RrzjBL/AAh4ah0Hw39qkg8+LT4muEQgFnIUnaM87j0HqT9K9O+G/hj/AIQ/wZY2LnfOkYe4c9ZJm+Z2PuWJNZZhOKtTW+7+4UVa7N2iiivMGFFFFABRRRQAUUUUAFFFFABRRRQBV1mxbU9LngVzGZUKBh2yK/Pj/goP/wAEqvD3xy0uW8vtWfRNelUpb39vELjeM9JYiVDrgtj5lbkckACv0Rrm/HPwzsvHez7SWUp6c10YesqctVdFJ2P5tviz+wt4z/Ye1uzh1O6trwajFLcW19pU8xj8rKgxMzJGS4wpIGRiROeTXiHxri1TxEuji8kvLv7EjIHkZpPKBbeFBP3QWdz6ZZj1PP8AUV8Sv2TPCPxL8GLouo6LpWpWyvvH2+1S42cEZUMCAeeowa4rwH/wTL+Fvw38UHWNJ8N6RZ6kYmiFwlorMgZWVtgbKplWZSVAJBIJwSK1cqTjyX0/H/g/gaKoup/PR4P+FPiDxYttaabpOo3s8MYVESJpH6k4GOn3jwvua+nf2Wf+CHnxe+I3iGSTWNGj8N6XeyicS3NwjApgYzGrFwx+bhgMHriv3V8C/BDwt8NrH7Pouh6Zp0JOTHbWqQx59diAL+ldRb20dpHsiRY19FGBUyrw+yv6/r0JU7bHxz+yX/wRi+HP7PIt77V4YfFGtRfMJ7mL93Ex67VOR+ee/rX1/peh2miQhLS2gt1Ax+7QLVuiueVSUtzMKKKKgAooooAKKKKACiiigD8uf+Dn2CPVvgJ4KgaYKLO5uZ5Yt+0yB2t409iN2SR6A+lfhDbS+J/hTrdrq+l3WraFdyQy/Z76xuXgkkilWW3lCyxnlHQzROFOGVpFbILCv3P/AODjSeLW38M6UwLq1oCyg9/MkI/HgGvyQ1X4QQTtPJCvkkg8pkbB6Z7/AOfrXRCCtfy1/r09Clc8Ig8USpLumQFsEMysY3GfTAwPyq3a+I7TVJI45LgxiPC7Jo9oPbAKg888Ejn1r03Xvgk10V/0e3uERSBIIzFj05UjnPOT+I6iue1L4B2lxHIqPq+mvtRIVa2W+hdyQGaWVCkkad8JDKwHHJqJRkr31f8AXy/EaujP0a61TQYbm4sLi8trCDH2i6s5t9qmcffKlot3s3POenNdDo/xw1GGZI5ktdUhcghipglKnB+8oKdwfufWsRP2ZfFNnqsc3ha40/xdcQ3Oy0TQrvdqVxKuCTDp0gj1I7c/f+zKPQ96o6j438R+HPEtxYeLdLTUb2G/F1qtrr9mRqFxKAQY7i5+S9CkEZQTp24BArn5IqPa/Xp/l+D018jaNafqeo6V8bNF1EoLmG+sy+csYjPGoHTDRZY+nKAfhXU6Nrmn+JFH9nXlreso3MIWWQgZ6sq8r9CB09a8U0LxT4I8RTWsWs23ifwpJNdSy3uoaIserW9vBgbLe20+Z7eQEZwZJL9iM5wQMVqaV8Lrf4iz6avh3xl4B1a51N5Z207W9TGhXGlRICxku7rURBYIzD5vLgup2BGMnGTm4uNmtb/L+vuN41k9Gj2WOIknvGi5OBlMHg59Px7mqlrpdlaXJnFpb+ayDJRTGAATj5EIU9Tkkc9DwMV5vrei/Eb4SeFtK13WtP8AF2jeHtfJg0rU9TsZTp+ssnVrSa4Ro5Y+Rh4GKkFSDzmn6f8AH+8UOt5YWVyfKDqI2ksz90sSQ3mbuB0G0Z9OlVd7NXX3/wBfcaRmnsz2C1t9Mn8mC4fVNP2/8fNy6pdHZwMRwjyex6GQ8e2TVpvAljLaS3Nlr+nBZJvKs7S7jmtr27GcEsQjWsYGeS1zgY615/p3xZ0HULCGSaZ7GW4I8tJIWZmAz1aPcig4ONzKenQGuh0++stRErWE9rdqg+dradLgRDoQShIHbjjp+NDv9nf+u1v61dyvU6qL4J+KX1Braz0i51uaOE3Mw0OSPWktVKsQZHs3lSPp0dgeDXLpdRFpY1kjeSBvLkTI3RkdmHUEdMYpbm7Elx87FtxyQxJJ9yf88+nSurT45eJ5ra1tdQ1WXXdOsTi1stbRNWsrbGDlbe5Dwjp/crTml9nb+v68/ISSZygaP7KVeDMjuGWYuRtAzlRg7SCSCcgkbeCMsDA6tIAW28/LkDn6Guzn8baVq6XMl74S0L7TcEedqNm1zYSQqRkrFDDItnGxHAP2YjrwRTYbLwbeXIf7X4s0KFowQs9tba69y5OM71NkEXv8qyHg9aOZPV/1/X/ATYuTscZH+55kP+z3xg57/nULThX+UgqMABjncP5//qrtT8KhqFtEtjr3hS9ubjlbZL2WweJcgEyS3kcNuMHjCSuMg4PFVG+FfiPSJbi9uNC1ebSbfDXGqWdqb+xgB5z9piLQNwegkwfUDmtFFSSUWKzW5zluvmygbd4JLOrHhmPX+le7fsmfBzQvE1lrOueIPD0OvafplthbYwM73UxyY402gnLMMZxxnPY14npL2146vG6S7yxDI447g+mOvFfXHgfU5fhb+ydpVjY3psNd8S6t9uS4tWjWa3too2MkoLKdrRMYW3DBGcg8FTVOyi572/4FhWbdj5o+M3hCy8NeLo9GtUjSz0ETSTRJEqeXdTiNpoyQMjCwQqE+6MMQOWJ5W2kXQbadU/1UgKBZm2O+Odx+bIOQMDvnGeOZo7271DTba41LVLnUdQuTPdNfzGOa4ud5cxtMy7dzmPy0Jck4HAx8tVJhDLayLlFffsDKMsU2nnOcDuD93OR1x8vJBWXPHd/5LT5LTt+RUvisWZbNWCSOS8LIPNTzsTTbXCEI2WGAhVgcBSoONxGToaLqNtoBgk8i2uXe3/0y2hAYjZKF2qWQmKVhGjl0JITzAGXzWWPNSSCW0kGGtyxWQI6bEm2gxqTGildyb3c5yNocZ3Z3x3MEA8pGuI2lh3J5oP7lhvZo5hlCXj+YHBUkqBy27ZVrR3T/AC7r8/O/6h0NO3vWhvLS5aYSz2XloHeaNFO4qQzeWVLYJI3FuFWIZQKoOlNpdvpkkNvYJfDUIVVW2Eu93G8ZLGJtqsM+XJt2qU8uRcZKNI+NaNp8qmb7LN5simS2s7K4Zo0cOdkTK3zkH5sMJflDg5kPyNs/bbHTPDNvbwwTTw3MsqT3U4DJax+WVeGPY5LRPFI5cMiuCyjeCHMkOlTnF33016/fZeWv3q1x3szqNPutOutOmaRl0u6s5NPa1S0gja2wBFG15vU5wMSNmIEFiu0BNypq2cqaZ4a0uQCWxuLUXIup5FlZ5VYKD+7OI4AkLW0YDKMyQuC5WJPIwdM1q78R6pe3ep3VxPPLe/vrm5be6tcFpLrhGzIzO5UlWQ72iXdhylcp+0T45nsvgXqtzPb2gu5LJLArJbCAp9rLSII15xiK4upAwJL+b5jM7bPLdo3UpLZP1unf7+1ui9UNa6Hwt8avFz+MPiTqeofv997cNdMrqpKvK5YrgccZx8vXAwB0H2T8UPEE/wCz1/wQm8BeCdP82HXP2kvHlzq91JF8v23RtI2QJbTrzk/2hIZUwQf9H56HHw5qD/bNZuLjaTGZW2DJ4VRjJHvj9O2K+0f+ChWluP2x/h38IwluE+APgTR/DOpR28xkt5dUW3+26lN8pK+a1/ezq/JO6H2xShFKKT6/8OcDbc7vz/yLX7OfgJIpbFWT5Y9oVSMYA6e35dPpxX278I9O+zW0PXK8Zbdx0yR+X+cV83fBHw+Ybu3II2gD2PPH4g4/Wvqz4Vad5rHevmEAANuPTHp1/wA+9erS1+HSxm9dj1jwTovmScrlmIyOmcj1P+fpX0z8C/B8d3NbOUV9h3KCxBBBB+ufxrwz4f26TeTE3kuCMsGJyMevp2r60/Z68Obfs6sOFBwff6+vXv2rtpxunJ7dSHax6rPpAnbSdOkQMssv2iQBekcOGGT6+YY/qCRXX1j6F/p2rXs5+5BstY/myDgBmPsdzbSP+mdbFeJKTlJyY9tAooopCCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD8iv8AgvNdNf8Ax9srbHEVrEB/3wCP1NfA0mlRv5bbeOmV6+h44557V+gP/Bbry7j9o9Vk3fLbRKD0CExJ83Q5HHT6+9fCl1btGn3vcbumf68V3pJwWhSutTC/sxTCH2k7uShTt0HTr/8Ar/FJdKha3UthmXcwwufocj37Y7fWtiW3YuFBVsHkeg4Pp05pttZk9OGGc5c8Z71hPb3i73loYN34QsdYjWK6tba6jfI8t4lkVxj3yPX8/er9lo15HoltpsOoTy6TpuVtdI1OGPV9LtWI5eOzvFlt1bBOGRFb0IrTSNpOv3Rxnucf489/yp1tHtlGAVc8DjpUx5U73CVtmcT4j+AvhDxYsn9o+DbO1c7mWbw5q0+kTSO2PmlW5F9bkZ/ggitxwBkc1zGv/sH6NqTTf2B8Q1sYlVcp4t8P3llJO7bwqQSab/aUJAwq+bdNaD5lJVRk17KpYSZCoAeo7Y/yKni2iA4jZcjOEIH4/wCfSsqjcpe6/wAP6/McUlqzwHwl+y/+0d8EtSm8V/D3TvGCyJaT2t94g+FniEa4thAmXeK4vtGuJ1t1+XeUmkQnAO3HNcTp/wC1Xc3VxZw+JvCHw88d6VpKGO2iutCGlGeUlQ091e6S9nfXcgAYE3FzLlixIPzE/Xtoxi1bT9TTy01TSpRNY3ifurqxkUgq8Mow6ODghkYEGuq1T4v654zn08eNW074kW9iz7IvHWlWnieQxtnfEt3fRyXtujc8W1xER1Uq2DXNOhWt3/B/5fiacy6Ox8PaV4t+E3iK2tLXUNP+IPgm985ri+1TT57XxFanO5lgtdMdbGSNB8o3TanKwGfvnFTx/C3wv4gUyeGPif4Qu5prgW+k6Hr8Nzomr3QDBQ9xNJE2kWhON2ZNUZVUjLdBX0nrf7O3wW8ZLZjU/htf+GW85hPceC/Fd3aR+Wc/M1rqqam00idlS6tlO3Hy9a888Tf8E5/B17pk0vhr4wPp0i3Yha18beDr2wDwZJV45tIbVlbsG8wQH0HJxnNqMf3ifz1W3f8A4PqaJv7O3lp+BzejfA740mG7utH0LXvGdto1vvvb7wnPF400fSIthO2a7sHurOF1VclWkBVRnGK47RP2lLhrdd6adqEMLYmkQGKWXPUb1OwdB/AcZ9+d3Wf+CZXxhXUbufw5oGkfEg6TcLLt8CazYeJ7yEZG2c2NhLJdwJzgGSCMgjBCng4vjv8AaH+OPgPxta2PxJ1LxLrWqeGlNrbaN8SdMXxFHoodRwmn6zHPHbkqoAIiQ4j4Py5Fp8y9x/1/S+ZXtbaNG9o37RWl3dgz3Fpcw79rRiCVJ1UHuxbZ79AfxHNdFpvxU0TUWb7NrFtEShV2lJtk6YK7nCqxx1AJznvXiU/xksPFGhy2GpfD7whPq9/ctPea7Ym+stTIZtxSCBLj+zYFAJwEsgq7VOMdc8674K13VmaGTxp4a06KINCjG216a5kBPDSf6AkSn2R+K6KcG2rNc3Z6f8BW66+hH1hJ6o+ohcHVtNgv4pRcRGNY/MjhUQED5Rh1+Vun3ick9emSqXb2JjkgmmtrqORVjkjP3D1zlcEEewOevGMH5Y0xjYi1u7HxLpcmqTS7IrYNLbz2w29XlkSOBOCB8s7HOQAeK6ay8d/EDTXvtPtZn1uaxHnXN5ZTw6ykSfKAGmHmx4HpuI5bPQ1fJKejhe/bXW34Py6FKvBbu34H0+fjR4h1TV/N1e7j16ZxtSTWrZNXaIHkKhuVcrgj+EjoevFdD4w/aEg+IHhP+zh4U8NWWpXOl/2da6lpiXFnLGhnwyvCJWt8mIMQUjVi0pyzYUD49039q3VrT5LuG0l8liZHmgIdiedgCOqLnJP3c8fhXUWP7WWna1rO240+W1j2ruKXZlaRed3ysE647uemM9MDnzxtNu3z/wCG7/MtTXRno7T290bgS7Yyw3xBF2JkMDzxwpXcBgDBKnO0GonvFEqjcJ4Wi2qoz8mQSOvTaTn0B7HkHltG+PvhXX4vKmnv7a3RR5bzxGUjkb8LF5ny5ZyBxj15OdPSPH/h+SHcmr2HkzybYzNcR2+5gVx8kgDY5JwcdQT05y5k9U0WtTbhiJYP5kCiBIyD5yEH5UAGd2AckZGcqN2duwikktrWeWKEht24LISd2MrhuTgZyTkFflAA3HBL2tPacRNPhYbO4QssisoYsFMaSIwU4Cl8sc4bae4GEvh/Z17M8UdsNssjeSVCgqG3Y+TaFH3goTA+Q8Dim0kr/wBfL5C6mhHqzwafYeQZEEH+kkvcN5BmYx48pEwI32RMhGRlOmNimtK71e7ktpZY3vdOiVJ5oUu7yUi1t3Mke0EsPOLrKY2O3lDJvGwsy4MsMA1OWI+VcxIpV5QwJcNJ/rF3hOvIBYNtVuUXaNmm0Jm1OG7/ANJj+2rG9ndEGCJlRlgEqSNg7AxYb8rtKbSARwXk5WX9ef36ad1rdJhZLU6qGK38FfbIJoni1HTVWKJPKM4t5d8aMzRuqJJ+6MuQUctHNjClWevAf23vGCWWh6PpESRPIolvpJTGw8xULQw7XJPygrKoCkgjDsXdmNevadc3X2C5ghSaaMRsJ3j2xSS2wwXTcwIRvkhOcHb5aYBIcN8o/tUeLm8U/E3UlZn8mymSxKpkCNYQQ2OTnLK53Z+YvknJqavvtJ6LZff917WV127Db5U2Wf8Agnn8PdK8c/twfDm31+K3PhbQ9QTxBr4lG6P+ytNR9Q1HcvUj7Ha3J2j72AMEkCui+EHiLU/2hvjf43+Jmvm3Ot+MtZu9RuzCmEM80z3Eu3uF3TNjnsBXJfs++Kpfhb8EPi34uinKX+p6Rb+C7GRJNk8E2pytNPIB1aJrDT9Qtmx0N4meterfsp+Fhpng7TQeG8lZGOOVLZbjI/2jwfSt6UIqfP0/r/LsedfSx9KfDHT/AJoD1Y7ST0yT0/rX1X8I9N2QI/DbgrHj7x5GPx55r5p+F+n+bcx7VOV2kHHQgent/Svrf4Sae4s7TcpxtySB1HOD/L/69d0N9Nwu7HtHwe8OLdammwgliMu5JOR0zn3x+lfWPwk09NEtJbqdW+z2sTSuxGSABuIHGTx26189fBCygvFhe3VvMHPzIyYIPuB35/CvpHwfpbDToLRHZxqNyplB6CNCXb6ghQh/3/euqtNww75epny3lZnf+G7BtO0eJHA81syy4HWRyWc8f7RNX6QDFLXhpWVgCiiimAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAfkx/wW3gaT9o+I/L/AMekS5wAf9WveviC7s1cnI4PByOv+cV+gX/BbXQn/wCFu6ddeW5EtsgBHcBVH9K+DJ7YoN3uMY4P0/nXpRjeMbPojRbamUlnk4Xvyew9M0ySEDZvUHYc8k5OcA1rPAGUA8DHzEdfpUBhdSck4bIxnBI69Olc9VSu2OCXQoxReYrAdh0I6+vX61JDa722/KExtJx27D61K1t5Lj5d54yAcE98/r1qSOHKMTnHAPb/AD3rHktoWV4osSnhl+XGSOv0qRd8cjFhyTz/ABcD/P8AL6VYFvuHABbHPbPrUhtmD5CkHP8Afx9O3+c1npey3EVlX584U49Djn/P/wCqlZCGKqyDjOSfmJGf8asSQFh6lhkrjP8An/69OK7XOcAEZH+A71UHJtaidkVSmF6buch8dfbiqxVVLnlcAAYyep55/pz/ACq28aiQY3YCnJAxjv8AlUbxean4ccZP+f8ACrlZbDXcyte0y01u3eO/tbe8hfBZJoRIpxjqCD0FdHo3xz8a+F9Fj0aw8ceLE8PQQ/Z/7Cu9Tmv9E8rr5TadcGS0kj6ZR4mU8jGDWRMu+M5BZohtxnt+FUrlPlJXuMhgevU1TpQlLmkk/PS4ueSVir4w0rw94v0+SLXPhj8IdeuVRgl0PDsnh5oMjHCaHcadC3TrLFIcgds15P4i/Zi+H2rPmDRfE+gbYCsj22uQaqs7knJjt5La2KLngK91JgDqeteo3iujcBe2QoC+g/Ks26XzY2ODu5JJ655BzxRCEabvFfrp87/gQ/e3Pn7Xv2SoNPgeex8RGLBLeTqmiXSyyKQAqqLIXiZOf4iMDJ9xwGt/BDWdCsyZZNIlTaqoBrFrHPKWPy4tWdZ2JAIx5eec9jX1ldDdnkkj7vPP49qzZLh5oHRxvHTBxwD15/AV0/u5e6lb+vP9A5WndM+Utc0bxl4a0q1bWrTxDaWEeFgGoW80dtwcHaJBtxyeQCM/kcpvEMl/eJ5sGmwheY/9EWJRgHGNg6cY59Rk9SPp3UfBGkSyiYaZaRXEYAeWGLy5PT76YbjPrXMeIPgzomuzfe1KCXczbzN5ztuI4Pmh89v88U0m1pL5N3/yM9uh8/f2sIt0MkM8fzFSiy8HPUAYzyOD9OelSS6sojxDc3MTIAyo6naT2LfMxzjtivUdc/ZdtXbdaajtQ43iaDd154IZV9T09K5zWP2cNUt4WWGWzuU+9lZmV36nO0rgc/7X9c88qbUbSVzReRxf/CUalBfRzLc28kqfdkLbWj46ZOCP8jtXRaX8cvF1pdIGvdUufLwY1N00kcbZJBCsSucsx+pzWbqXwX121cEWcxz8oYKr7gPZTnqPSsS48Mavoc7tLbXMaM3ytLG0avjPA3AduxrllT5Xsae2l3PV/Dn7XviPSbyTzbyS4V4hbyRSwRiERhlYAlAGwrhSDngquDgCuq8N/tdT3VzD5tnpSmNcE2yzQnepO19xdynYHbjpuGDzXgFvreozRqs1xLPGPlUFzIoGAOnI9cfjWtYX9taWLmWCzaZGDM23Zu5+7nGcdOnbnoRVWT3k/n+XcpYiXY+hLf8AazWbSfs8GkwJcSQLawyx6gzK+xi43r5QDqrFDt4OI0AZdpZvnLxBFcyTPdSiUw3Ksls7j/j4UOVds55+dGUn1RhklTi1oHjFvD+oi8g0/R5b61k8yI3lnHew8A8PBMHhkQk/ddGHy9KXxj4t1z4keIZ9c8R6tfanfXgihmu7y7eWUxxRiKKJS2TsjiRIkQcIqKqgBQAqdO1ur/L8Pv8AlqyalVyVnoirdNL4hsvDvhhVUZu5LmSSNPnYy+WhzzyEWMsPTe/qa+2Ph5ZW9j8sCsIW+WLIw6rxsyBwDyOnH4Gvkn9n7TW8U/FWK+b51s0ZgCNyHAVAM59GJ4x9ea+yvAtvtZWb5Rt4zyMVvu+b+tFZGaVtD3D4N2gF2rOV2g/KxXp0GePbtX2D8FvD4uRZ5TIz5e09wME9c8dT+P5/LH7Ommm7voi8LeXnIUrjIxjPPpX238EdDL6da4jPXduIOQOhHTjiu2jZu8h6nu/wi8Jr9kdHQ7GPIJzxjceew5/LP0r2X4WMuqatqE8XltbaYfsELI24GThpvxDYQjsYzXBeB5U8MeCJruaDzfs6NO8MTAu21d20dix6Aep7jFer/DPw8/hnwbaW8203Thp7hlXbulkYu5wOOrGox87Wpr1f6Ed2b9FFFecIKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD8/wD/AILbeFjdWHh/UcfLHAYSeck72P49vevzdmtlQ4x0x9f88V+u/wDwVt8EyeJv2eYbyOLzP7NuCWOOm7GP5EfjX5K6hGFXGMkHkLz/AJzXo0YylS90q+hkXMCyFC+1mycc9T15/P8AX61UdDuG4cZAGOB0/LNaro5iJZD1+YdNvPv6Ux4QrsFDj5up6Hjnn6fzorx5Y6F3MsxM7lCOVGCRyT/9en7CsiblOAxG4jg+wz7GrctvtOMgqe/TgHHPt/hTYm2rwApxwcnAPTnvWE9FzdQvcrQyMzYI3KOg9ef/ANVJ5fGc4B5yBgj6/pxV2OMuG3DHOFAOQT6/rj8TSuhhf5Qfu8nAOT/+v0rlinuwuQKu9/vHzDk8AnI78fT+VRKPl+ULnlgc9TnH+FWGjCMCrHkdh36D+vH/AOumbGMR4xnlvQ++TXRJuTUl0DcrOigcAc5JXOcDmoRGs6Dgn3zzjt+P8qum1yTgbs9eTge4qCW3aONsfwE47e/fv/n1pXgkF10Kbx8+hxlRuA6+vt/n3qrcLsTrzjJJ5yO38uatSJvk+fK7lz0xg9KrSIzI3bqMbenU5P8AntWkbct1uFjJv7fzI32tHsIAU89Ov9aybmEptzv7kDH3vT0H/wBety8BkYsyNuJ2kY+906ism/j2xk4GQMlentgf/r6ClNJRuTrfQx5ZfLP3t/IK8dfX3/8A1cVSuEE8wK5LBhkq3J5PA/CrV/H+8Y5bdg4wMZ/z/OqLXOJDym7hmIHT657elNWkrFFXUWeOPdGziQg529GHOf0P61j30X7sMhf5OBuwcHsMfgOvcGt2eMPGqjjJ+YHKk+n+fb2rNu7IGT5vvMfnGeSOn9KqFmyOXWxmxXWWCN1PGPX6e9E1wpXdswMYXgdPT9aiv7Zoh/s9hnp/n1qtFcbDtb+InBI4HP8A9ah+Yrj5G81tp6npz14HNVJkeKdTtQsjFvmAYEgcZB4P4girU7F1yo5HXJ+lNRVlVWfjDc7TgkZ5rG6Ssi+V3uc5rnhew1NMXen2k5I4aWEOwU9uf8/lXPaz8L9FvJWRrPZ8nWGRlC/QA7Qfb6V20o8yUgnI+vT0/wDrVUuQTKPNJkyRhtpBPr9e1TNJqwNWPMdR+EEFo2+zu54mjOeSMKe2CACO4zXGat4OmgnO6Zfl53KuN3XOBz14r3S5twGIywbBzxkY6H6557iuR8W6KZHVzkkHAOM9uD+o6fh0op+8uWwtR/7M9qmka4VHlgF8kqg34YAEEgZxheOeMn1NfYPgWw8+SEsIyMD5Tn5ffH4mvkb4PP8A2Z4htmDELuHfO8k9cV9rfDfTRcW9sfn7MxChiPTj/PetYxbj7w0e/fs/Ilpr1hEx+8VAOOrMQFH1JOP07ivuX4J6Z59vFxhVcAADjPX0/wAj8q+N/gjoYmvI3AOCV+YLx78c9Pyr7l/Zw0qae0gjaWSTbgsxIUudxxwMZAU+36nHfQXLZPUGup7LYaSviHxRomhfI0cWNT1BB1EaHESkdcPLgg/9MWFewgYrjPhVarql9q2tdVmm+w2pxyIICw6+8plP0IrtK8utU55uRD00CiiishBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAYfxG+Hum/FLwfe6Jq0bSWd7GUYocPGezKexHuCDyCCCQfgb9of/AII0akJ7q/8AA+owaihLOlnOwgnyXO1AWPlkKpGWLLnBwvav0VorSFWcPhYH8/PjrwNqXw+16ew1K1lt542IO6Ihs9zj/wCtWA88UULbsY/hLdVx3/z71+1f7Uf7A/hj9ouOW9TZpWtSZZ5RHuiuWx/Gv8JJAyw9WJVic18Y/EL/AII0+NrS/wBmlQWOpJjcJbe7jjjB9MSFD/47T9srao6lCEoq0vvPh83QACls8HBPUZ4J/wA+lNjbB7bhyASADjjpX2l4W/4InfEHWvM+13Ol6KUUhPtN0rhvYeUH/kO9eafF7/gmR8UvhXE8txoF1eWiI7NPbILiJI16s7Rlgi4GfnwcfStU6fLozN6aHzwJQF43Kp6ZHB7/AM6MqZH5Bx29fTH51rav4F1LR5XE1lNEe7FT82e4PpwR+dZZPkRhCm1lIHQZFK6cbRWpIYC9dvPJBHU1Cs+T8wJyRwCee9Pk9BgjABwecfT/AD/SoR/q+P72GWqnzP3Zbh0uAmEiHvgdT0Hp/n3psjbmQAkE5yT/AA++Mfypk42En7z+4JJ4/wD1fkKaQu45bB68L938KUsOurK9CK4O07VywP8ATNV5bcjdwwyDkMR0x+dTZVx2dfujHv8A/rpkigJjO3jI2np/+rFUovtcNSheQ4j2lmXPI9B6Z/Osm8jVhgbWfAxt6AEdOT/nPvWxfKVU5lDA4yVXOPqP/rVnXkvmQKpjO7OEIHTkg/5+layjfYi7asc7d24LcNlsZ7dMfX3/AM4rKktRFyPTHzdP17Z/z3rpLu0Dtzgjo/BwMdP54rHurDyGWT+8S3OCDnrx9M/T8qhJRauUZcz7dwPmKcFcnn6is67tzCwdDtULyM9enYVt+UhfGV+76dKzr/TAwJwu49Tjvxx7f/X/AD1urqTC2phXDhiQSTjAxjrx/n/PFUZ4FI+Xb8xzkDBPb64rXvrfld+eh79OenT9KpTWpTHT3yaxknfUGjMhYQyKzOcODk8fnUqXCxbUVC2McDv6U6a3DPsJ75A/z/nioXRoZuF+YHhevocEenFY2s9BoHJAY7Oc4OCCcD/IqiEZd3OFOVX3JzWiGNzCvyLE5+9n16/5/wAaQ2PPX7xxyfel10H5Mzri02npGTtHBBIJ78Dvj1/WsPWdPF/bEspkEgwyg7ckHnrXWLCFIIwvJJ/2sY596zNVsfkYDBHfPG485/X1rSNtJC5U9jk/BlqYNchOSxVxg52g56c9xwf/ANdfcfwatw+k2LZfYV5HOW6H1+tfGeg2hj1bcwRC75G0fTGBxxx7V9t/szWw1XSrI4chVAj2nGOfr65o5tLExWp9afs7eErmRI2WDO8Ahwe2ec556f5719xfCDR30TSpbhIEim+yiNA671knZtsYxjONx5OOjdq+a/2bPDeI4AV4kIPL45/z/nivsb4b+HlufF2nQbUKWKtqExI5LY8uH8OZDj1Qelds04UHNf1cXMm7HpfhHw1B4O8N2WmWoxBZQrEuSSWwOSSeck5P41pUUV5G2iI3CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOT+InwJ8H/FiGZfEPhzStTedBG88kAW42joBKuJB+DV89/FT/gkF8N/HBnl0ea/8PXEzhlXAubeJe4Cna5z6tIa+sKKabWw7s/LH4p/8EVvHfh9WPhy40vW43kYIsVyIpFXHDN5oQD6KW718z/E79kXx58KbpF1jw5qVmZ92zzrd4vMK5yVBAyODyM/yr95qjuraO9t3hmjSWKVSjo6hldTwQQeCDVKb5uZ6j5j+dvUtAudNBWW3niK8AMn+fT9Koyx5bBjJTqcevboM1+7vxI/Yc+FvxRtit/4R0y1kEbRxy2CfZDGTn59qYRmGcgurV81/Fr/gh/4b1v7RN4V8RXFi5UGK3voshn6EtKmMD2EXYCtYVIuyqDTR+Vkqb2wW9h05Hb/PvUC/6xTtc5HduD+dfYPxc/4I6/FD4fLcSadYRa9aIAfN05/NLk9QsfEpxjrsFfO3xA/Z68XfDrUrm01bRNRsrqD5pLeaErJGCMjKEZHHQY5zVxknL3WVqcBP+4j3Hd8pGDn7vp/P9Kz7s4ckAsDkYHU9cfz/AM9a1r7Sri1dvtELptHRs5H+f1rD1I+XIowFxgIAflP0H510SVtQ9CldS8HADcZ54yMdB+XtWdqLAszgds4HYfU/T+VXrkMGzhiu4MAO/wCg/wAelZ93EH6rk45Xpn/OP5VHJZXYkZtyuZiSGAzxx0PTJzx/+qoJJ2RpFSR0EiFJFVm+ZSd2D7ZANWrmJFlbJOR6n+Q/Oqk/mLGeWOehPCg9xj8a3cYvdaieiMy9jURMzbd20nGcAj8euKpzJlcHJ6k8d/bjjoK0r63DRrs5C9QVHJ7f59/eq06Zc7ssCM5PPPp078VHIm7JCi1bUy5oMkbud2MEnpx2/wA/zqvcRKy/dOAfxPHp+Pf1PatOaIP90h2UAE5O0enX0qFk8qTk5U9fb9K5vZST0ZSZmi32sduTnPQ89vXv/h9KsRoGaPLFsHjcOc+lPkt952jgYJyD0+gpIlWM4wM47e9CWty7q1xotEkHKbTwOF+v61Wv9PBtz8uNpxuDZ9/85q9boJZfqOB3/X/PpS3MJWHoWI/yOafLcnyOfstO23asSfv5GOSffn14r7J/Ykt0uYoQP4SASeSDj8e2ema+SI7WOOVsDJGD0C9cdD7V9ffsGuTdQxhQSGONpByemc59B+p/HTDpc95bBa6P0q/Zm8Nec8KkM6lcleu0fn69ef8A6/1Z+zzYXEvhq+1W78vzNUvJTbmP7v2VHZYcemVG4+7se9fOfwd0ltJ8G2y2zeVfay8djaMnDo78Fgf9kEt/wA+1fYOgaPF4f0W1soAFhtYliQAdAoxTx0uVKn8/8v68yLrWxcooorziQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAGFsMacDmjvS0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFUfEPhrTvFumPZapYWWpWcnLQXUCzRMe2VYEGr1FAHh/xR/4J0/CP4rR3JuvCttpt1cqFFxprG3MOO6R8wg/9s6+b/i1/wAEF/CviJ7mfw34nuLE7M21ve2obLgfxTIRgfSLgdq/QCiq55LqB+OHxL/4IT/FTw3Mo0b+ytcQoWZ7W8jVE/2SJvLZjwOi9a+aPir+w18S/hJF5mt+EtasbUuY1lubN4lmYHnaWUbvwz196/omoreGJklZ6lcx/MFrvg3UtHlxdWNzEQx3BkI/XHv9K5+7R4SF/eZySRX9LHjz9kr4afEuC5TWfBHhy5e8JM88dktvcSk9SZY9sn/j1eA/FD/giJ8FviBLPNZW2r+H5XTbFHbXCywRt2JEitI3uPMGea3WLi7aWBNdT8HJI967V3AEjADYxjtmqTWwZmBXO4FsL37YB7V+rXxU/wCDc++PPhTxnpt2uDuF/DJaEH0UL5oP1LCvm/4n/wDBED42+AIZpYfD8ur2sR+R7GaO5eTv8saM0n0JWj2sJyvcenQ+LPnVv4Q27IGMbvbr7/yqNjiJTjByVI7+gxxXpnxL/ZL8e/DC++x674Z1LTroKD5NxbPFIfT5WAPb0rz3VfDt/p8o+02k0ZI3Hcp/z/n60La6Yyq6bCvykDIBwCOev/66Zv6btrcd8+np+FMkQsmJFdD3UjOR9acki3EPzxFgepGCMYPb8up7Ed6pNNaD6Eog3SAglgO/9B6/596W5TaMFVGAFBHGfU8daUsVAUtuQZyAMY9eB0zSyQtINu0gEnAJzjp1/SqgtPeE7GbbIXuSADwQdxA54/l/Pmvsj/gn7+98RWC5BVZUBwPv545xgd8fienFfJVlY75Y/lDo/O3dgZ9c+nX8voa+2v8Agm7psVj46sZ7lQIrR/OkJG7hOvXj1P1961oxjKfIyr+R+r37Pfg2HVPH8ZUyfZfDNqjMjcD7XKMjj/Zix+Mhr6DrgP2b/Dc2jfDaC8vECahrbtqFwMcrv5VPoq4Uewrv683EVPaVHIzl2CiiisCQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAE70hO2nU16AHUUinK0tABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSHpS0UAVL3S7bWrOWC5t45oJQUkjkQFZB3BB6ivJviF/wT++DvxPgCar4A8PYB3ZtLc2RP1MBQn8TXslFAbbH5O/8FNv+CJ2i+E/DVx4v+GlreQ2VujPe6cp877GBz5qZ+Zo8feBJK4LElSdn5ka/8HNS8PXxhd1zGSpSRdhBx6c8/wCFf1LTQrOm1hkV8vftM/8ABJv4a/tBGa7trY+GdXl/5eLOMGBjxy0OQOgxhCg5JOTTjJqV76HTSnDaoj+fRvDd7aOfMtiT0DI+cnocdOevTt9aIYMiTLuAeowfmyOSePev1E8e/wDBvb4rF5KdF8UaFcWpY+WJ3lSTGe67Co4J6N/jXI2v/BvZ8R7++Pna54ctojyT9okJH5RmvQp1tC5wo2vFn54aPD591wJWhU/MWGFQf7RPAH1x3r77/wCCS3wruvjP8Q7QWML3GmxSK1zdhD5IVWBZVb+Idtw+XjjcCSfZvhZ/wbpadb6hbz+LvFst9bxsolsrOIosqgn5TITu28+gPb3r9DvgT+zv4T/Zy8G2+ieFNJt9NtIEC/IPmf3J7n370p11FJrcw5orY7W0tVsrWOKMBUiUIoHYDipKKK8/cyCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACkK7qWigBAMUtFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABSbeaWigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA/9k=)"
      ],
      "metadata": {
        "id": "xwGUBX9CHGGe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG6JRjlfVVy7"
      },
      "source": [
        "## Einf√ºhrung: Generierung und Dekodierung/Klassifizierung von DTMF (dual-tone multi-frequency) Signalen <a class=\"anchor\" id=\"part0\"></a>\n",
        "\n",
        "\n",
        "Das Dualton-Mehrfrequenzwahlverfahren (DTMF) ist ein Signalisierungssystem f√ºr das W√§hlen eines Telefons, das in den fr√ºhen 1960er Jahren von Western Electric entwickelt und sp√§ter von Bell System kommerziell an Telefonkunden geliefert wurde.\n",
        "Wenn eine Taste auf dem Telefon gedr√ºckt wird, werden zwei harmonische Tonsignale erzeugt, und die Superposition/√úberlagerung beider Signale wird verwendet, um die entsprechende Telefontaste zu charakterisieren. Wenn zum Beispiel die Taste ‚Äû5‚Äú gedr√ºckt wird, entsteht ein Dualtontonsignal, das sich aus den Frequenzen 770 Hz und 1336 Hz zusammensetzt. Die beiden Frequenzen, die jede Taste beschreiben, sind in der folgenden Tabelle aufgef√ºhrt:\n",
        "\n",
        "|   | 1209Hz  | 1336 Hz  | 1477 Hz   | 1633 Hz  |\n",
        "|---|:---:|:---:|:---:|:---:|\n",
        "| **697 Hz**  |  1 | 2  | 3  | A  |\n",
        "| **770 Hz**  |  4 | 5  | 6  | B  |\n",
        "| **852 Hz**  |  7 | 8  | 9  | C  |\n",
        "| **941 Hz**  |  * | 0  | #  | D  |\n",
        "\n",
        "In diesem Beispiel werden wir uns ansehen, wie man solche DTMF-W√§hlsequenzen generiert, sie in einer Audiodatei speichert und das Audiosignal mit einem einfachen KI-Modell wieder dekodiert.\n",
        "\n",
        "Wir werden die folgenden Schritte durchf√ºhren, um ein DTMF-Signal zu erzeugen und mit einem Klassifikationsmodell zu dekodieren:\n",
        "1. Erzeugung des Signals und der Audiodatei mit `scipy` und `numpy`. Wir speichern die erzeugte Audiodatei in einer `.wav` Datei, die in diesem Notebook oder in deinem lokalen Audioplayer abgespielt werden kann\n",
        "2. Wir laden eine einfaches KI-Modell, das die Klassifizierung der Tonsignale vornehmen kann\n",
        "3. Extraktion der gew√§hlten Tastenfolge aus der `.wav`-Datei unter Verwendung des KI-Modells\n",
        "4. Quantisierung & Export des Modells nach ONNX im FP32 und FP16 Format. Quantisierung nach INT8 und Export nach TensorRT.\n",
        "5. Laufzeituntersuchungen f√ºr FP32/FP16/INT8, unterschiedliche Batch-Gr√∂√üen und Signall√§ngen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNXOs32MVVy7"
      },
      "outputs": [],
      "source": [
        "# TODOs:\n",
        "# Profiling in ONNX/TRT\n",
        "# We need to add the DTMF model artifacts to the assets\n",
        "# We need a TRT model which supports longer sequences for the accuracy!!!\n",
        "# Analysis in Frequency Domain\n",
        "# [x] Try to use ONNX INT8-model for TF\n",
        "# [x] Run an already quantized ONNX model in TRT without setting any Flag like INT8/FP16\n",
        "# [x] Look at results of quantized INT8 ONNX model for DTMF\n",
        "# [x] QAT of Tensorflow -> tf2onnx -> ORT/TRT\n",
        "# Hinweis Laufzeit neu starten in rot\n",
        "# Numerierung der Abschnitte\n",
        "# Merge to master branch and change installation instructions in notebooks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51a6fcd-760a-4926-8d68-7f75eddb906a"
      },
      "source": [
        "## Signal- und Audiodatei-Generierung <a class=\"anchor\" id=\"part1\"></a>\n",
        "- Im folgendem Widget ist es m√∂glich, eine Nummer zu w√§hlen, f√ºr die ein DTMF-Signal generiert werden soll\n",
        "- Falls im Widget keine Nummer \"gew√§hlt\" wird, wird eine Default-Sequenz angenommen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9360855-39ba-450f-975b-ebd7f48a5521"
      },
      "outputs": [],
      "source": [
        "# First import the necessary libs\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kR8O3oWRKR"
      },
      "outputs": [],
      "source": [
        "# @title Tastenfeld-Widget f√ºr Generierung der W√§hlsequenz' {display-mode: \"form\"}\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# from IPython.display import display\n",
        "\n",
        "# Initialize a text widget to display the dial sequence\n",
        "dial_sequence = widgets.Text(\n",
        "    value=\"\",\n",
        "    placeholder=\"Dial sequence will appear here...\",\n",
        "    description=\"\",\n",
        "    disabled=True,\n",
        "    layout=widgets.Layout(width=\"300px\"),\n",
        ")\n",
        "\n",
        "\n",
        "# Function to handle button clicks\n",
        "def on_button_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    dial_sequence.value += b.description\n",
        "\n",
        "\n",
        "# Create buttons for the phone dialer\n",
        "buttons = []\n",
        "for row in [\n",
        "    [\"1\", \"2\", \"3\", \"A\"],\n",
        "    [\"4\", \"5\", \"6\", \"B\"],\n",
        "    [\"7\", \"8\", \"9\", \"C\"],\n",
        "    [\"*\", \"0\", \"#\", \"D\"],\n",
        "]:\n",
        "    button_row = []\n",
        "    for label in row:\n",
        "        button = widgets.Button(\n",
        "            description=label, layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        "        )\n",
        "        button.on_click(on_button_click)\n",
        "        button_row.append(button)\n",
        "    buttons.append(widgets.HBox(button_row))\n",
        "\n",
        "# Create a clear button\n",
        "clear_button = widgets.Button(\n",
        "    description=\"Clear\", layout=widgets.Layout(width=\"158px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "back_button = widgets.Button(\n",
        "    description=\"‚¨Ö\", layout=widgets.Layout(width=\"50px\", height=\"50px\")\n",
        ")\n",
        "\n",
        "\n",
        "def on_clear_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = \"\"\n",
        "\n",
        "\n",
        "def on_back_click(b):\n",
        "    \"\"\"_summary_.\n",
        "\n",
        "    Args:\n",
        "        b (_type_): _description_\n",
        "    \"\"\"\n",
        "    global dial_sequence\n",
        "    dial_sequence.value = dial_sequence.value[:-1]\n",
        "\n",
        "\n",
        "clear_button.on_click(on_clear_click)\n",
        "\n",
        "\n",
        "back_button.on_click(on_back_click)\n",
        "\n",
        "# Display the dialer\n",
        "display(dial_sequence)\n",
        "for button_row in buttons:\n",
        "    display(button_row)\n",
        "display(widgets.HBox([clear_button, back_button]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V728NfPmsAQr"
      },
      "outputs": [],
      "source": [
        "print(\"Gew√§hlte Sequenz:\", dial_sequence.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8i2MsZF3o0g"
      },
      "source": [
        "### Generierung des W√§hl-Audiosignals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAyM34wYqx_A"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    # length (randomly sampled in given range, or scalar) of the key signals (in seconds):\n",
        "    dur_key=(0.2, 0.3),\n",
        "\n",
        "    # length (randomly sampled in given range, or scalar) of the pauses (in seconds):\n",
        "    dur_pause=(0.01, 0.1),\n",
        "\n",
        "    # You can vary the noise level here (sampled from given range, or scalar value):\n",
        "    noise_factor=(20.0, 60.0),\n",
        "\n",
        "    # Frequency range (in Hz) to produce noise:\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62132ef1-c61f-4653-9f6c-a4d9f892781e"
      },
      "outputs": [],
      "source": [
        "# Either use the dialed sequence from above:\n",
        "my_dialed_sequence_keys = dial_sequence.value\n",
        "\n",
        "# ... or generate a random sequence:\n",
        "# my_dialed_sequence_keys = \"\".join([random.choice(\"1234567890ABCD*#\") for i in range(10)])\n",
        "\n",
        "# ... or use a simple sequence for debugging purposes\n",
        "# my_dialed_sequence_keys = \"1234567890ABCD*#\" # for debug purposes...\n",
        "\n",
        "# ... or use a slightly longer sequence (which also contains all symbols)\n",
        "# my_dialed_sequence_keys = \"91D282A0B8C16C*C9#504979D#443B\"\n",
        "if not my_dialed_sequence_keys:\n",
        "    my_dialed_sequence_keys = \"9128A08C16*C#547D3B\"\n",
        "\n",
        "# Try changing the following arguments: dur_key=0.05, dur_pause=0.02\n",
        "my_dialed_sequence_signal = dtmf_gen.get_tone_sequence(my_dialed_sequence_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-9x6ncx3wiD"
      },
      "source": [
        "### Visualisierung des Signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aarMEIq3vS0m"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Das vollst√§ndige gew√§hlte Signal\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWiuyJ_7BUS6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal[: 10**4])\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Die ersten 10000 Datenpunkte des gew√§hlten Signals\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJe9QX8Ee9aA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "quant = np.quantile(my_dialed_sequence_signal, 0.99)\n",
        "start_index = np.where(my_dialed_sequence_signal > quant)[0][10]\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Weiterer Zoom-In\")\n",
        "plt.xlim(start_index, start_index + 1.5 * 10**3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42af11c2-3c15-4a57-afa8-f62b8e82925d"
      },
      "outputs": [],
      "source": [
        "# Now let us listen to the generated WAV file\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "wav_file_name = \"my_dtmf_file.wav\"\n",
        "\n",
        "wavfile.write(\n",
        "    wav_file_name,\n",
        "    dtmf_gen.get_sample_rate(),\n",
        "    (my_dialed_sequence_signal * np.iinfo(np.int32).max).astype(np.int32),\n",
        ")\n",
        "IPython.display.Audio(wav_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51a52767-7e0e-444f-8028-f5a52fce4820"
      },
      "outputs": [],
      "source": [
        "print(\"Gew√§hlte Sequenz: \", my_dialed_sequence_keys)\n",
        "print(\"Anzahl verwendeter Zeichen: \", len(set(my_dialed_sequence_keys)))\n",
        "print(\"Gesamtl√§nge des Signals:\", my_dialed_sequence_signal.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b763fef4-360e-4a01-910b-add573007fd3"
      },
      "source": [
        "### Signal-Spektrogramm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7827a985-0dd0-40c0-993c-e002523ef0e9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "Pxx, freqs, bins, im = plt.specgram(\n",
        "    my_dialed_sequence_signal, NFFT=1024, Fs=dtmf_gen.get_sample_rate()\n",
        ")\n",
        "plt.ylim(0, 2000)\n",
        "plt.xlabel(\"t [s]\")\n",
        "plt.ylabel(\"f [Hz]\")\n",
        "plt.title(\"Spektrogramm des generierten Telefonw√§hlsignals\")\n",
        "plt.show(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aio7fvyo4ZUy"
      },
      "source": [
        "## Laden & Konvertierung des vortrainierten Keras Modells\n",
        "\n",
        "Optionale Fragen:\n",
        "- Wie k√∂nnte man mit einem klassischen Ansatz oder auch mit einem neuronalem Netz die W√§hlsequenz extrahieren?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHys5X74cRB"
      },
      "source": [
        "### Laden des vortrainierten Keras Modells\n",
        "\n",
        "- Wir verwenden ein vortrainiertes Netz um uns die Trainingszeit zu ersparen\n",
        "- Das Training kann weiter unten reproduziert werden\n",
        "- Modellarchitektur:\n",
        "  - Im Wesentlichen ein sogenenanntes Conv-Net (Fully Convolutional Net, FCN)\n",
        "  - Einige Downsampling layer (MaxPooling) und Upsampling layer\n",
        "  - Input: Ein Batch mit der Dimension N x T x 1, wobei N die Batch-Gr√∂√üe und T die L√§nge der Signale darstellt.\n",
        "  - Output: N x T x 17, wobei wir nun 16+1=17 Ausgabesignale haben, ein Signal pro Taste (0,1,2,...,*,#,A,B,C,D) und 1 Signal f√ºr \"keine Taste aktiv\"\n",
        "  - Output-Schicht: \"Softmax\" layer. Bedeutet, dass jedes Element in einem 17-dim. Vektor eine Wahrscheinlichkeit darstellt und dass die Summe √ºber jeden 17-dim. Vektor genau 1 ergibt.\n",
        "\n",
        "\n",
        "Optionale Fragen:\n",
        "- Gibt es andere/elegantere M√∂glichkeiten um insbesondere ein brauchbares Output zu erzeugen (anstatt eines N x T x 17 Signals)?\n",
        "\n",
        "TODO: Einf√ºhrung: Was ist die Eingabe/Ausgabe des Modells\n",
        "Was ist das f√ºr ein Modell, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4Tks3yH0ipe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "keras_model = tf.keras.models.load_model(\"dtmf_classifier.keras\") # TODO: load from assets\n",
        "keras_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize using Keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Plot the model graph and save to a temporary file\n",
        "plot_model(keras_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, dpi=60)\n",
        "\n",
        "# Display the plot inline\n",
        "display(Image('model_plot.png'))"
      ],
      "metadata": {
        "id": "krT-bqjRHk0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kesc3J6SUBOv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "length = my_dialed_sequence_signal.size\n",
        "keras_pred = keras_model.predict(my_dialed_sequence_signal[:(length//8)*8].reshape(1, -1, 1), verbose=0)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Inferenzzeit:\", round(end - start, 2), \"Sekunden\")\n",
        "\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(my_dialed_sequence_signal)\n",
        "\n",
        "for key_idx in range(keras_pred.shape[-1] - 1):  # last index represents pauses\n",
        "    plt.plot(\n",
        "        keras_pred[0, :, key_idx],\n",
        "        label=f\"{dtmf_gen.get_key(key_idx=key_idx)}\",\n",
        "        color=colors[key_idx],\n",
        "    )\n",
        "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15), ncol=8, title=\"Prognostizierte Tasten\")\n",
        "plt.title(f\"Tats√§chliche W√§hlsequenz: {' '.join(list(my_dialed_sequence_keys))}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_zpgnG6CviY"
      },
      "outputs": [],
      "source": [
        "predicted_key_sequence = dtmf_gen.decode_prediction(keras_pred)\n",
        "print(\"Prognostizierte W√§hlsequenz:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlich gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-97qYaeo4k86"
      },
      "source": [
        "### Konvertierung des Keras Modells nach ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0niGbjMEhna"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "import tensorflow as tf\n",
        "\n",
        "# This line sets the output names for the Keras model.\n",
        "# It might throw an error, but the ONNX model should still be exported correctly.\n",
        "keras_model.output_names = [\"output\"]\n",
        "\n",
        "# Define the input signature for the model.\n",
        "# This specifies the shape and type of the input tensor.\n",
        "# 'None' in the shape indicates a variable dimension, meaning the model can accept inputs of varying sizes.\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, None, 1], tf.float32, name=\"input\")\n",
        "]\n",
        "\n",
        "# Convert the Keras model to an ONNX model using the specified input signature and opset version.\n",
        "# The opset version defines the set of operations available in the ONNX model.\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(keras_model, input_signature, opset=18)\n",
        "\n",
        "# Save the converted ONNX model to a file.\n",
        "onnx.save(onnx_model, \"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-CLAhtx4tTw"
      },
      "source": [
        "### Optimierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5PAAutNg2bE"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "import onnxsim\n",
        "\n",
        "# Define the path to the original ONNX model\n",
        "model_path = \"dtmf_classifier.onnx\"\n",
        "\n",
        "# Define the path where the simplified ONNX model will be saved\n",
        "simplified_model_path = \"dtmf_classifier.onnx\"\n",
        "\n",
        "# Load the original ONNX model from the specified file\n",
        "onnx_model = onnx.load(model_path)\n",
        "\n",
        "# Check the model to ensure it is well-formed and valid according to ONNX standards\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# Simplify the ONNX model to make it more efficient and easier to understand\n",
        "onnx_model_simp, check = onnxsim.simplify(onnx_model)\n",
        "\n",
        "# Ensure that the simplified model is valid\n",
        "assert check, \"Simplified ONNX model could not be validated\"\n",
        "\n",
        "# Save the simplified ONNX model to the specified file\n",
        "onnx.save(onnx_model_simp, simplified_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9OUrzZa-bgt"
      },
      "outputs": [],
      "source": [
        "from techdays25 import onnx_utils\n",
        "\n",
        "onnx_utils.netron_visualize(\"dtmf_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0s4ULT84ynC"
      },
      "source": [
        "### FP16 Quantisierung des ONNX Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EOwr_prgiN4"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "onnx_model = onnx.load(\"dtmf_classifier.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "onnx_model_fp16 = float16.convert_float_to_float16(\n",
        "    onnx_model,\n",
        "    min_positive_val=1e-7,\n",
        "    max_finite_val=1e4,\n",
        "    keep_io_types=True,\n",
        "    disable_shape_infer=False,\n",
        "    op_block_list=None,\n",
        "    node_block_list=None,\n",
        ")\n",
        "onnx.save(onnx_model_fp16, \"dtmf_classifier_fp16.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INT8 Quantisierung des ONNX Modells\n",
        "- dynamische INT8 Quantisierung derzeit nicht m√∂glich, da die ONNX Runtime dynamisch-quantisierte Conv1D Layer aktuell nicht unterst√ºtzt\n",
        "- statische INT8 Quantisierung in ONNX funktioniert, jedoch sind keine Laufzeitvorteile in der ONNX Runtime gegen√ºber des FP32 Modells erkennbar (Code in Anhang)\n",
        "- Auch keine Laufzeitverbesserung mit QAT in TensorFlow und Export nach INT8 ONNX Modell (Code in Anhang)\n",
        "- **Daher**: Verwendung von INT8 Quantisierung in Nvidia TensorRT"
      ],
      "metadata": {
        "id": "8-Q48XtarK-2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGuwxgoDkgGv"
      },
      "source": [
        "### TensorRT Tests\n",
        "\n",
        "TODO: Move below code to .py files and import!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSJVcrVW6gPw"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.04, 0.05),\n",
        "    dur_pause=(0.03, 0.04),\n",
        "    noise_factor=(0.0, 60.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3of1tuYcNrC"
      },
      "outputs": [],
      "source": [
        "def get_gpu_type() -> str:\n",
        "    \"\"\"Get the type of GPU available on the system.\n",
        "\n",
        "    This function checks if a CUDA-capable GPU is available using PyTorch.\n",
        "    If a GPU is available, it returns the name of the GPU in lowercase with spaces replaced by underscores.\n",
        "    If no GPU is available, it returns 'cpu'.\n",
        "\n",
        "    Returns:\n",
        "        str: The type of GPU available or 'cpu' if no GPU is available.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        return \"cpu\"\n",
        "    return \"_\".join(torch.cuda.get_device_name(0).lower().split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5sW5xE4y3Yf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "from cuda import cuda, cudart\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def check_cuda_err(err: cuda.CUresult | cudart.cudaError_t) -> None:\n",
        "    \"\"\"Check for CUDA errors and raise an exception if an error is found.\n",
        "\n",
        "    Args:\n",
        "        err (Union[cuda.CUresult, cudart.cudaError_t]): The CUDA error code.\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: If a CUDA error is detected.\n",
        "    \"\"\"\n",
        "    if isinstance(err, cuda.CUresult) and err != cuda.CUresult.CUDA_SUCCESS:\n",
        "        raise RuntimeError(f\"Cuda Error: {err}\")\n",
        "    if isinstance(err, cudart.cudaError_t):\n",
        "        if err != cudart.cudaError_t.cudaSuccess:\n",
        "            raise RuntimeError(f\"Cuda Runtime Error: {err}\")\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown error type: {err}\")\n",
        "\n",
        "\n",
        "def cuda_call(call: Any) -> Any:\n",
        "    \"\"\"Make a CUDA call and check for errors.\n",
        "\n",
        "    Args:\n",
        "        call (Any): The CUDA call to make.\n",
        "\n",
        "    Returns:\n",
        "        Any: The result of the CUDA call.\n",
        "    \"\"\"\n",
        "    err, res = call[0], call[1:]\n",
        "    check_cuda_err(err)\n",
        "    if len(res) == 1:\n",
        "        res = res[0]\n",
        "    return res\n",
        "\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_host_to_device(device_ptr: int, host_arr: np.ndarray) -> None:\n",
        "    \"\"\"Copy data from host to device.\n",
        "\n",
        "    Args:\n",
        "        device_ptr (int): The device pointer.\n",
        "        host_arr (np.ndarray): The host array.\n",
        "    \"\"\"\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(\n",
        "        cudart.cudaMemcpy(\n",
        "            device_ptr, host_arr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# Wrapper for cudaMemcpy which infers copy size and does error checking\n",
        "def memcpy_device_to_host(host_arr: np.ndarray, device_ptr: int) -> None:\n",
        "    \"\"\"Copy data from device to host.\n",
        "\n",
        "    Args:\n",
        "        host_arr (np.ndarray): The host array.\n",
        "        device_ptr (int): The device pointer.\n",
        "    \"\"\"\n",
        "    nbytes = host_arr.size * host_arr.itemsize\n",
        "    cuda_call(\n",
        "        cudart.cudaMemcpy(\n",
        "            host_arr, device_ptr, nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "class MNISTEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    \"\"\"INT8 calibrator for our DTMF classifier model.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, training_data: str, cache_file: str, batch_size: int = 16\n",
        "    ) -> None:\n",
        "        \"\"\"Initialize the MNISTEntropyCalibrator.\n",
        "\n",
        "        Args:\n",
        "            training_data (str): The path to the training data.\n",
        "            cache_file (str): The path to the cache file.\n",
        "            batch_size (int, optional): The batch size. Defaults to 16.\n",
        "        \"\"\"\n",
        "        # Whenever you specify a custom constructor for a TensorRT class,\n",
        "        # you MUST call the constructor of the parent explicitly.\n",
        "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
        "\n",
        "        self.cache_file = cache_file\n",
        "\n",
        "        # Every time get_batch is called, the next batch of size batch_size will be copied to the device and returned.\n",
        "        # self.data = 2 * np.random.rand(32*batch_size, 2**12, 1).astype(np.float32) - 1.0\n",
        "        # self.data = training_data\n",
        "        self.data = dtmf_gen.generate_dataset(\n",
        "            n_samples=32 * batch_size, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        # print(self.data.dtype)\n",
        "        # self.data = self.data.astype(np.float32)\n",
        "        self.batch_size = batch_size\n",
        "        self.current_index = 0\n",
        "\n",
        "        # Allocate enough memory for a whole batch.\n",
        "        # self.device_input = cuda.mem_alloc(self.data[0].nbytes * self.batch_size)\n",
        "        n_bytes = self.data[0].nbytes * self.batch_size\n",
        "        # print(\"n_bytes\", n_bytes)\n",
        "        self.device_input = cuda_call(cudart.cudaMalloc(n_bytes))\n",
        "\n",
        "    def get_batch_size(self) -> int:\n",
        "        \"\"\"Get the batch size.\n",
        "\n",
        "        Returns:\n",
        "            int: The batch size.\n",
        "        \"\"\"\n",
        "        return self.batch_size\n",
        "\n",
        "    # TensorRT passes along the names of the engine bindings to the get_batch function.\n",
        "    # You don't necessarily have to use them, but they can be useful to understand the order of\n",
        "    # the inputs. The bindings list is expected to have the same ordering as 'names'.\n",
        "    def get_batch(self, names: list[str]) -> list[int] | None:\n",
        "        \"\"\"Get a batch of data.\n",
        "\n",
        "        Args:\n",
        "            names (List[str]): The names of the engine bindings.\n",
        "\n",
        "        Returns:\n",
        "            Optional[List[int]]: The device input pointer, or None if there is no more data.\n",
        "        \"\"\"\n",
        "        # print(\"names:\", names)\n",
        "        if self.current_index + self.batch_size > self.data.shape[0]:\n",
        "            return None\n",
        "\n",
        "        current_batch = int(self.current_index / self.batch_size)\n",
        "        if current_batch % 10 == 0:\n",
        "            print(\n",
        "                f\"Calibrating batch {current_batch}, containing {self.batch_size} images\"\n",
        "            )\n",
        "\n",
        "        batch = self.data[\n",
        "            self.current_index : self.current_index + self.batch_size\n",
        "        ].ravel()\n",
        "        # cuda.memcpy_htod(self.device_input, batch)\n",
        "        # memcpy_host_to_device(self.device_input, batch)\n",
        "        memcpy_host_to_device(self.device_input, np.ascontiguousarray(batch))\n",
        "        self.current_index += self.batch_size\n",
        "        # print(\"Schalom!\")\n",
        "        return [int(self.device_input)]\n",
        "\n",
        "    def read_calibration_cache(self) -> bytes | None:\n",
        "        \"\"\"Read the calibration cache.\n",
        "\n",
        "        Returns:\n",
        "            Optional[bytes]: The calibration cache, or None if it does not exist.\n",
        "        \"\"\"\n",
        "        # If there is a cache, use it instead of calibrating again. Otherwise, implicitly return None.\n",
        "        if Path.exists(self.cache_file):\n",
        "            return Path(self.cache_file).read_bytes()\n",
        "        return None\n",
        "\n",
        "    def write_calibration_cache(self, cache: bytes) -> None:\n",
        "        \"\"\"Write the calibration cache.\n",
        "\n",
        "        Args:\n",
        "            cache (bytes): The calibration cache.\n",
        "        \"\"\"\n",
        "        return  # for now\n",
        "        Path(self.cache_file).write_bytes(cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6k2njAel4z6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import tensorrt as trt\n",
        "\n",
        "# You can set the logger severity higher to suppress messages (or lower to display more messages).\n",
        "TRT_LOGGER: trt.Logger = trt.Logger(trt.Logger.VERBOSE)\n",
        "\n",
        "\n",
        "def build_engine_onnx(\n",
        "    model_file: str, trt_engine_path: str, precision: str\n",
        ") -> None:\n",
        "    \"\"\"Builds a TensorRT engine from an ONNX model file.\n",
        "\n",
        "    Args:\n",
        "        model_file (str): The path to the ONNX model file.\n",
        "        trt_engine_path (str): The path to save the TensorRT engine.\n",
        "        precision (str): The precision mode to use ('fp16', 'int8', 'mixed').\n",
        "\n",
        "    Returns:\n",
        "        Optional[None]: Returns None if the engine creation fails.\n",
        "    \"\"\"\n",
        "    seq_len: int = 2**12\n",
        "    max_batch_size: list[int] = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
        "    calibration_batch_size: int = 16\n",
        "    builder: trt.Builder = trt.Builder(TRT_LOGGER)\n",
        "    network: trt.INetworkDefinition = builder.create_network(0)\n",
        "    config: trt.IBuilderConfig = builder.create_builder_config()\n",
        "    parser: trt.OnnxParser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "    config.set_memory_pool_limit(\n",
        "        trt.MemoryPoolType.WORKSPACE, 8 * 1 << 30\n",
        "    )  # TODO: Constant\n",
        "\n",
        "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "    if not parser.parse(Path(model_file).read_bytes()):\n",
        "        print(\"ERROR: Failed to parse the ONNX file.\")\n",
        "        for error in range(parser.num_errors):\n",
        "            print(parser.get_error(error))\n",
        "        return\n",
        "\n",
        "    for b in max_batch_size:\n",
        "        profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
        "        profile.set_shape(\"input\", [b//2 + 1, seq_len, 1], [b, seq_len, 1], [b, seq_len, 1])\n",
        "        config.add_optimization_profile(profile)\n",
        "\n",
        "    if precision in [\"fp16\", \"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_fp16:\n",
        "            print(\"FP16 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.FP16)\n",
        "    if precision in [\"int8\", \"mixed\"]:\n",
        "        if not builder.platform_has_fast_int8:\n",
        "            print(\"INT8 is not supported natively on this platform/device\")\n",
        "        config.set_flag(trt.BuilderFlag.INT8)\n",
        "        # config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "\n",
        "        calib = MNISTEntropyCalibrator(\n",
        "            \"\", cache_file=\"cache.file\", batch_size=calibration_batch_size\n",
        "        )\n",
        "        config.int8_calibrator = calib\n",
        "\n",
        "        calib_profile: trt.IOptimizationProfile = builder.create_optimization_profile()\n",
        "        calib_profile.set_shape(\n",
        "            \"input\",\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "            [calibration_batch_size, seq_len, 1],\n",
        "        )\n",
        "        config.set_calibration_profile(calib_profile)\n",
        "        config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED\n",
        "\n",
        "        print(\"int 8 model\")\n",
        "\n",
        "    engine_bytes: bytes | None = builder.build_serialized_network(network, config)\n",
        "\n",
        "    if engine_bytes is None:\n",
        "        print(\"Failed to create the TensorRT engine\")\n",
        "        return\n",
        "    trt.Runtime(TRT_LOGGER)\n",
        "\n",
        "    # Save the engine to a file\n",
        "    Path(trt_engine_path).write_bytes(engine_bytes)\n",
        "\n",
        "    print(f\"TensorRT engine saved to {trt_engine_path}\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "precision: str = \"int8\"\n",
        "onnx_path: str = \"qat_dtmf_classifier.onnx\"\n",
        "trt_path: str = \"dtmf_classifier_\" + precision + \"_\" + get_gpu_type() + \".trt\"\n",
        "build_engine_onnx(onnx_path, trt_path, precision=precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY4AP6jrmJKg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import Any\n",
        "\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "\n",
        "DEBUG = False\n",
        "\n",
        "\n",
        "def print_dbg(*x: Any) -> None:\n",
        "    \"\"\"Print debug information if DEBUG is set to True.\n",
        "\n",
        "    Args:\n",
        "        *x (Any): The information to print.\n",
        "    \"\"\"\n",
        "    if DEBUG:\n",
        "        print(x)\n",
        "\n",
        "class CustomProfiler(trt.IProfiler):\n",
        "    \"\"\"Custom Profiler for logging layer-wise latency.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        trt.IProfiler.__init__(self)\n",
        "        self.layers = {}\n",
        "\n",
        "    def report_layer_time(self, layer_name, ms):\n",
        "        if layer_name not in self.layers:\n",
        "            self.layers[layer_name] = []\n",
        "\n",
        "        self.layers[layer_name].append(ms)\n",
        "\n",
        "class TensorRTInfer:\n",
        "    # TODO: This code still has a memory leak. The memory allocated by\n",
        "    # cudaMalloc has to be released!\n",
        "    \"\"\"Implements inference for the TensorRT engine.\"\"\"\n",
        "\n",
        "    def __init__(self, engine_path: str) -> None:\n",
        "        \"\"\"Initialize the TensorRTInfer class.\n",
        "\n",
        "        Args:\n",
        "            engine_path (str): The path to the serialized engine to load from disk.\n",
        "        \"\"\"\n",
        "        # Load TRT engine\n",
        "        self.logger = trt.Logger(trt.Logger.ERROR)\n",
        "        trt.init_libnvinfer_plugins(self.logger, namespace=\"\")\n",
        "        # with open(engine_path, \"rb\") as f, trt.Runtime(self.logger) as runtime:\n",
        "        #    assert runtime\n",
        "        #    self.engine = runtime.deserialize_cuda_engine(f.read())\n",
        "        runtime = trt.Runtime(self.logger)\n",
        "        assert runtime\n",
        "        self.engine = runtime.deserialize_cuda_engine(Path(engine_path).read_bytes())\n",
        "\n",
        "        assert self.engine\n",
        "        self.context = self.engine.create_execution_context()\n",
        "        assert self.context\n",
        "\n",
        "        # Some Infos about the engine\n",
        "        print_dbg(\"num optimization profiles:\", self.engine.num_optimization_profiles)\n",
        "        print_dbg(\"num io tensors:\", self.engine.num_io_tensors)\n",
        "\n",
        "        # Create CUDA stream for asynchronous tasks\n",
        "        _, self.stream = cudart.cudaStreamCreate()\n",
        "\n",
        "        # Setup I/O bindings\n",
        "        self.inputs = []\n",
        "        self.outputs = []\n",
        "        self.allocations = []\n",
        "        for prof_idx in range(self.engine.num_optimization_profiles):\n",
        "            for i in range(self.engine.num_io_tensors):\n",
        "                name = self.engine.get_tensor_name(i)\n",
        "                is_input = False\n",
        "                if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
        "                    is_input = True\n",
        "                dtype = np.dtype(trt.nptype(self.engine.get_tensor_dtype(name)))\n",
        "                shape = self.engine.get_tensor_shape(name)\n",
        "                if is_input and shape[0] < 0:\n",
        "                    assert self.engine.num_optimization_profiles >= 1\n",
        "                    profile_shape = self.engine.get_tensor_profile_shape(name, prof_idx)\n",
        "                    print_dbg(\"profile_shape\", name, profile_shape)\n",
        "                    assert len(profile_shape) == 3  # min,opt,max\n",
        "\n",
        "                    # Set the *max* profile as binding shape\n",
        "                    self.switch_profile(prof_idx)\n",
        "                    self.context.set_input_shape(name, profile_shape[2])\n",
        "                    shape = self.context.get_tensor_shape(name)\n",
        "\n",
        "                if not is_input:\n",
        "                    shape = self.context.get_tensor_shape(name)\n",
        "                    print_dbg(\"shape for output:\", name, shape)\n",
        "\n",
        "                if is_input:\n",
        "                    self.batch_size = shape[0]\n",
        "                size = dtype.itemsize\n",
        "                for s in shape:\n",
        "                    size *= s\n",
        "                allocation = cuda_call(cudart.cudaMalloc(size))\n",
        "                host_allocation = None if is_input else np.zeros(shape, dtype)\n",
        "                binding = {\n",
        "                    \"index\": i,\n",
        "                    \"name\": name,\n",
        "                    \"dtype\": dtype,\n",
        "                    \"shape\": list(shape),\n",
        "                    \"allocation\": allocation,\n",
        "                    \"host_allocation\": host_allocation,\n",
        "                }\n",
        "                self.allocations.append(allocation)\n",
        "                if is_input:\n",
        "                    self.inputs.append(binding)\n",
        "                else:\n",
        "                    self.outputs.append(binding)\n",
        "                print_dbg(\n",
        "                    \"{} '{}' with shape {} and dtype {}\".format(\n",
        "                        \"Input\" if is_input else \"Output\",\n",
        "                        binding[\"name\"],\n",
        "                        binding[\"shape\"],\n",
        "                        binding[\"dtype\"],\n",
        "                    )\n",
        "                )\n",
        "            print_dbg()\n",
        "\n",
        "        assert self.batch_size > 0\n",
        "        assert len(self.inputs) > 0\n",
        "        assert len(self.outputs) > 0\n",
        "        assert len(self.allocations) > 0\n",
        "\n",
        "    def enable_profiling(self, profiler: trt.IProfiler = None) -> None:\n",
        "        \"\"\"Enable TensorRT profiling.\n",
        "\n",
        "        TensorRT will report time spent on each layer in stdout for each forward run.\n",
        "        \"\"\"\n",
        "        if not self.context.profiler:\n",
        "            self.context.profiler = CustomProfiler() if profiler is None else profiler\n",
        "\n",
        "    def input_spec(self) -> tuple[list[int], np.dtype]:\n",
        "        \"\"\"Get the specs for the input tensor of the network. Useful to prepare memory allocations.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[List[int], np.dtype]: Two items, the shape of the input tensor and its (numpy) datatype.\n",
        "        \"\"\"\n",
        "        # TODO: Index 0 is wrong\n",
        "        return self.inputs[0][\"shape\"], self.inputs[0][\"dtype\"]\n",
        "\n",
        "    def output_spec(self) -> list[tuple[list[int], np.dtype]]:\n",
        "        \"\"\"Get the specs for the output tensors of the network. Useful to prepare memory allocations.\n",
        "\n",
        "        Returns:\n",
        "            List[Tuple[List[int], np.dtype]]: A list with two items per element, the shape and (numpy) datatype of each output tensor.\n",
        "        \"\"\"\n",
        "        specs = []\n",
        "        for o in self.outputs:\n",
        "            specs.append((o[\"shape\"], o[\"dtype\"]))\n",
        "        return specs\n",
        "\n",
        "    def switch_profile(self, idx: int) -> None:\n",
        "        \"\"\"Switch to a different optimization profile.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the optimization profile to switch to.\n",
        "        \"\"\"\n",
        "        self.context.set_optimization_profile_async(\n",
        "            idx, self.stream\n",
        "        )\n",
        "\n",
        "    def infer(self, batch: np.ndarray) -> list[np.ndarray]:\n",
        "        \"\"\"Execute inference on a batch of images.\n",
        "\n",
        "        Args:\n",
        "            batch (np.ndarray): A numpy array holding the image batch.\n",
        "\n",
        "        Returns:\n",
        "            List[np.ndarray]: A list of outputs as numpy arrays.\n",
        "        \"\"\"\n",
        "        # If the optimization profile does not match, change it here:\n",
        "        # In our setup the opt. profiles are selected in a way that the\n",
        "        # optimal batch sizes are powers of 2. In practice, one would not do\n",
        "        # it in this way:\n",
        "        # TODO: If the profile does not fit in the range, find the profile with\n",
        "        # the closest optimal settings...\n",
        "        if True:\n",
        "          expected_profile = int(np.log2(batch.shape[0]))\n",
        "          if self.context.active_optimization_profile != expected_profile:\n",
        "              print(\"Changing to profile\", expected_profile)\n",
        "              self.switch_profile(expected_profile)\n",
        "\n",
        "          if self.context.get_tensor_shape(\"input\") != batch.shape:\n",
        "              print(\"Changing batch size for inference!\")\n",
        "\n",
        "              # Adapt the input shape:\n",
        "              self.context.set_input_shape(\"input\", batch.shape)\n",
        "        print_dbg(\n",
        "            \"self.engine.get_tensor_shape(input)\", self.engine.get_tensor_shape(\"input\")\n",
        "        )\n",
        "        print_dbg(\n",
        "            \"self.context.get_tensor_shape(input)\",\n",
        "            self.context.get_tensor_shape(\"input\"),\n",
        "        )\n",
        "        print_dbg(\n",
        "            \"self.context.get_tensor_shape(output)\",\n",
        "            self.context.get_tensor_shape(\"output\"),\n",
        "        )\n",
        "        print_dbg()\n",
        "\n",
        "        o_idx = self.context.active_optimization_profile\n",
        "        print_dbg(\"Active output index (opt. profile)\", o_idx)\n",
        "\n",
        "        # Copy I/O and Execute\n",
        "        memcpy_host_to_device(self.inputs[o_idx][\"allocation\"], batch)\n",
        "\n",
        "        self.context.execute_v2(self.allocations)\n",
        "        memcpy_device_to_host(\n",
        "            self.outputs[o_idx][\"host_allocation\"], self.outputs[o_idx][\"allocation\"]\n",
        "        )\n",
        "\n",
        "        return [self.outputs[o_idx][\"host_allocation\"]]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Main function to run the TensorRT inference.\"\"\"\n",
        "trt_path = \"dtmf_classifier_int8_tesla_t4.trt\"\n",
        "seq_len = 2**12\n",
        "trt_infer = TensorRTInfer(trt_path)\n",
        "#trt_infer.enable_profiling() # Use only for debugging/analysis purposes, since it slows down inference\n",
        "\n",
        "print(\"Starting inference\")\n",
        "if True:\n",
        "    trt_infer.switch_profile(6)\n",
        "    spec = trt_infer.input_spec()\n",
        "    print(\"spec\", spec)\n",
        "    # batch = my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        "    X, Y = dtmf_gen.generate_dataset(n_samples=256, t_length=seq_len)\n",
        "    o = trt_infer.infer(X.astype(np.float32))[0][: X.shape[0]]\n",
        "    #o = keras_model.predict(X.astype(np.float32), verbose=0)\n",
        "    print(\"o.shape\", o.shape)\n",
        "\n",
        "    thresholded = (o > 0.5).astype(int)\n",
        "    print((thresholded == Y).sum() / Y.size)\n",
        "    for iidx in range(X.shape[0]):\n",
        "        predicted_key_sequence = dtmf_gen.decode_prediction(o[iidx])\n",
        "        original_key_sequence = dtmf_gen.decode_prediction(Y[iidx])\n",
        "        if predicted_key_sequence != original_key_sequence:\n",
        "            print(\"predicted_key_sequence\", predicted_key_sequence)\n",
        "            print(\"original_key_sequence\", original_key_sequence)\n",
        "        else:\n",
        "            print(\"OK\", predicted_key_sequence)\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"No input provided, running in benchmark mode\")\n",
        "    trt_infer.switch_profile(0)\n",
        "    spec = trt_infer.input_spec()\n",
        "\n",
        "    spec = (512, 4096, 1), np.float32\n",
        "\n",
        "    rng = np.random.default_rng()\n",
        "    batch = rng.random(spec[0]).astype(spec[1])\n",
        "    # batch = np.random.rand(*spec[0]).astype(spec[1])\n",
        "\n",
        "    print(\"batch.shape\", batch.shape)\n",
        "    print(\"batch.dtype\", batch.dtype)\n",
        "    print(\"min/max/mean\", batch.min(), batch.max(), batch.mean())\n",
        "    iterations = 100\n",
        "    times = []\n",
        "    for i in range(20):  # GPU warmup iterations\n",
        "        trt_infer.infer(batch)\n",
        "    for i in range(iterations):\n",
        "        start = time.time()\n",
        "        o = trt_infer.infer(batch)\n",
        "        times.append(time.time() - start)\n",
        "        print(f\"Iteration {i + 1} / {iterations}\", end=\"\\r\")\n",
        "    print(\"Benchmark results include time for H2D and D2H memory copies\")\n",
        "    print(f\"Average Latency: {1000 * np.average(times):.3f} ms\")\n",
        "    print(f\"Average Throughput: {trt_infer.batch_size / np.average(times):.1f} ips\")\n",
        "\n",
        "print()\n",
        "print(\"Finished Processing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, o.shape"
      ],
      "metadata": {
        "id": "a2skERGo8hxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X[3,:,0])"
      ],
      "metadata": {
        "id": "6FE57CRX-q1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trt_path"
      ],
      "metadata": {
        "id": "NJxjPLRYoscs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_fp16 = pd.DataFrame([ (k, np.mean(v)) for k, v in trt_infer.context.profiler.layers.items()], columns=[\"Layer\", \"Time (ms)\"])"
      ],
      "metadata": {
        "id": "ZjSx_JaTn9Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_int8.set_index(\"Layer\").add_suffix(' int8'), df_fp16.set_index(\"Layer\").add_suffix(' fp16')], axis=1)"
      ],
      "metadata": {
        "id": "UPSFFqu8pFfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"diff\"] = df[\"Time (ms) fp16\"] - df[\"Time (ms) int8\"]"
      ],
      "metadata": {
        "id": "R461aK52qy2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)  # Display up to 50 columns\n",
        "df.sort_values(\"diff\", ascending=False)"
      ],
      "metadata": {
        "id": "eDZQHQaupi_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in trt_infer.context.profiler.layers.items():\n",
        "  print(k[-40:], np.sum(v))"
      ],
      "metadata": {
        "id": "JK_aoGgKZh69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trt_infer.profiler.report_layer_time(0)"
      ],
      "metadata": {
        "id": "tLg5ItFTYRCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modell-Experimente"
      ],
      "metadata": {
        "id": "xIEjIXGXq_k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laden der einzelnen Modelle f√ºr die Inferenz"
      ],
      "metadata": {
        "id": "ajTlV0ndF3j0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYcDlVrLqWwx"
      },
      "outputs": [],
      "source": [
        "from techdays25.onnx_utils import (\n",
        "    OnnxModel,\n",
        "    benchmark_models_on_batch_size,\n",
        "    plot_benchmark_results,\n",
        ")\n",
        "from pathlib import Path\n",
        "\n",
        "# FP32 ONNX Model\n",
        "onnx_classifier = OnnxModel(\"dtmf_classifier.onnx\")\n",
        "\n",
        "# FP16 ONNX Model\n",
        "onnx_classifier_fp16 = OnnxModel(\"dtmf_classifier_fp16.onnx\")\n",
        "\n",
        "# INT8 TensorRT Model\n",
        "tensorrt_classifier_int8 = TensorRTInfer(f\"dtmf_classifier_int8_{get_gpu_type()}.trt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H557RUJyEhf"
      },
      "outputs": [],
      "source": [
        "# TODO: Allow to select model here:\n",
        "onnx_prediction = onnx_classifier_fp16.predict(\n",
        "    my_dialed_sequence_signal.reshape(1, -1, 1).astype(np.float32)\n",
        ")\n",
        "predicted_key_sequence = dtmf_gen.decode_prediction(onnx_prediction)\n",
        "print(\"Predicted Sequence:\", predicted_key_sequence)\n",
        "print(\n",
        "    \"Passt die Prognose zur tats√§chlichen gew√§hlten Sequenz?:\",\n",
        "    \"Ja!\" if predicted_key_sequence == my_dialed_sequence_keys else \"Nein!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns8srDuD5Ji1"
      },
      "source": [
        "### Laufzeitmessung (Latenz) der individuellen Modelle\n",
        "- Messung der Inferenzzeiten f√ºr 4 Modelle:\n",
        "  - Keras, FP32 (urspr√ºngliches Modell)\n",
        "  - ONNX, FP32\n",
        "  - ONNX, FP16\n",
        "  - TensorRT, INT8\n",
        "- Verschiedene Batch-Gr√∂√üen: 1,2,4,...,\n",
        "- Signall√§nge: 4096\n",
        "- \"Aufw√§rmen\" der Modelle: Jeweils 20 Durchl√§ufe f√ºr eine Batch-Gr√∂√üe\n",
        "- 100-fache Wiederholung jeder Messung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj0splX4gqHP"
      },
      "outputs": [],
      "source": [
        "n_runs = 100\n",
        "n_warmup = 20\n",
        "signal_length = 2**12\n",
        "batch_sizes = [2**i for i in range(10)]\n",
        "\n",
        "model_dict = {\n",
        "    \"keras (FP32)\": lambda x: keras_model.predict(x, verbose=0),\n",
        "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    \"TRT (INT8)\": tensorrt_classifier_int8.infer,\n",
        "}\n",
        "\n",
        "dtmf_benchmark_results = benchmark_models_on_batch_size(\n",
        "    model_dict=model_dict,\n",
        "    input_shape=(signal_length, 1),\n",
        "    batch_sizes=batch_sizes,\n",
        "    n_runs=n_runs,\n",
        "    n_warmup=n_warmup,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzxwUrIdqNFN"
      },
      "outputs": [],
      "source": [
        "show_models = [\n",
        "    'keras (FP32)',\n",
        "    'ONNX (FP32)',\n",
        "    'ONNX (FP16)',\n",
        "     'TRT (INT8)',\n",
        "]\n",
        "\n",
        "plot_benchmark_results(\n",
        "    results={k: v for k,v in dtmf_benchmark_results.items() if k in show_models},\n",
        "    title=\"Inferenzzeiten von DTMF-Klassifikationsmodellen\",\n",
        "    xscale=\"log\",\n",
        "    yscale=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "df_runtimes = pd.DataFrame( {k: v.median(axis=0)*1000.0 for k,v in dtmf_benchmark_results.items()} )\n",
        "df_runtimes.index.name = 'Batchgr√∂√üe'\n",
        "display(HTML(\"<h2>Durchschnittliche Inferenzzeiten in Millisekunden</h2>\"))\n",
        "display(df_runtimes)"
      ],
      "metadata": {
        "id": "rTqqTVpthq3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Speedup der quantisierten Modelle gg√º. Keras-Modell {display-mode: \"form\"}\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_speedup(df, reference_model, batch_size):\n",
        "    # Ensure the batch size exists in the DataFrame\n",
        "    if batch_size not in df.index:\n",
        "        raise ValueError(f\"Batch size {batch_size} not found in the DataFrame index.\")\n",
        "\n",
        "    # Ensure the reference model exists in the DataFrame columns\n",
        "    if reference_model not in df.columns:\n",
        "        raise ValueError(f\"Reference model {reference_model} not found in the DataFrame columns.\")\n",
        "\n",
        "    # Extract the runtimes for the given batch size\n",
        "    runtimes = df.loc[batch_size]\n",
        "\n",
        "    # Calculate the speedup relative to the reference model\n",
        "    reference_runtime = runtimes[reference_model]\n",
        "    speedup = reference_runtime / runtimes\n",
        "\n",
        "    # Plot the bar chart\n",
        "    plt.figure(figsize=(7, 5))\n",
        "\n",
        "    #colors = plt.cm.viridis(np.linspace(0, 1, len(speedup)))  # Use a colormap for different colors\n",
        "    cmap = plt.get_cmap(\"tab10\")\n",
        "\n",
        "    colors = [cmap(i) for i in range(16)]  # Get 16 distinct colors\n",
        "    bars = speedup.plot(kind='bar', color=colors)\n",
        "\n",
        "    # Annotate each bar with the speedup value\n",
        "    for bar in bars.patches:\n",
        "        height = bar.get_height()\n",
        "        bars.annotate(f'x{height:.2f}',\n",
        "                      xy=(bar.get_x() + bar.get_width() / 2, height-0.1),\n",
        "                      xytext=(0, 3),  # 3 points vertical offset\n",
        "                      textcoords=\"offset points\",\n",
        "                      ha='center', va='bottom')\n",
        "\n",
        "    plt.title(f'Speedup relativ zu \"{reference_model}\" f√ºr Batch-Gr√∂√üe {batch_size}')\n",
        "    plt.xlabel('Modell')\n",
        "    plt.ylabel('Speedup')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', which=\"both\")\n",
        "    plt.show()\n",
        "\n",
        "plot_speedup(df_runtimes, reference_model='keras (FP32)', batch_size=512)"
      ],
      "metadata": {
        "id": "Lpfn2IjIk-bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genauigkeit der (quantisierten) Modelle"
      ],
      "metadata": {
        "id": "CFZx9ylH06K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "signal_length = 2**12 # TODO: Increase\n",
        "batch_size = 256\n",
        "noise_levels = [5*i for i in range(21)]\n",
        "\n",
        "model_dict = {\n",
        "    \"keras (FP32)\": lambda x: keras_model.predict(x, verbose=0),\n",
        "    \"ONNX (FP32)\": onnx_classifier.predict,\n",
        "    \"ONNX (FP16)\": onnx_classifier_fp16.predict,\n",
        "    \"TRT (INT8)\": lambda x: tensorrt_classifier_int8.infer(x)[0],\n",
        "}"
      ],
      "metadata": {
        "id": "difLRtDd1nK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.02, 0.05),\n",
        "    dur_pause=(0.01, 0.03),\n",
        "    noise_factor=None, # We will set this manually ourselves later\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ],
      "metadata": {
        "id": "sv7_Ttzq1Mb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Genaugkeit der einzelnen Modelle f√ºr unterschiedliches Rauschverhalten auswerten {display-mode: \"form\"}\n",
        "\n",
        "import Levenshtein\n",
        "\n",
        "# A bit hacky code here...\n",
        "\n",
        "def plot_acc_metrics(df_levenshtein, df_accuracies, avg_sequence_length):\n",
        "  def plot(which_result):\n",
        "    df = df_levenshtein if which_result == \"levenshtein\" else df_accuracies\n",
        "    df.index.name = \"Rauschlevel\"\n",
        "    cmap = plt.get_cmap(\"tab10\")\n",
        "    colors = [cmap(i) for i in range(len(df.columns))]\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for column, color in zip(df.columns, colors):\n",
        "      plt.plot(df[column], color=color, label=column)\n",
        "\n",
        "    plt.xlabel(\"Rauschlevel\")\n",
        "    plt.ylabel(which_result)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.title(f\"Metrik '{which_result}' f√ºr ausgew√§hlte Modelle (mittlere Sequenzl√§nge: {avg_sequence_length: .2f})\")\n",
        "    plt.show()\n",
        "  return plot\n",
        "\n",
        "def evaluate_dtmf_model(model_fnc, X_val, Y_val):\n",
        "  prediction = model_fnc(X_val.astype(np.float32))\n",
        "\n",
        "  assert prediction.shape == Y_val.shape\n",
        "\n",
        "  # Compute Class Accuracy\n",
        "  pred_classes = prediction.squeeze().argmax(axis=-1)\n",
        "  Y_val_classes = Y_val.squeeze().argmax(axis=-1)\n",
        "  accuracy = (pred_classes == Y_val_classes).sum() / Y_val_classes.size\n",
        "\n",
        "  # For every prediction check, if sequence matches\n",
        "  levenshtein_distance = 0\n",
        "  sequence_length = 0\n",
        "  for idx in range(X_val.shape[0]):\n",
        "      predicted_key_sequence = dtmf_gen.decode_prediction(prediction[idx])\n",
        "      original_key_sequence = dtmf_gen.decode_prediction(Y_val[idx])\n",
        "      levenshtein_distance += Levenshtein.distance(predicted_key_sequence, original_key_sequence)\n",
        "      sequence_length += len(original_key_sequence)\n",
        "  # accuracy and average levenshtein distance\n",
        "  return accuracy, levenshtein_distance / X_val.shape[0], sequence_length / X_val.shape[0]\n",
        "\n",
        "noise_level_accuracies = {}\n",
        "noise_level_levenshtein = {}\n",
        "\n",
        "print(\"Auswertung l√§uft \", end=\"\")\n",
        "for noise_level in noise_levels:\n",
        "  X_val, Y_val = dtmf_gen.generate_dataset(n_samples=batch_size, t_length=signal_length, noise_factor=noise_level)\n",
        "  # print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())\n",
        "\n",
        "  # To be fair, use the same data for all models\n",
        "  all_model_accuracies = {}\n",
        "  all_model_levenshtein = {}\n",
        "  for model_name, model_fnc in model_dict.items():\n",
        "    print(\".\", end=\"\")\n",
        "    accuracy_signal, avg_levenshtein_distance, avg_sequence_length = evaluate_dtmf_model(model_fnc, X_val, Y_val)\n",
        "    #print(accuracy_signal, accuracy_sequence)\n",
        "\n",
        "    all_model_accuracies[model_name] = accuracy_signal\n",
        "    all_model_levenshtein[model_name] = avg_levenshtein_distance\n",
        "\n",
        "  noise_level_accuracies[noise_level] = pd.Series(all_model_accuracies)\n",
        "  noise_level_levenshtein[noise_level] = pd.Series(all_model_levenshtein)\n",
        "\n",
        "df_levenshtein = pd.DataFrame(noise_level_levenshtein).T\n",
        "df_accuracies = pd.DataFrame(noise_level_accuracies).T\n",
        "\n",
        "plot_accuracy_metrics = plot_acc_metrics(df_levenshtein, df_accuracies, avg_sequence_length)"
      ],
      "metadata": {
        "id": "DMCl3eyy2Nn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_metrics(\"levenshtein\")\n",
        "plot_accuracy_metrics(\"accuracy\")"
      ],
      "metadata": {
        "id": "DVqYJn097xKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96Jn4tTY6DJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIWnRYYTuD4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein # TODO: Put into dependencies"
      ],
      "metadata": {
        "id": "tcwDvfRm5dYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN2XVzIyy_Ww"
      },
      "source": [
        "## Anhang 1: Reproduktion des Modells/Erneutes Training des Keras Modells (Optional)\n",
        "\n",
        "**Hinweis:** Da das Training des Modells vergleichsweise viele Ressourcen ben√∂tigt (RAM/GPU), sollte *jetzt* die Colab Sitzung neugestartet werden!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y0ndHlTcqzX"
      },
      "source": [
        "# Further Experiments with Data Types\n",
        "\n",
        "TODO: Move to utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frFXsleBYGPT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def float_to_binary_fp32(num: float) -> str:\n",
        "    \"\"\"Converts a built-in floating point number (64-bit) to its FP32 binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the floating point number.\n",
        "    \"\"\"\n",
        "    print(\"fp32:\", num)\n",
        "    return \"\".join(f\"{c:0>8b}\" for c in struct.pack(\"!f\", num))\n",
        "\n",
        "\n",
        "def float_to_binary_fp16(num: float) -> str:\n",
        "    \"\"\"Converts a builtin-in floating point number to a 16-bit floating point number and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the 16-bit floating point number.\n",
        "    \"\"\"\n",
        "    # Convert the number to a float16\n",
        "    float16_num = np.float16(num)\n",
        "\n",
        "    print(\"fp16:\", float16_num)\n",
        "\n",
        "    # Convert the float16 to bytes\n",
        "    float16_bytes = float16_num.tobytes()\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(float16_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_bf16(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to bfloat16  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the bfloat16 floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to bfloat16\n",
        "    bf = a.bfloat16()\n",
        "\n",
        "    print(\"bf16\", bf)\n",
        "\n",
        "    # Convert the bfloat16 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string (big endian notation)\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in reversed(bf_bytes))\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e4m3(num: float) -> str:\n",
        "    \"\"\"Converts a  floating point number to float8 (e4m3) and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e4m3) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e4m3)\n",
        "    bf = a.to(torch.float8_e4m3fn)\n",
        "\n",
        "    print(\"fp8_e4m3\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_fp8_e5m2(num: float) -> str:\n",
        "    \"\"\"Converts a floating point number to float8 (e5m2)  and returns its binary representation.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the float8 (e5m2) floating point number.\n",
        "    \"\"\"\n",
        "    # Create a tensor with the given number\n",
        "    a = torch.Tensor([num])\n",
        "\n",
        "    # Convert the tensor to float8 (e5m2)\n",
        "    bf = a.to(torch.float8_e5m2)\n",
        "\n",
        "    print(\"fp8_e5m2\", bf)\n",
        "\n",
        "    # Convert the float8 tensor to bytes\n",
        "    bf_bytes = bytes(bf.untyped_storage())\n",
        "\n",
        "    # Convert the bytes to a binary string\n",
        "    return \"\".join(f\"{byte:08b}\" for byte in bf_bytes)\n",
        "\n",
        "\n",
        "def float_to_binary_int(num: float, bit_length: int = 8) -> str:\n",
        "    \"\"\"Converts a floating point number to its binary representation as an integer.\n",
        "\n",
        "    Args:\n",
        "        num (float): The floating point number to convert.\n",
        "        bit_length (int, optional): The bit length of the binary representation. Defaults to 8.\n",
        "\n",
        "    Returns:\n",
        "        str: A string representing the binary format of the integer part of the floating point number.\n",
        "    \"\"\"\n",
        "    return np.binary_repr(round(num), width=bit_length)\n",
        "\n",
        "\n",
        "num = -8.875074538462327 - 2**-7 - 2**-8\n",
        "float_to_binary_fp32(num)\n",
        "# float_to_binary_fp16(num)\n",
        "# float_to_binary_bf16(num)\n",
        "# float_to_binary_fp8_e4m3(num)\n",
        "# float_to_binary_fp8_e5m2(num)\n",
        "# float_to_binary_int(num, bit_length=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-X1F7z9BUS8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "s = \"1100100001111100\"\n",
        "b = int(s, base=2).to_bytes(2, \"little\")\n",
        "print(b)\n",
        "c = np.frombuffer(b, dtype=np.float16, count=1)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGjV-2lyBUS9"
      },
      "outputs": [],
      "source": [
        "# Binary string\n",
        "binary_string = \"11000001000011111000101100101011\"\n",
        "\n",
        "# Convert the binary string to an integer\n",
        "binary_int = int(binary_string, 2)\n",
        "\n",
        "# Convert the integer to bytes (4 bytes for float32)\n",
        "binary_bytes = binary_int.to_bytes(4, byteorder=\"big\")\n",
        "\n",
        "# Unpack the bytes to a float\n",
        "float_value = struct.unpack(\">f\", binary_bytes)[0]\n",
        "\n",
        "print(float_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeF16bolNFX1"
      },
      "source": [
        "# Anhang 2: Analyse eines kleinen DTMF Klassifikationsmodells im Frequenzbereich"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Callable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def multiple_formatter(\n",
        "    denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
        ") -> Callable[[float, int], str]:\n",
        "    \"\"\"Creates a formatter function for matplotlib that formats axis labels as multiples of a given number.\n",
        "\n",
        "    Args:\n",
        "        denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
        "        number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
        "        latex (str, optional): The LaTeX string to use for the base number.\n",
        "\n",
        "    Returns:\n",
        "        Callable[[float, int], str]: A function that formats a given value as a LaTeX fraction of the base number.\n",
        "    \"\"\"\n",
        "\n",
        "    def gcd(a: int, b: int) -> int:\n",
        "        \"\"\"Computes the greatest common divisor of two integers.\n",
        "\n",
        "        Args:\n",
        "            a (int): The first integer.\n",
        "            b (int): The second integer.\n",
        "\n",
        "        Returns:\n",
        "            int: The greatest common divisor of a and b.\n",
        "        \"\"\"\n",
        "        while b:\n",
        "            a, b = b, a % b\n",
        "        return a\n",
        "\n",
        "    def _multiple_formatter(x: float, pos: int) -> str:\n",
        "        \"\"\"Formats a given value as a LaTeX fraction of the base number.\n",
        "\n",
        "        Args:\n",
        "            x (float): The value to format.\n",
        "            pos (int): The position (not used in this implementation).\n",
        "\n",
        "        Returns:\n",
        "            str: The formatted string.\n",
        "        \"\"\"\n",
        "        den = denominator\n",
        "        num = np.int64(np.rint(den * x / number))\n",
        "        com = gcd(num, den)\n",
        "        (num, den) = (int(num / com), int(den / com))\n",
        "        if den == 1:\n",
        "            if num == 0:\n",
        "                return r\"$0$\"\n",
        "            if num == 1:\n",
        "                return rf\"${latex}$\"\n",
        "            if num == -1:\n",
        "                return rf\"$-{latex}$\"\n",
        "            return rf\"${num}{latex}$\"\n",
        "        if num == 1:\n",
        "            return rf\"$\\frac{{{latex}}}{{{den}}}$\"\n",
        "        if num == -1:\n",
        "            return rf\"$\\frac{{-{latex}}}{{{den}}}$\"\n",
        "        return rf\"$\\frac{{{num}{latex}}}{{{den}}}$\"\n",
        "\n",
        "    return _multiple_formatter\n",
        "\n",
        "\n",
        "class Multiple:\n",
        "    \"\"\"A class to create locators and formatters for matplotlib axes based on multiples of a given number.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, denominator: int = 2, number: float = np.pi, latex: str = r\"\\pi\"\n",
        "    ):\n",
        "        \"\"\"Initializes the Multiple class with the given parameters.\n",
        "\n",
        "        Args:\n",
        "            denominator (int, optional): The denominator to use for the fraction representation. Defaults to 2.\n",
        "            number (float, optional): The base number to use for the multiples. Defaults to np.pi.\n",
        "            latex (str, optional): The LaTeX string to use for the base number.\n",
        "        \"\"\"\n",
        "        self.denominator = denominator\n",
        "        self.number = number\n",
        "        self.latex = latex\n",
        "\n",
        "    def locator(self) -> plt.MultipleLocator:\n",
        "        \"\"\"Creates a locator for matplotlib axes based on multiples of the base number.\n",
        "\n",
        "        Returns:\n",
        "            plt.MultipleLocator: A locator for matplotlib axes.\n",
        "        \"\"\"\n",
        "        return plt.MultipleLocator(self.number / self.denominator)\n",
        "\n",
        "    def formatter(self) -> plt.FuncFormatter:\n",
        "        \"\"\"Creates a formatter for matplotlib axes that formats labels as multiples of the base number.\n",
        "\n",
        "        Returns:\n",
        "            plt.FuncFormatter: A formatter for matplotlib axes.\n",
        "        \"\"\"\n",
        "        return plt.FuncFormatter(\n",
        "            multiple_formatter(self.denominator, self.number, self.latex)\n",
        "        )"
      ],
      "metadata": {
        "id": "iEAt6KPLZd0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze0NbFHqNO-K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(\"simple_dtmf_classifier.keras\")\n",
        "\n",
        "# Recreate the intermediate model\n",
        "intermediate_output = loaded_model.get_layer('concat').output\n",
        "recreated_intermediate_model = Model(inputs=loaded_model.input, outputs=intermediate_output, name=\"RecreatedIntermediateModel\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Plot the model graph and save to a temporary file\n",
        "plot_model(loaded_model, to_file='simple_dtmf_classifier.png', show_shapes=False, show_layer_names=True, dpi=50)\n",
        "\n",
        "# Display the plot inline\n",
        "display(Image('simple_dtmf_classifier.png'))"
      ],
      "metadata": {
        "id": "1i9AFr9Hmy0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_layer_by_name(model, layer_name):\n",
        "  for layer in model.layers:\n",
        "    if layer.name == layer_name:\n",
        "      return layer\n",
        "  return None\n"
      ],
      "metadata": {
        "id": "vDxjMxd4jGSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVexf_PdNVDg"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  for n in range(len(loaded_model.layers)):\n",
        "      if loaded_model.layers[n].name == layer_name:\n",
        "          break\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "  # Assuming 'model' is your Keras model and 'n' is the index of the layer you are interested in\n",
        "  n = 4  # Example: Get the weights and name of the 3rd layer (indexing starts from 0)\n",
        "\n",
        "  # Access the n-th layer\n",
        "  nth_layer = model.layers[n]\n",
        "\n",
        "  # Get the weights of the n-th layer\n",
        "  weights = nth_layer.get_weights()\n",
        "\n",
        "  # Get the name of the n-th layer\n",
        "  layer_name = nth_layer.name\n",
        "\n",
        "  # Print the name and weights of the n-th layer\n",
        "  print(f\"Name der {n + 1}. Schicht (Index {n}): {layer_name}\")\n",
        "  # print(f\"Gewichte der {n+1}. Schicht (Index {n}):\\n\", weights)\n",
        "  print(f\"Dimension des Layers: {weights[0].shape} (kernel_size x input_channels x  num_filters)\" ) # (kernel_size, input_channels, num_filters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = \"conv_1_1\"\n",
        "layer = find_layer_by_name(loaded_model, layer_name =  layer_name)\n",
        "\n",
        "# Print the name and weights of the n-th layer\n",
        "#print(f\"Name der {n + 1}. Schicht (Index {n}): {layer_name}\")\n",
        "# print(f\"Gewichte der {n+1}. Schicht (Index {n}):\\n\", weights)\n",
        "print(f\"Dimension des Layers: {layer.get_weights()[0].shape} (kernel_size x input_channels x  num_filters)\" ) # (kernel_size, input_channels, num_filters)"
      ],
      "metadata": {
        "id": "9nXkiac8jHe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following is necessary, since we have several downsampling layers in the model\n",
        "# Note that this computation is specific to this particular model\n",
        "freq_multiplier = 1\n",
        "if \"conv\" in layer_name:\n",
        "  freq_multiplier *= 2** (int(layer_name.split(\"_\")[1]) + 1)\n",
        "freq_multiplier"
      ],
      "metadata": {
        "id": "3D31qIHvd1Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = [freq_multiplier*2.0 * np.pi * f / dtmf_gen.get_sample_rate() for f in dtmf_gen.FREQS]"
      ],
      "metadata": {
        "id": "RCvM88wLWa3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay9hPpIUPf-M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "fig = plt.figure(figsize=(15, 16))\n",
        "\n",
        "for z in range(1):\n",
        "    dil_rate = 1 # Is always 1 in this example...\n",
        "    b = weights[0][:, 0, z]  # (kernel_size, channels, num_filters)\n",
        "    w, h = signal.freqz(b[::-1])\n",
        "    if dil_rate > 1:\n",
        "        m = b.shape\n",
        "        out = np.zeros((dil_rate) * m[0], dtype=b.dtype)\n",
        "        out[::dil_rate] = b\n",
        "        b = out[: -dil_rate + 1]\n",
        "        w, h = signal.freqz(b[::-1])\n",
        "\n",
        "    ax1 = fig.add_subplot(421 + z)\n",
        "\n",
        "    #ax1.set_title(\"Dilation rate q=\" + str(dil_rate))\n",
        "    ax1.set_title(f\"Frequenzantwort f√ºr Schicht {layer_name}\")\n",
        "\n",
        "    # plt.plot(w, 20 * np.log10(abs(h)), 'b')\n",
        "    plt.plot(w, abs(h), \"b\")\n",
        "    if z % 2 == 0:\n",
        "        plt.ylabel(\"Amplitude [dB]\", color=\"b\")\n",
        "    if z // 2 == 1:\n",
        "        plt.xlabel(r\"$\\hat\\omega$ [rad]\")  # Frequency [rad/sample]\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    angles = np.unwrap(np.angle(h))\n",
        "    # angles = angles % (2 * np.pi) - np.pi\n",
        "    plt.plot(w, angles, \"g\")\n",
        "    if z % 2 == 1:\n",
        "        plt.ylabel(\"Angle [rad]\", color=\"g\")\n",
        "    plt.grid()\n",
        "    # plt.axis('tight')\n",
        "\n",
        "    ax1.xaxis.grid(True)\n",
        "    ax1.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n",
        "    ax1.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 10))\n",
        "    ax1.xaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
        "\n",
        "    ax2.yaxis.grid(True)\n",
        "    ax2.yaxis.set_major_locator(plt.MultipleLocator(dil_rate * np.pi))\n",
        "    # ax2.yaxis.set_minor_locator(plt.MultipleLocator(2*np.pi))\n",
        "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
        "\n",
        "    # Plot vertical lines at specified frequencies\n",
        "    if frequencies:\n",
        "        for freq in frequencies:\n",
        "            ax1.axvline(x=freq, color='r', linestyle='--')\n",
        "\n",
        "plt.tight_layout(pad=0.5)\n",
        "# plt.savefig(\"pdf/example-frequency-response-ecg1.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FNI7hwmWHzP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def zplane(b, a=np.array([1])):\n",
        "    \"\"\"Plot the complex z-plane given a transfer function.\"\"\"\n",
        "    # Create a unit circle\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    ax = plt.subplot(1, 1, 1)\n",
        "    unit_circle = plt.Circle((0, 0), 1, color=\"gray\", fill=False, linestyle=\"dotted\")\n",
        "    ax.add_artist(unit_circle)\n",
        "\n",
        "    # Plot zeros and poles\n",
        "    zeros = np.roots(b)\n",
        "    poles = np.roots(a)\n",
        "    plt.scatter(\n",
        "        np.real(zeros),\n",
        "        np.imag(zeros),\n",
        "        s=50,\n",
        "        marker=\"o\",\n",
        "        facecolors=\"none\",\n",
        "        edgecolors=\"b\",\n",
        "        label=\"Zeros\",\n",
        "    )\n",
        "    plt.scatter(\n",
        "        np.real(poles), np.imag(poles), s=50, marker=\"x\", color=\"r\", label=\"Poles\"\n",
        "    )\n",
        "\n",
        "    # Set plot limits and labels\n",
        "    plt.xlim(-1.5, 1.5)\n",
        "    plt.ylim(-1.5, 1.5)\n",
        "    plt.axhline(0, color=\"black\", lw=1)\n",
        "    plt.axvline(0, color=\"black\", lw=1)\n",
        "    plt.xlabel(\"Real Part\")\n",
        "    plt.ylabel(\"Imaginary Part\")\n",
        "    plt.title(\"Z-Plane Diagram\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example: Design a low-pass FIR filter using the window method\n",
        "# numtaps = 21  # Number of filter coefficients (taps)\n",
        "# cutoff = 0.3  # Normalized cutoff frequency (0 to 1, where 1 corresponds to Nyquist frequency)\n",
        "# b = firwin(numtaps, cutoff)\n",
        "\n",
        "# Plot the z-plane diagram for the FIR filter\n",
        "zplane(b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import chirp\n",
        "\n",
        "# Define parameters\n",
        "dur = 2.0  # Duration of the chirp signal in seconds\n",
        "sample_rate = 44100  # Sampling rate in Hz\n",
        "f1 = 0  # Start frequency of the chirp in Hz\n",
        "f2 = 2000  # End frequency of the chirp in Hz\n",
        "\n",
        "f_interest = [697, 770, 852, 941, 1209, 1336, 1477, 1633]\n",
        "\n",
        "# Generate the time vector\n",
        "tt = np.arange(0.0, dur, 1 / sample_rate)\n",
        "\n",
        "# Generate the chirp signal\n",
        "chirp_signal = chirp(tt, f0=f1, f1=f2, t1=dur, method='linear')\n",
        "\n",
        "# Calculate the time points for the frequencies of interest\n",
        "t_interest = [(f - f1) / (f2 - f1) * dur for f in f_interest]\n",
        "\n",
        "# Plot the chirp signal\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.plot(tt, chirp_signal, label='Chirp Signal')\n",
        "\n",
        "# Add markers for the frequencies of interest\n",
        "for f, t in zip(f_interest, t_interest):\n",
        "    plt.axvline(x=t, color='r', linestyle='--', alpha=0.5)\n",
        "    plt.text(t, 0, f'{f} Hz', rotation=90, verticalalignment='bottom', color='r')\n",
        "\n",
        "plt.title(f'Chirp Signal from {f1} Hz to {f2} Hz')\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XLsaVUMcP9Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = intermediate_model.predict(chirp_signal.reshape(1, -1, 1))\n",
        "result.shape"
      ],
      "metadata": {
        "id": "UbbzOWRPOjz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate example data (896x8)\n",
        "# In practice, you would load your actual data here\n",
        "data = result.squeeze()\n",
        "\n",
        "# Create a figure with 8 subplots arranged vertically\n",
        "fig, axes = plt.subplots(4, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "# Plot each time series in its respective subplot\n",
        "for i in range(4):\n",
        "    ax_data = data[:len(tt), i]\n",
        "    axes[i].plot(tt, ax_data, alpha=0.8)\n",
        "    #axes[i].set_title(f'Time Series {i+1}')\n",
        "    axes[i].grid(True)\n",
        "\n",
        "    # Add markers for the frequencies of interest\n",
        "    for f, t in zip(f_interest, t_interest):\n",
        "        axes[i].axvline(x=t, color='r', linestyle='--', alpha=0.5)\n",
        "        axes[i].text(t*1.01, min(ax_data), f'{f} Hz', rotation=90, verticalalignment='bottom', color='r')\n",
        "\n",
        "# Set common labels\n",
        "fig.text(0.5, 0.04, 'Time', ha='center')\n",
        "fig.text(0.04, 0.5, 'Amplitude', va='center', rotation='vertical')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout(rect=[0.03, 0.03, 1, 0.97])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7aHPwaGFN7Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO"
      ],
      "metadata": {
        "id": "v9SuALdPYq5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AWzMtPVQkgb"
      },
      "outputs": [],
      "source": [
        "# from collections.abc import Callable\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shl0yW5zcdri"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.02, 0.1),\n",
        "    dur_pause=(0.01, 0.05),\n",
        "    noise_factor=(0.0,60.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This model can be used as a basis to analyze it in the frequency domain.\n",
        "# It appears to show some interesting insights in the frequency domain.\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Concatenate, Activation\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (None, 1)  # Example: sequence length is variable, and there are 3 features per time step\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "# Learn a filter for the input:\n",
        "conv_layer_input = Conv1D(filters=1, kernel_size=32, padding='same', activation='linear', name=f'input_filter', use_bias=False)(inputs)\n",
        "\n",
        "# Do some downsampling first\n",
        "avg_pooled = layers.AveragePooling1D(padding=\"same\", pool_size=2)(conv_layer_input)\n",
        "avg_pooled_1 = layers.AveragePooling1D(padding=\"same\", pool_size=2)(avg_pooled)\n",
        "\n",
        "# Define 4 different Conv1D layers\n",
        "conv_layers = []\n",
        "for i in range(4):\n",
        "    conv_layer = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_1_{i+1}', use_bias=False)(avg_pooled_1)\n",
        "\n",
        "    max_pooled_layer =  layers.AveragePooling1D(padding=\"same\", pool_size=2)(conv_layer)\n",
        "    conv_layer_1 = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_2_{i+1}', use_bias=False)(max_pooled_layer)\n",
        "\n",
        "    max_pooled_layer_2 = layers.MaxPooling1D(padding=\"same\")(conv_layer_1)\n",
        "    conv_layer_2 = Conv1D(filters=1, kernel_size=64, padding='same', activation='linear', name=f'conv_3_{i+1}', use_bias=False)(max_pooled_layer_2)\n",
        "    upsamp_layer = layers.UpSampling1D(size=16)(conv_layer_2)\n",
        "\n",
        "    conv_layers.append(upsamp_layer)\n",
        "\n",
        "# Concatenate the outputs of the Conv1D layers\n",
        "concatenated = Concatenate(name=\"concat\")(conv_layers)\n",
        "\n",
        "# Final 1x1 Conv1D layer with softmax activation\n",
        "output = Conv1D(filters=dtmf_gen.get_num_keys() + 1, kernel_size=1, activation='softmax', name=\"final_conv\", use_bias=False)(concatenated)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=output, name=\"MultiConv1DModel\")\n",
        "\n",
        "# Create an additional model to output the concatenated layer\n",
        "intermediate_model = Model(inputs=inputs, outputs=concatenated, name=\"IntermediateModel\")\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "tjb5kdPBgrrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN_hSCvRHtgy"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX1JtkVWTrI5"
      },
      "outputs": [],
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcganU0yPkdG"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=50, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"simple_dtmf_classifier.keras\")"
      ],
      "metadata": {
        "id": "lKhU_0SSM5xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEgSKqSPParf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IoHrDuOGcvj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RViibMMa6XF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anhang 3: Experimente mit \"Quantization Aware Training\" in TensorFlow"
      ],
      "metadata": {
        "id": "5W5cGlTk9FgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "FU2p0U14qYpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNrpNO97eX3Y"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX8x5Lym9upH"
      },
      "outputs": [],
      "source": [
        "from techdays25.dtmf_generation import DtmfGenerator\n",
        "from techdays25.dtmf_models import build_dtmf_classifier_model\n",
        "\n",
        "dtmf_gen = DtmfGenerator(\n",
        "    dur_key=(0.02, 0.1),\n",
        "    dur_pause=(0.01, 0.05),\n",
        "    noise_factor=(0.0,60.0),\n",
        "    noise_freq_range=(0.0, 20000.0),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (None, 1)\n",
        "num_classes = dtmf_gen.get_num_keys() + 1\n",
        "\n",
        "model = keras.Sequential([\n",
        "        keras.layers.Input(shape=input_shape),\n",
        "\n",
        "        keras.layers.Reshape((-1, input_shape[1], 1)),\n",
        "\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "        keras.layers.Conv2D(32, kernel_size=(32,1), activation=\"relu\",padding=\"same\"),\n",
        "\n",
        "        # Final layer\n",
        "        keras.layers.Conv2D(num_classes, kernel_size=(1,1), activation=\"softmax\", padding=\"same\"),\n",
        "\n",
        "        keras.layers.Reshape((-1, num_classes))\n",
        "    ])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "faIwam7j9upI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmgDwbmD9upI"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")  # multi-label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYwO54_A9upI"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = dtmf_gen.generate_dataset(n_samples=1024, t_length=2**14)\n",
        "X_val, Y_val = dtmf_gen.generate_dataset(n_samples=64, t_length=2**16)\n",
        "\n",
        "\n",
        "#X_train, Y_train = np.expand_dims(X_train, -1), np.expand_dims(Y_train, -2)\n",
        "#X_val, Y_val = np.expand_dims(X_val, -1), np.expand_dims(Y_val, -2)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_train.min(), X_train.max())\n",
        "print(X_val.shape, Y_val.shape, X_val.min(), X_val.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eypmk8Ab9upJ"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"pre_qat_dtmf_classifier.keras\")"
      ],
      "metadata": {
        "id": "JRXPVGIC_R-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "q_aware_model = quantize_model(model) # throws error\n",
        "\n",
        "#q_aware_model = tfmot.quantization.keras.quantize_annotate_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "id": "D0n21Nyspudg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.fit(X_train, Y_train, batch_size=64, epochs=2, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "id": "mrLpJt3Rp9AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import tf2onnx\n",
        "import tensorflow as tf\n",
        "\n",
        "which_model = \"qat_dtmf_classifier\"\n",
        "\n",
        "my_model = q_aware_model if which_model == \"qat_dtmf_classifier\" else model\n",
        "\n",
        "\n",
        "# This line sets the output names for the Keras model.\n",
        "# It might throw an error, but the ONNX model should still be exported correctly.\n",
        "my_model.output_names = [\"output\"]\n",
        "\n",
        "# Define the input signature for the model.\n",
        "# This specifies the shape and type of the input tensor.\n",
        "# 'None' in the shape indicates a variable dimension, meaning the model can accept inputs of varying sizes.\n",
        "input_signature = [\n",
        "    tf.TensorSpec([None, None, 1], tf.float32, name=\"input\")\n",
        "]\n",
        "\n",
        "# Convert the Keras model to an ONNX model using the specified input signature and opset version.\n",
        "# The opset version defines the set of operations available in the ONNX model.\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(my_model, input_signature, opset=18)\n",
        "\n",
        "# Save the converted ONNX model to a file.\n",
        "onnx.save(onnx_model, which_model + \".onnx\")"
      ],
      "metadata": {
        "id": "Xezsp71L-xrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "euGiqbOVAWsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anhang 4: ONNX INT8 Quantizatisierung vom DTMF-Klassifizierungsmodells"
      ],
      "metadata": {
        "id": "h2g33IROY5vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from onnxruntime.quantization import (\n",
        "    CalibrationDataReader,\n",
        "    QuantType,\n",
        "    quantize_dynamic,\n",
        "    quantize_static,\n",
        ")\n",
        "from onnxruntime.quantization.shape_inference import quant_pre_process"
      ],
      "metadata": {
        "id": "VbQpRe5Fzgyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = Path(\"dtmf_classifier.onnx\")\n",
        "# First try static quantization and then switch to dynamic quantization\n",
        "# and see how the results change\n",
        "static_quantization = True  # toggles between static and dynamic quantization\n",
        "onnx_model_path_int8 = onnx_model_path.stem + \"_int8.onnx\"\n",
        "\n",
        "quant_pre_process(onnx_model_path, onnx_model_path_int8 + \".pre\")\n",
        "\n",
        "\n",
        "class CalibrationDataReaderImpl(CalibrationDataReader):\n",
        "    \"\"\"A class for constructing calibration data for the ONNX INT8 calibration.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Initialize the CalibrationDataReaderImpl.\n",
        "\n",
        "        This class implements a calibration data reader for INT8 calibration.\n",
        "        It generates synthetic data for calibration purposes.\n",
        "        \"\"\"\n",
        "        self.counter: int = 0\n",
        "\n",
        "    def get_next(self) -> dict[str, Any] | None:\n",
        "        \"\"\"Get the next batch of calibration data.\n",
        "\n",
        "        This method generates synthetic data for calibration. It returns None after 16 batches.\n",
        "\n",
        "        Returns:\n",
        "            Optional[Dict[str, Any]]: A dictionary containing the input data for calibration,\n",
        "            or None if there are no more batches.\n",
        "        \"\"\"\n",
        "        if self.counter >= 16:\n",
        "            return None\n",
        "        self.counter += 1\n",
        "        X = dtmf_gen.generate_dataset(\n",
        "            n_samples=32, t_length=2**12, with_labels=None\n",
        "        ).astype(np.float32)\n",
        "        return {\"input\": X.astype(np.float32)}\n",
        "\n",
        "\n",
        "# Prepare calibration data\n",
        "calibration_data_reader = CalibrationDataReaderImpl()\n",
        "\n",
        "if static_quantization:\n",
        "    quantize_static(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        calibration_data_reader,\n",
        "        # quant_format=QuantFormat.QOperator,\n",
        "        per_channel=True,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        extra_options={\"CalibTensorRangeSymmetric\":True}\n",
        "    )\n",
        "else:\n",
        "    quantize_dynamic(\n",
        "        onnx_model_path_int8 + \".pre\",\n",
        "        onnx_model_path_int8,\n",
        "        weight_type=QuantType.QInt8,  # Quantize weights to int8\n",
        "        per_channel=True,  # Enable per-channel quantization\n",
        "        reduce_range=True,  # Reduce the quantization range\n",
        "    )"
      ],
      "metadata": {
        "id": "e6ohocSdz4GK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}